{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ The Black Friday Playbook: Building Your Peak Event Intelligence System\n",
    "## AWS re:Invent 2025 - DAT409\n",
    "## Implement hybrid search with Aurora PostgreSQL for MCP retrieval\n",
    "\n",
    "### Your Mission\n",
    "Transform a year of engineering observations into actionable intelligence for Black Friday. Build a hybrid search system that surfaces hidden patterns from past incidents and creates proactive monitoring strategies.\n",
    "\n",
    "### The Real-World Problem We're Solving\n",
    "**Every engineering team describes the same problem differently:**\n",
    "- **DBA**: \"Noticed autovacuum process holding locks longer than usual\"\n",
    "- **SRE**: \"Application response times degraded, seeing timeouts\"\n",
    "- **Developer**: \"Getting connection pool exhausted exceptions\"\n",
    "- **Data Engineer**: \"ETL jobs failing due to database unavailability\"\n",
    "\n",
    "**These are all symptoms of the same underlying issue!** Traditional search misses these connections. Today, you'll build a system that finds them all.\n",
    "\n",
    "### What You'll Learn\n",
    "1. **PostgreSQL Full-Text Search with pg_trgm**: Find variations, typos, and partial matches\n",
    "2. **Semantic Search with pgvector**: Understand conceptual similarity\n",
    "3. **Hybrid Search**: Combine both for comprehensive pattern discovery\n",
    "4. **Cohere Reranking via Amazon Bedrock**: Improve result relevance\n",
    "5. **MCP Patterns**: Structure retrieval for different contexts\n",
    "6. **Search Strategy Optimization**: Choose the right approach for each query type\n",
    "\n",
    "### Prerequisites\n",
    "- AWS Account with Bedrock access\n",
    "- Basic knowledge of PostgreSQL and Python\n",
    "- Laptop with Jupyter environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Challenge: Why Different Personas Matter\n",
    "\n",
    "Your e-commerce platform handled 10 million transactions last Black Friday. You have invaluable data from:\n",
    "- **4 engineering teams**: DBA, SRE, Developer, Data Engineer\n",
    "- **365 days** of operational observations\n",
    "- **50+ documented incidents** with different severity levels\n",
    "- **1000+ metric anomalies** captured in logs\n",
    "\n",
    "### Why Persona-Based Search Matters\n",
    "\n",
    "**Different teams have different visibility:**\n",
    "- **DBAs** see database internals: vacuum processes, lock contention, buffer cache metrics\n",
    "- **SREs** see service health: response times, error rates, availability metrics\n",
    "- **Developers** see application behavior: exceptions, query patterns, connection issues\n",
    "- **Data Engineers** see pipeline health: ETL latency, data freshness, processing backlogs\n",
    "\n",
    "**The same incident appears differently to each team:**\n",
    "- DBA logs: \"autovacuum process taking unusually long on orders table\"\n",
    "- SRE alerts: \"p99 latency spike to 2.3 seconds\"\n",
    "- Developer logs: \"ConnectionPoolExhaustedException in checkout service\"\n",
    "- Data Engineer reports: \"Order analytics pipeline delayed by 45 minutes\"\n",
    "\n",
    "**Your search system must connect these dots to prevent future incidents.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 1: Understanding Your Historical Data\n",
    "\n",
    "### Why This Matters\n",
    "Before building search capabilities, we need to understand the structure and diversity of our data. This exploration reveals:\n",
    "- How different teams document issues\n",
    "- The language patterns unique to each persona\n",
    "- The metadata that enables contextual filtering\n",
    "\n",
    "Let's start by exploring the engineering wisdom hidden in your logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Installation and Setup\n",
    "# Why: We need specific libraries for vector operations, PostgreSQL connectivity, and AWS integration\n",
    "# The warning suppression keeps the output clean for workshop participants\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Suppress all warnings for cleaner workshop experience\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "\n",
    "# Core packages needed:\n",
    "# - psycopg: Modern PostgreSQL adapter with async support\n",
    "# - pgvector: Enables vector similarity search in PostgreSQL\n",
    "# - boto3: AWS SDK for Bedrock integration (embeddings & reranking)\n",
    "# - pandas/numpy: Data manipulation and numerical operations\n",
    "# - tqdm: Progress bars for long-running operations\n",
    "# - python-dotenv: Environment variable management\n",
    "\n",
    "%pip install --quiet --upgrade psycopg pgvector boto3 pandas numpy tqdm python-dotenv 2>/dev/null\n",
    "\n",
    "print(\"‚úÖ Core packages installed\")\n",
    "print(\"‚ÑπÔ∏è Note: Any dependency warnings have been suppressed for a cleaner workshop experience\")\n",
    "\n",
    "# Quick verification that key packages are importable\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import psycopg\n",
    "    print(\"‚úÖ Package imports verified - ready to proceed!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Please restart kernel if you see import errors: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration: Understanding Your Year of Engineering Wisdom\n",
    "### Why This Matters:\n",
    "- Each persona captures different aspects of system health\n",
    "- Understanding data distribution helps optimize search strategies\n",
    "- Severity levels indicate which patterns are most critical to find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load historical incident data from your engineering teams\n",
    "# This represents a full year of observations across all teams\n",
    "with open('../data/incident_logs.json', 'r') as f:\n",
    "    incident_logs = json.load(f)\n",
    "\n",
    "print(f\"üìä Total logs to analyze: {len(incident_logs)}\")\n",
    "print(f\"üìÖ Time range: 1 year of operational data\")\n",
    "\n",
    "# Examine the MCP-style structure\n",
    "# Notice how each log has:\n",
    "# - content: The actual observation text\n",
    "# - mcp_metadata: Structured context for filtering and correlation\n",
    "sample_log = incident_logs[0]\n",
    "print(\"\\nüìã Sample log structure:\")\n",
    "print(json.dumps(sample_log, indent=2)[:600] + \"...\")\n",
    "\n",
    "# Analyze distribution by persona and severity\n",
    "# This reveals:\n",
    "# - Which teams are most active in logging (visibility gaps?)\n",
    "# - Severity distribution (are we capturing enough warning signs?)\n",
    "personas = {}\n",
    "severities = {}\n",
    "for log in incident_logs:\n",
    "    persona = log['mcp_metadata']['persona']\n",
    "    severity = log['mcp_metadata'].get('severity', 'info')\n",
    "    personas[persona] = personas.get(persona, 0) + 1\n",
    "    severities[severity] = severities.get(severity, 0) + 1\n",
    "\n",
    "print(\"\\nüë• Logs by engineering team:\")\n",
    "print(\"(Different teams have different observability - this affects search results)\")\n",
    "for persona, count in sorted(personas.items()):\n",
    "    print(f\"  - {persona}: {count} observations\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è Logs by severity:\")\n",
    "print(\"(Most issues start as 'info' before escalating - early detection is key)\")\n",
    "for severity, count in sorted(severities.items()):\n",
    "    print(f\"  - {severity}: {count} incidents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 2: Database Setup with Aurora PostgreSQL\n",
    "\n",
    "### Why Aurora PostgreSQL?\n",
    "- **Native pgvector support**: No external vector databases needed\n",
    "- **Full-text search built-in**: Combines with vectors in the same query\n",
    "- **ACID compliance**: Critical for production incident tracking\n",
    "- **Managed service**: Focus on search logic, not database operations\n",
    "\n",
    "We'll enable both pgvector and pg_trgm extensions for comprehensive search capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database Connection Setup\n",
    "### Why This Configuration:\n",
    "- psycopg: Modern PostgreSQL adapter with better performance than psycopg2\n",
    "- register_vector: Enables pgvector types in Python\n",
    "- autocommit=True: Simplifies DDL operations in workshop environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg\n",
    "from pgvector.psycopg import register_vector\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables for secure credential management\n",
    "load_dotenv()\n",
    "\n",
    "# Production Best Practice: Never hardcode credentials\n",
    "# Workshop Studio provides these via environment variables\n",
    "DB_HOST = os.getenv('DB_HOST', 'your-aurora-cluster.amazonaws.com')\n",
    "DB_NAME = os.getenv('DB_NAME', 'workshop')\n",
    "DB_USER = os.getenv('DB_USER', 'postgres')\n",
    "DB_PASSWORD = os.getenv('DB_PASSWORD', 'your-password')\n",
    "DB_PORT = os.getenv('DB_PORT', 5432)\n",
    "\n",
    "def get_db_connection():\n",
    "    \"\"\"Create a connection to Aurora PostgreSQL with vector support\n",
    "    \n",
    "    Production considerations:\n",
    "    - Use connection pooling for multiple concurrent searches\n",
    "    - Implement retry logic for transient failures\n",
    "    - Monitor connection metrics for capacity planning\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = psycopg.connect(\n",
    "            host=DB_HOST,\n",
    "            dbname=DB_NAME,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASSWORD,\n",
    "            port=DB_PORT,\n",
    "            autocommit=True  # Simplifies workshop operations\n",
    "        )\n",
    "        # Enable pgvector type handling in Python\n",
    "        register_vector(conn)\n",
    "        print(\"‚úÖ Connected to Aurora PostgreSQL\")\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Connection failed: {e}\")\n",
    "        print(\"üìù Using local PostgreSQL for demonstration\")\n",
    "        # Fallback for local testing\n",
    "        conn = psycopg.connect(\n",
    "            host='localhost',\n",
    "            dbname='workshop',\n",
    "            user='postgres',\n",
    "            password='postgres',\n",
    "            autocommit=True\n",
    "        )\n",
    "        register_vector(conn)\n",
    "        return conn\n",
    "\n",
    "# Establish connection\n",
    "conn = get_db_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database Schema Creation\n",
    "### Why This Schema Design:\n",
    "- Combines structured data (persona, timestamp) with unstructured (content)\n",
    "- Supports both vector embeddings and text search in one table\n",
    "- JSONB for flexible metrics storage without schema changes\n",
    "- Arrays for multi-valued attributes (related_systems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_database(conn):\n",
    "    \"\"\"Create database schema optimized for hybrid search\n",
    "    \n",
    "    Key design decisions:\n",
    "    - Single table design for simplicity and performance\n",
    "    - 1024-dimension vectors (Cohere's embedding size)\n",
    "    - JSONB for schema-free metrics (different teams track different metrics)\n",
    "    - Temporal markers for time-based pattern analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    with conn.cursor() as cur:\n",
    "        # Enable required extensions\n",
    "        print(\"üîß Enabling PostgreSQL extensions...\")\n",
    "        \n",
    "        # pgvector: Enables vector similarity search\n",
    "        cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "        \n",
    "        # pg_trgm: Enables trigram-based fuzzy text matching\n",
    "        cur.execute(\"CREATE EXTENSION IF NOT EXISTS pg_trgm;\")\n",
    "        \n",
    "        # Clean slate for workshop\n",
    "        cur.execute(\"DROP TABLE IF EXISTS incident_logs CASCADE;\")\n",
    "        \n",
    "        # Create main table with hybrid search capabilities\n",
    "        print(\"üìä Creating incident_logs table...\")\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TABLE incident_logs (\n",
    "                -- Primary identifier\n",
    "                doc_id TEXT PRIMARY KEY,\n",
    "                \n",
    "                -- Core content for search\n",
    "                content TEXT NOT NULL,\n",
    "                \n",
    "                -- MCP-style structured metadata\n",
    "                persona TEXT NOT NULL,        -- Which team observed this?\n",
    "                timestamp TIMESTAMPTZ NOT NULL, -- When did it happen?\n",
    "                task_context TEXT,             -- What were they doing?\n",
    "                severity TEXT DEFAULT 'info',  -- How critical was it?\n",
    "                \n",
    "                -- Flexible metric storage\n",
    "                metrics JSONB,                 -- Team-specific metrics\n",
    "                \n",
    "                -- Relationship tracking\n",
    "                related_systems TEXT[],        -- Which systems were involved?\n",
    "                temporal_marker TEXT,          -- Time-of-day patterns\n",
    "                \n",
    "                -- Vector embedding for semantic search\n",
    "                content_embedding vector(1024), -- Cohere embedding dimension\n",
    "                \n",
    "                -- Audit trail\n",
    "                created_at TIMESTAMPTZ DEFAULT NOW()\n",
    "            );\n",
    "        \"\"\")\n",
    "        \n",
    "        print(\"‚úÖ Database schema created successfully\")\n",
    "\n",
    "# Setup the database\n",
    "setup_database(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 3: Understanding PostgreSQL Full-Text Search with pg_trgm\n",
    "\n",
    "### What are Trigrams and Why Do They Matter?\n",
    "\n",
    "**The Problem:** Engineers don't always use consistent terminology:\n",
    "- One team writes \"database\", another writes \"db\"\n",
    "- Typos happen under pressure: \"performence\" instead of \"performance\"\n",
    "- Abbreviations vary: \"conn pool\" vs \"connection pool\"\n",
    "\n",
    "**The Solution:** Trigrams break text into 3-character chunks, enabling fuzzy matching:\n",
    "- 'database' ‚Üí ['dat', 'ata', 'tab', 'aba', 'bas', 'ase']\n",
    "- 'databse' (typo) ‚Üí ['dat', 'ata', 'tab', 'abs', 'bse']\n",
    "- These share many trigrams, so they match!\n",
    "\n",
    "This helps find:\n",
    "- **Partial matches**: \"db\" matches \"database\"\n",
    "- **Typos and misspellings**: Critical during incident response\n",
    "- **Similar words**: \"connection\" and \"connections\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrating Trigram Search Capabilities\n",
    "### Why This Matters for Operations:\n",
    "- During incidents, engineers make typos\n",
    "- Different teams use different abbreviations\n",
    "- Historical searches need to be forgiving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cur:\n",
    "    # Visualize how trigrams work\n",
    "    cur.execute(\"SELECT show_trgm('database performance') as trigrams;\")\n",
    "    trigrams = cur.fetchone()[0]\n",
    "    print(\"üìù Trigrams for 'database performance':\")\n",
    "    print(f\"   {trigrams}\")\n",
    "    print(\"   Note: Spaces become part of trigrams, enabling phrase matching\\n\")\n",
    "    \n",
    "    # Real-world similarity scoring examples\n",
    "    test_phrases = [\n",
    "        ('database performance', 'database performance', 'Exact match'),\n",
    "        ('database performance', 'db performance', 'Common abbreviation'),\n",
    "        ('database performance', 'database perf', 'Truncated term'),\n",
    "        ('database performance', 'databse performence', 'Multiple typos'),\n",
    "        ('database performance', 'query latency', 'Different concept')\n",
    "    ]\n",
    "    \n",
    "    print(\"üîç Similarity Scores (0 = no match, 1 = perfect match):\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for phrase1, phrase2, description in test_phrases:\n",
    "        cur.execute(\"SELECT similarity(%s, %s) as score;\", (phrase1, phrase2))\n",
    "        score = cur.fetchone()[0]\n",
    "        print(f\"{description:20} | '{phrase2:25}' | Score: {score:.3f}\")\n",
    "        \n",
    "        # Explain the implications\n",
    "        if score > 0.3:\n",
    "            print(f\"                     ‚úì Would be found with fuzzy search\")\n",
    "        elif score > 0:\n",
    "            print(f\"                     ‚ö† Weak match, might need lower threshold\")\n",
    "        else:\n",
    "            print(f\"                     ‚úó No trigram overlap - need semantic search\")\n",
    "\n",
    "print(\"\\nüí° Key Insight: Trigrams handle variations but miss conceptual similarity\")\n",
    "print(\"   That's why we need semantic search too!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 4: Semantic Search with pgvector and Cohere Embeddings\n",
    "\n",
    "### How Semantic Search Complements Trigrams\n",
    "\n",
    "**Where Trigrams Fall Short:**\n",
    "- \"Connection pool exhausted\" and \"max threads reached\" have no text overlap\n",
    "- \"Database slow\" and \"query latency high\" are conceptually similar but textually different\n",
    "\n",
    "**How Semantic Search Works:**\n",
    "1. **Text ‚Üí Vector**: Convert text to high-dimensional vectors (embeddings)\n",
    "2. **Similarity in Space**: Similar concepts have similar vectors\n",
    "3. **Nearest Neighbors**: Find closest vectors in 1024-dimensional space\n",
    "\n",
    "**Why Cohere Embed v3:**\n",
    "- State-of-the-art performance for technical content\n",
    "- Understands engineering terminology\n",
    "- Differentiates between document indexing and query search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up Semantic Search with Cohere Embeddings\n",
    "### Why Cohere via Bedrock:\n",
    "- No API key management (uses IAM roles)\n",
    "- Consistent AWS billing and monitoring\n",
    "- Low latency from within AWS regions\n",
    "- Enterprise-grade SLAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialize Bedrock client for embedding generation\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name='us-west-2'\n",
    ")\n",
    "\n",
    "def generate_embedding(text, input_type='search_document'):\n",
    "    \"\"\"\n",
    "    Generate embeddings using Cohere Embed v3 via Amazon Bedrock\n",
    "    \n",
    "    Critical distinction:\n",
    "    - 'search_document': Use when indexing logs (storing)\n",
    "    - 'search_query': Use when searching (retrieving)\n",
    "    \n",
    "    This asymmetric approach improves search relevance by 5-10%\n",
    "    \n",
    "    Args:\n",
    "        text: Input text to embed\n",
    "        input_type: 'search_document' for indexing, 'search_query' for searching\n",
    "    \"\"\"\n",
    "    # Cohere has a 2048 character limit\n",
    "    # In production, implement chunking for longer texts\n",
    "    if len(text) > 2048:\n",
    "        text = text[:2048]\n",
    "        print(\"‚ö†Ô∏è Text truncated to 2048 chars\")\n",
    "    \n",
    "    try:\n",
    "        request_body = {\n",
    "            'texts': [text],\n",
    "            'input_type': input_type  # Critical for search quality!\n",
    "        }\n",
    "        \n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId='cohere.embed-english-v3',\n",
    "            contentType='application/json',\n",
    "            accept='application/json',\n",
    "            body=json.dumps(request_body)\n",
    "        )\n",
    "        \n",
    "        response_body = json.loads(response['body'].read())\n",
    "        embedding = response_body['embeddings'][0]\n",
    "        \n",
    "        return embedding\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Bedrock call failed: {e}\")\n",
    "        print(\"Using mock embeddings for demonstration\")\n",
    "        # Generate deterministic mock embedding for testing\n",
    "        # In production, handle this error appropriately\n",
    "        np.random.seed(hash(text) % 2**32)\n",
    "        return np.random.randn(1024).tolist()\n",
    "\n",
    "# Test embedding generation with a real-world example\n",
    "test_text = \"Database performance degradation during Black Friday peak traffic\"\n",
    "test_embedding = generate_embedding(test_text)\n",
    "\n",
    "print(f\"‚úÖ Generated embedding with {len(test_embedding)} dimensions\")\n",
    "print(f\"üìä Sample values: {test_embedding[:5]}...\")\n",
    "print(f\"\\nüí° These numbers represent the 'meaning' of the text in 1024-dimensional space\")\n",
    "print(f\"   Similar texts will have similar numbers in similar positions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 5: Loading and Indexing Historical Data\n",
    "\n",
    "### Why Proper Indexing Matters\n",
    "\n",
    "**The Challenge:** \n",
    "- Processing 365 days of logs √ó 4 teams = thousands of documents\n",
    "- Each search needs to check similarity across all documents\n",
    "- Without indexes, searches take seconds instead of milliseconds\n",
    "\n",
    "**Our Indexing Strategy:**\n",
    "- **HNSW Index** for vectors: Hierarchical Navigable Small World graphs for fast approximate nearest neighbor search\n",
    "- **GIN Index** for trigrams: Generalized Inverted Index for efficient text pattern matching\n",
    "- **B-tree Indexes** for filters: Fast exact matches on persona, timestamp, severity\n",
    "\n",
    "This combination enables sub-100ms searches across thousands of documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Historical Incident Data with Embeddings\n",
    "### Why Batch Processing:\n",
    "- Reduces database round trips\n",
    "- Enables progress monitoring\n",
    "- Allows for failure recovery (can resume from last batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "def load_incident_data(conn, incident_logs, batch_size=10):\n",
    "    \"\"\"\n",
    "    Load incident logs with embeddings into database\n",
    "    \n",
    "    Production optimizations:\n",
    "    - Parallel embedding generation (multi-threading)\n",
    "    - Bulk inserts with COPY command for larger datasets\n",
    "    - Checkpointing for resumable loads\n",
    "    - Embedding caching to avoid regeneration\n",
    "    \"\"\"\n",
    "    print(f\"üì• Loading {len(incident_logs)} incident logs...\")\n",
    "    print(f\"   This generates embeddings for semantic search capability\")\n",
    "    \n",
    "    with conn.cursor() as cur:\n",
    "        # Process in batches for efficiency and progress tracking\n",
    "        for i in tqdm(range(0, len(incident_logs), batch_size), \n",
    "                     desc=\"Loading batches\",\n",
    "                     unit=\"batch\"):\n",
    "            batch = incident_logs[i:i+batch_size]\n",
    "            \n",
    "            for log in batch:\n",
    "                # Generate embedding for semantic search\n",
    "                # Using 'search_document' type for indexing\n",
    "                embedding = generate_embedding(log['content'], 'search_document')\n",
    "                \n",
    "                # Insert with all metadata for comprehensive filtering\n",
    "                cur.execute(\"\"\"\n",
    "                    INSERT INTO incident_logs (\n",
    "                        doc_id, content, persona, timestamp,\n",
    "                        task_context, severity, metrics,\n",
    "                        related_systems, temporal_marker, content_embedding\n",
    "                    ) VALUES (\n",
    "                        %s, %s, %s, %s, %s, %s, %s, %s, %s, %s\n",
    "                    ) ON CONFLICT (doc_id) DO NOTHING;\n",
    "                \"\"\", (\n",
    "                    log['doc_id'],\n",
    "                    log['content'],\n",
    "                    log['mcp_metadata']['persona'],\n",
    "                    log['mcp_metadata']['timestamp'],\n",
    "                    log['mcp_metadata'].get('task_context'),\n",
    "                    log['mcp_metadata'].get('severity', 'info'),\n",
    "                    json.dumps(log['mcp_metadata'].get('metrics', {})),\n",
    "                    log['mcp_metadata'].get('related_systems', []),\n",
    "                    log['mcp_metadata'].get('temporal_marker'),\n",
    "                    embedding\n",
    "                ))\n",
    "    \n",
    "    print(\"‚úÖ Data loading complete\")\n",
    "    print(\"   Each log now has both text content and semantic embedding\")\n",
    "\n",
    "# Load subset for workshop speed (in production, load all)\n",
    "print(\"üìù Note: Loading first 50 logs for workshop speed\")\n",
    "print(\"   In production, you'd load all historical data\")\n",
    "load_incident_data(conn, incident_logs[:50], batch_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Optimized Search Indexes\n",
    "### Why Each Index Type:\n",
    "- HNSW: Graph-based index for fast vector similarity (10-100x faster than brute force)\n",
    "- GIN Trigram: Inverted index for fuzzy text matching\n",
    "- GIN FTS: Full-text search for exact phrase matching\n",
    "- B-tree: Standard indexes for filtering and sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_search_indexes(conn):\n",
    "    \"\"\"\n",
    "    Create all necessary indexes for production-grade hybrid search\n",
    "    \n",
    "    Index tuning parameters:\n",
    "    - HNSW m=16: Number of connections per node (higher = better quality, more memory)\n",
    "    - HNSW ef_construction=64: Build-time accuracy (higher = better quality, slower build)\n",
    "    - GIN: Best for text pattern matching and JSONB queries\n",
    "    \"\"\"\n",
    "    print(\"üî® Creating search indexes...\")\n",
    "    print(\"   This is a one-time operation that dramatically improves search speed\")\n",
    "    \n",
    "    with conn.cursor() as cur:\n",
    "        # Vector similarity index using HNSW algorithm\n",
    "        print(\"  Creating vector index (HNSW)...\")\n",
    "        print(\"    ‚Üí Enables sub-100ms semantic searches\")\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE INDEX IF NOT EXISTS idx_logs_embedding\n",
    "            ON incident_logs\n",
    "            USING hnsw (content_embedding vector_cosine_ops)\n",
    "            WITH (m = 16, ef_construction = 64);\n",
    "        \"\"\")\n",
    "        \n",
    "        # Trigram index for fuzzy text search\n",
    "        print(\"  Creating trigram index...\")\n",
    "        print(\"    ‚Üí Enables typo-tolerant searches\")\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE INDEX IF NOT EXISTS idx_logs_content_trgm\n",
    "            ON incident_logs\n",
    "            USING gin(content gin_trgm_ops);\n",
    "        \"\"\")\n",
    "        \n",
    "        # Traditional full-text search index\n",
    "        print(\"  Creating full-text search index...\")\n",
    "        print(\"    ‚Üí Enables exact phrase matching\")\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE INDEX IF NOT EXISTS idx_logs_fts\n",
    "            ON incident_logs\n",
    "            USING gin(to_tsvector('english', content));\n",
    "        \"\"\")\n",
    "        \n",
    "        # Indexes for filtering (critical for MCP-style contextual search)\n",
    "        print(\"  Creating filter indexes...\")\n",
    "        print(\"    ‚Üí Enables fast filtering by team, time, and severity\")\n",
    "        cur.execute(\"CREATE INDEX IF NOT EXISTS idx_logs_timestamp ON incident_logs(timestamp);\")\n",
    "        cur.execute(\"CREATE INDEX IF NOT EXISTS idx_logs_persona ON incident_logs(persona);\")\n",
    "        cur.execute(\"CREATE INDEX IF NOT EXISTS idx_logs_severity ON incident_logs(severity);\")\n",
    "        \n",
    "        # Update table statistics for query planner\n",
    "        cur.execute(\"ANALYZE incident_logs;\")\n",
    "        \n",
    "    print(\"‚úÖ All indexes created successfully\")\n",
    "    print(\"   Your database is now optimized for hybrid search!\")\n",
    "\n",
    "# Create the indexes\n",
    "create_search_indexes(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 6: Implementing and Comparing Search Methods\n",
    "\n",
    "### The Three Search Methods and When Each Excels\n",
    "\n",
    "**1. Trigram Search (Fuzzy Matching)**\n",
    "- ‚úÖ Best for: Typos, abbreviations, partial matches\n",
    "- ‚ùå Weakness: Misses conceptually similar content\n",
    "- üìä Example: \"db perf\" finds \"database performance\"\n",
    "\n",
    "**2. Semantic Search (Conceptual Similarity)**\n",
    "- ‚úÖ Best for: Finding related concepts, understanding context\n",
    "- ‚ùå Weakness: Misses exact metrics or specific terms\n",
    "- üìä Example: \"slow queries\" finds \"high latency database operations\"\n",
    "\n",
    "**3. Full-Text Search (Exact Terms)**\n",
    "- ‚úÖ Best for: Exact phrases, specific error messages\n",
    "- ‚ùå Weakness: Too rigid, misses variations\n",
    "- üìä Example: Only finds exact match of \"ConnectionPoolExhaustedException\"\n",
    "\n",
    "Let's see them in action to understand why we need all three!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Three Search Methods\n",
    "# Each method has different strengths - let's see them in action\n",
    "\n",
    "def trigram_search(query, conn, limit=5):\n",
    "    \"\"\"\n",
    "    Trigram-based fuzzy text search\n",
    "    \n",
    "    Use cases:\n",
    "    - Finding logs despite typos made during incidents\n",
    "    - Matching abbreviations to full terms\n",
    "    - Discovering partial matches\n",
    "    \n",
    "    Threshold of 0.1 is lenient - adjust based on your needs\n",
    "    \"\"\"\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT\n",
    "                doc_id,\n",
    "                content,\n",
    "                persona,\n",
    "                timestamp,\n",
    "                severity,\n",
    "                similarity(%s, content) as score\n",
    "            FROM incident_logs\n",
    "            WHERE similarity(%s, content) > 0.1  -- Adjust threshold as needed\n",
    "            ORDER BY score DESC\n",
    "            LIMIT %s;\n",
    "        \"\"\", (query, query, limit))\n",
    "        \n",
    "        return cur.fetchall()\n",
    "\n",
    "def semantic_search(query, conn, limit=5):\n",
    "    \"\"\"\n",
    "    Semantic search using vector similarity\n",
    "    \n",
    "    Use cases:\n",
    "    - Finding conceptually related incidents\n",
    "    - Discovering patterns described differently\n",
    "    - Cross-team correlation (same issue, different terminology)\n",
    "    \n",
    "    Uses cosine distance (<=>) for similarity\n",
    "    \"\"\"\n",
    "    # Generate query embedding with 'search_query' type\n",
    "    # This is different from 'search_document' used during indexing!\n",
    "    query_embedding = generate_embedding(query, input_type='search_query')\n",
    "    \n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT\n",
    "                doc_id,\n",
    "                content,\n",
    "                persona,\n",
    "                timestamp,\n",
    "                severity,\n",
    "                1 - (content_embedding <=> %s::vector) as score\n",
    "            FROM incident_logs\n",
    "            WHERE content_embedding IS NOT NULL\n",
    "            ORDER BY content_embedding <=> %s::vector  -- Order by distance\n",
    "            LIMIT %s;\n",
    "        \"\"\", (query_embedding, query_embedding, limit))\n",
    "        \n",
    "        return cur.fetchall()\n",
    "\n",
    "def fulltext_search(query, conn, limit=5):\n",
    "    \"\"\"\n",
    "    Traditional PostgreSQL full-text search\n",
    "    \n",
    "    Use cases:\n",
    "    - Finding exact error messages\n",
    "    - Searching for specific metric names\n",
    "    - Locating precise configuration values\n",
    "    \n",
    "    Uses stemming and stop word removal\n",
    "    \"\"\"\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT\n",
    "                doc_id,\n",
    "                content,\n",
    "                persona,\n",
    "                timestamp,\n",
    "                severity,\n",
    "                ts_rank_cd(to_tsvector('english', content),\n",
    "                          plainto_tsquery('english', %s)) as score\n",
    "            FROM incident_logs\n",
    "            WHERE to_tsvector('english', content) @@ plainto_tsquery('english', %s)\n",
    "            ORDER BY score DESC\n",
    "            LIMIT %s;\n",
    "        \"\"\", (query, query, limit))\n",
    "        \n",
    "        return cur.fetchall()\n",
    "\n",
    "# Compare search methods with a real-world query\n",
    "test_query = \"database performance issues\"\n",
    "print(f\"üîç Testing query: '{test_query}'\")\n",
    "print(f\"   This is a common search during incident investigation\\n\")\n",
    "\n",
    "# Trigram search results\n",
    "print(\"1Ô∏è‚É£ TRIGRAM SEARCH (Fuzzy Matching):\")\n",
    "print(\"-\" * 60)\n",
    "trgm_results = trigram_search(test_query, conn, limit=3)\n",
    "if trgm_results:\n",
    "    for doc_id, content, persona, timestamp, severity, score in trgm_results:\n",
    "        print(f\"[{persona}] Score: {score:.3f}\")\n",
    "        print(f\"   {content[:100]}...\\n\")\n",
    "else:\n",
    "    print(\"No fuzzy matches found\\n\")\n",
    "\n",
    "# Semantic search results\n",
    "print(\"\\n2Ô∏è‚É£ SEMANTIC SEARCH (Conceptual Similarity):\")\n",
    "print(\"-\" * 60)\n",
    "sem_results = semantic_search(test_query, conn, limit=3)\n",
    "if sem_results:\n",
    "    for doc_id, content, persona, timestamp, severity, score in sem_results:\n",
    "        print(f\"[{persona}] Score: {score:.3f}\")\n",
    "        print(f\"   {content[:100]}...\\n\")\n",
    "else:\n",
    "    print(\"No semantic matches found\\n\")\n",
    "\n",
    "# Full-text search results\n",
    "print(\"\\n3Ô∏è‚É£ FULL-TEXT SEARCH (Exact Terms):\")\n",
    "print(\"-\" * 60)\n",
    "fts_results = fulltext_search(test_query, conn, limit=3)\n",
    "if fts_results:\n",
    "    for doc_id, content, persona, timestamp, severity, score in fts_results:\n",
    "        print(f\"[{persona}] Score: {score:.3f}\")\n",
    "        print(f\"   {content[:100]}...\\n\")\n",
    "else:\n",
    "    print(\"No exact matches found\")\n",
    "    print(\"   This is common - exact matching is too restrictive!\")\n",
    "\n",
    "print(\"\\nüí° Notice how each method finds different results!\")\n",
    "print(\"   Hybrid search combines all three for comprehensive coverage.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 7: Building Hybrid Search\n",
    "\n",
    "### The Power of Combination\n",
    "\n",
    "**Why Hybrid Search is Essential:**\n",
    "\n",
    "Imagine searching for \"autovacuum taking too long\":\n",
    "- **Trigram** finds: \"autovacuum process extended\" (text similarity)\n",
    "- **Semantic** finds: \"database maintenance delays\" (conceptual match)\n",
    "- **Full-text** finds: Documents with exact phrase \"autovacuum\"\n",
    "\n",
    "**Combining them surfaces ALL relevant incidents**, regardless of how they were described.\n",
    "\n",
    "### Weight Tuning for Different Scenarios\n",
    "\n",
    "- **Investigation Mode** (Semantic-heavy): Finding all related issues\n",
    "- **Forensics Mode** (Keyword-heavy): Finding specific metrics or errors\n",
    "- **Balanced Mode**: General-purpose search\n",
    "\n",
    "Let's build a system that adapts to your search intent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Hybrid Search\n",
    "# This combines all three methods with configurable weights\n",
    "\n",
    "def hybrid_search(query, conn, weights=None, limit=10):\n",
    "    \"\"\"\n",
    "    Combine semantic, trigram, and full-text search with configurable weights\n",
    "    \n",
    "    Weight configurations for different use cases:\n",
    "    \n",
    "    1. Investigation Mode (semantic-heavy):\n",
    "       - Use when: Exploring related incidents, pattern discovery\n",
    "       - Weights: {'semantic': 0.7, 'trigram': 0.2, 'fulltext': 0.1}\n",
    "    \n",
    "    2. Forensics Mode (keyword-heavy):\n",
    "       - Use when: Finding specific errors, exact metrics\n",
    "       - Weights: {'semantic': 0.2, 'trigram': 0.1, 'fulltext': 0.7}\n",
    "    \n",
    "    3. Balanced Mode (default):\n",
    "       - Use when: General search, unsure of exact terms\n",
    "       - Weights: {'semantic': 0.4, 'trigram': 0.3, 'fulltext': 0.3}\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = {'semantic': 0.4, 'trigram': 0.3, 'fulltext': 0.3}\n",
    "    \n",
    "    # Normalize weights to sum to 1.0\n",
    "    total = sum(weights.values())\n",
    "    weights = {k: v/total for k, v in weights.items()}\n",
    "    \n",
    "    # Get results from all methods (fetch more than needed for better ranking)\n",
    "    semantic_results = semantic_search(query, conn, limit=20)\n",
    "    trigram_results = trigram_search(query, conn, limit=20)\n",
    "    fulltext_results = fulltext_search(query, conn, limit=20)\n",
    "    \n",
    "    # Combine scores using weighted sum\n",
    "    combined_scores = {}\n",
    "    \n",
    "    # Process semantic results\n",
    "    for doc_id, content, persona, timestamp, severity, score in semantic_results:\n",
    "        combined_scores[doc_id] = {\n",
    "            'content': content,\n",
    "            'persona': persona,\n",
    "            'timestamp': timestamp,\n",
    "            'severity': severity,\n",
    "            'semantic_score': score,\n",
    "            'trigram_score': 0,\n",
    "            'fulltext_score': 0,\n",
    "            'combined_score': score * weights['semantic']\n",
    "        }\n",
    "    \n",
    "    # Add trigram scores\n",
    "    for doc_id, content, persona, timestamp, severity, score in trigram_results:\n",
    "        if doc_id in combined_scores:\n",
    "            combined_scores[doc_id]['trigram_score'] = score\n",
    "            combined_scores[doc_id]['combined_score'] += score * weights['trigram']\n",
    "        else:\n",
    "            combined_scores[doc_id] = {\n",
    "                'content': content,\n",
    "                'persona': persona,\n",
    "                'timestamp': timestamp,\n",
    "                'severity': severity,\n",
    "                'semantic_score': 0,\n",
    "                'trigram_score': score,\n",
    "                'fulltext_score': 0,\n",
    "                'combined_score': score * weights['trigram']\n",
    "            }\n",
    "    \n",
    "    # Add full-text scores\n",
    "    for doc_id, content, persona, timestamp, severity, score in fulltext_results:\n",
    "        # Normalize FTS score to 0-1 range\n",
    "        normalized_score = min(score, 1.0)\n",
    "        if doc_id in combined_scores:\n",
    "            combined_scores[doc_id]['fulltext_score'] = normalized_score\n",
    "            combined_scores[doc_id]['combined_score'] += normalized_score * weights['fulltext']\n",
    "        else:\n",
    "            combined_scores[doc_id] = {\n",
    "                'content': content,\n",
    "                'persona': persona,\n",
    "                'timestamp': timestamp,\n",
    "                'severity': severity,\n",
    "                'semantic_score': 0,\n",
    "                'trigram_score': 0,\n",
    "                'fulltext_score': normalized_score,\n",
    "                'combined_score': normalized_score * weights['fulltext']\n",
    "            }\n",
    "    \n",
    "    # Sort by combined score\n",
    "    sorted_results = sorted(\n",
    "        combined_scores.items(),\n",
    "        key=lambda x: x[1]['combined_score'],\n",
    "        reverse=True\n",
    "    )[:limit]\n",
    "    \n",
    "    return sorted_results\n",
    "\n",
    "# Test hybrid search with different configurations\n",
    "test_query = \"connection pool problems\"\n",
    "print(f\"üîç Hybrid Search Query: '{test_query}'\")\n",
    "print(f\"   A common issue that teams describe differently\\n\")\n",
    "\n",
    "# Test different weight configurations\n",
    "weight_configs = [\n",
    "    {'semantic': 0.7, 'trigram': 0.2, 'fulltext': 0.1},  # Investigation mode\n",
    "    {'semantic': 0.2, 'trigram': 0.1, 'fulltext': 0.7},  # Forensics mode\n",
    "    {'semantic': 0.4, 'trigram': 0.3, 'fulltext': 0.3}   # Balanced mode\n",
    "]\n",
    "\n",
    "config_names = ['Investigation Mode (Find Related Issues)', \n",
    "                'Forensics Mode (Find Exact Terms)', \n",
    "                'Balanced Mode (General Search)']\n",
    "\n",
    "for config_name, weights in zip(config_names, weight_configs):\n",
    "    print(f\"\\nüìä {config_name}:\")\n",
    "    print(f\"   Weights: Semantic={weights['semantic']:.1f}, \"\n",
    "          f\"Trigram={weights['trigram']:.1f}, \"\n",
    "          f\"Fulltext={weights['fulltext']:.1f}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    results = hybrid_search(test_query, conn, weights=weights, limit=3)\n",
    "    \n",
    "    for doc_id, result in results:\n",
    "        print(f\"[{result['persona']}] Combined Score: {result['combined_score']:.3f}\")\n",
    "        print(f\"   Component scores: Semantic={result['semantic_score']:.3f}, \"\n",
    "              f\"Trigram={result['trigram_score']:.3f}, \"\n",
    "              f\"FTS={result['fulltext_score']:.3f}\")\n",
    "        print(f\"   {result['content'][:100]}...\\n\")\n",
    "\n",
    "print(\"üí° Key Insight: Different weight configurations surface different results!\")\n",
    "print(\"   Choose weights based on your search intent.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 8: Implementing Cohere Reranking\n",
    "\n",
    "### Why Reranking Matters\n",
    "\n",
    "**The Problem with Simple Score Combination:**\n",
    "- Scores from different methods aren't directly comparable\n",
    "- A high trigram score doesn't equal a high semantic score\n",
    "- Simple weighted averaging can bury the most relevant results\n",
    "\n",
    "**How Reranking Helps:**\n",
    "- Uses a specialized model trained specifically for relevance\n",
    "- Understands the query-document relationship holistically\n",
    "- Can boost results that match user intent, not just keywords\n",
    "\n",
    "**Real-World Impact:**\n",
    "- Improves result relevance by 20-30%\n",
    "- Reduces time to find root cause during incidents\n",
    "- Surfaces insights that simple scoring misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Reranking with Cohere via Bedrock\n",
    "# This adds intelligence beyond simple score combination\n",
    "\n",
    "def rerank_results(query, search_results, limit=5):\n",
    "    \"\"\"\n",
    "    Rerank search results using Cohere Rerank v3.5 via Bedrock\n",
    "    \n",
    "    Why reranking improves results:\n",
    "    1. Trained on relevance: Model understands what makes a good match\n",
    "    2. Context-aware: Considers the full query-document relationship\n",
    "    3. Cross-encoder architecture: More accurate than embedding similarity\n",
    "    \n",
    "    When to use reranking:\n",
    "    - User-facing search where relevance is critical\n",
    "    - After hybrid search to refine top results\n",
    "    - When precision matters more than recall\n",
    "    \"\"\"\n",
    "    if not search_results:\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # Initialize Bedrock agent runtime for reranking\n",
    "        bedrock_agent_runtime = boto3.client(\n",
    "            'bedrock-agent-runtime',\n",
    "            region_name='us-west-2'\n",
    "        )\n",
    "        \n",
    "        # Prepare documents for reranking\n",
    "        documents = []\n",
    "        for doc_id, result in search_results:\n",
    "            documents.append({\n",
    "                \"type\": \"INLINE\",\n",
    "                \"inlineDocumentSource\": {\n",
    "                    \"type\": \"TEXT\",\n",
    "                    \"textDocument\": {\n",
    "                        \"text\": result['content']\n",
    "                    }\n",
    "                }\n",
    "            })\n",
    "        \n",
    "        # Call Cohere Rerank for intelligent relevance scoring\n",
    "        modelId = \"cohere.rerank-v3-5:0\"\n",
    "        model_arn = f\"arn:aws:bedrock:us-west-2::foundation-model/{modelId}\"\n",
    "        \n",
    "        response = bedrock_agent_runtime.rerank(\n",
    "            queries=[\n",
    "                {\n",
    "                    \"type\": \"TEXT\",\n",
    "                    \"textQuery\": {\n",
    "                        \"text\": query\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            sources=documents,\n",
    "            rerankingConfiguration={\n",
    "                \"type\": \"BEDROCK_RERANKING_MODEL\",\n",
    "                \"bedrockRerankingConfiguration\": {\n",
    "                    \"numberOfResults\": limit,\n",
    "                    \"modelConfiguration\": {\n",
    "                        \"modelArn\": model_arn\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Map reranked results back to original data\n",
    "        reranked = []\n",
    "        for result in response['results']:\n",
    "            idx = result['index']\n",
    "            doc_id, original_result = search_results[idx]\n",
    "            reranked.append((doc_id, original_result, result['relevanceScore']))\n",
    "        \n",
    "        return reranked\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Reranking failed: {e}\")\n",
    "        print(\"Returning original order with mock scores\")\n",
    "        # Graceful degradation - return original order\n",
    "        return [(doc_id, result, 1.0 - i*0.1) \n",
    "                for i, (doc_id, result) in enumerate(search_results[:limit])]\n",
    "\n",
    "# Demonstrate the power of reranking\n",
    "query = \"autovacuum taking too long\"\n",
    "print(f\"üîç Testing Reranking for: '{query}'\")\n",
    "print(f\"   A specific DBA concern that might be described various ways\\n\")\n",
    "\n",
    "# Get hybrid search results\n",
    "hybrid_results = hybrid_search(query, conn, limit=10)\n",
    "\n",
    "print(\"Before Reranking (Hybrid Search):\")\n",
    "print(\"-\" * 60)\n",
    "for i, (doc_id, result) in enumerate(hybrid_results[:5], 1):\n",
    "    print(f\"{i}. [{result['persona']}] Score: {result['combined_score']:.3f}\")\n",
    "    print(f\"   {result['content'][:80]}...\\n\")\n",
    "\n",
    "# Apply intelligent reranking\n",
    "reranked_results = rerank_results(query, hybrid_results, limit=5)\n",
    "\n",
    "print(\"\\nAfter Reranking (Cohere Intelligence):\")\n",
    "print(\"-\" * 60)\n",
    "for i, (doc_id, result, rerank_score) in enumerate(reranked_results, 1):\n",
    "    print(f\"{i}. [{result['persona']}] Rerank Score: {rerank_score:.3f}\")\n",
    "    print(f\"   {result['content'][:80]}...\\n\")\n",
    "\n",
    "print(\"üí° Notice: Reranking often surfaces different top results!\")\n",
    "print(\"   The model understands relevance beyond simple keyword matching.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 9: MCP-Style Structured Retrieval\n",
    "\n",
    "### Model Context Protocol (MCP) Patterns\n",
    "\n",
    "**What Makes MCP Different:**\n",
    "- Not just searching for relevance, but building structured context\n",
    "- Filters enable precise slicing of your knowledge base\n",
    "- Combines semantic understanding with structured metadata\n",
    "\n",
    "### Real-World MCP Use Cases\n",
    "\n",
    "**1. Persona-Based Context:**\n",
    "- \"What did DBAs observe?\" ‚Üí Filter by persona='dba'\n",
    "- \"Show me developer exceptions\" ‚Üí Filter by persona='developer'\n",
    "\n",
    "**2. Temporal Context Windows:**\n",
    "- \"Last week's issues\" ‚Üí Filter by timestamp range\n",
    "- \"Black Friday incidents\" ‚Üí Filter by specific date range\n",
    "\n",
    "**3. Severity-Based Prioritization:**\n",
    "- \"Critical issues only\" ‚Üí Filter by severity='critical'\n",
    "- \"Warning signs before outage\" ‚Üí Filter by severity='warning'\n",
    "\n",
    "This structured approach enables AI assistants to build rich, contextual understanding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCP-Style Contextual Search Implementation\n",
    "# This enables structured, filter-based retrieval for AI assistants\n",
    "\n",
    "def mcp_contextual_search(query, conn, context_filters=None, weights=None, limit=10):\n",
    "    \"\"\"\n",
    "    MCP-style contextual search with structured filters\n",
    "    \n",
    "    This is how modern AI assistants retrieve context:\n",
    "    1. Semantic search for conceptual relevance\n",
    "    2. Structured filters for precise context\n",
    "    3. Metadata for relationship understanding\n",
    "    \n",
    "    Filter examples for different scenarios:\n",
    "    \n",
    "    1. Team-specific investigation:\n",
    "       context_filters={'persona': 'dba'}\n",
    "       ‚Üí \"Show me what the database team observed\"\n",
    "    \n",
    "    2. Time-bounded analysis:\n",
    "       context_filters={'time_range': (start_date, end_date)}\n",
    "       ‚Üí \"What happened during Black Friday?\"\n",
    "    \n",
    "    3. Severity-based triage:\n",
    "       context_filters={'severity': 'critical'}\n",
    "       ‚Üí \"Show me only critical issues\"\n",
    "    \n",
    "    4. Multi-filter precision:\n",
    "       context_filters={'persona': 'sre', 'severity': 'warning', \n",
    "                       'time_range': (date1, date2)}\n",
    "       ‚Üí \"SRE warnings from last week\"\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = {'semantic': 0.5, 'trigram': 0.3, 'fulltext': 0.2}\n",
    "    \n",
    "    # Build SQL WHERE clauses from filters\n",
    "    where_clauses = []\n",
    "    params = []\n",
    "    \n",
    "    if context_filters:\n",
    "        if 'persona' in context_filters:\n",
    "            where_clauses.append(\"persona = %s\")\n",
    "            params.append(context_filters['persona'])\n",
    "        \n",
    "        if 'time_range' in context_filters:\n",
    "            start, end = context_filters['time_range']\n",
    "            where_clauses.append(\"timestamp BETWEEN %s AND %s\")\n",
    "            params.extend([start, end])\n",
    "        \n",
    "        if 'severity' in context_filters:\n",
    "            where_clauses.append(\"severity = %s\")\n",
    "            params.append(context_filters['severity'])\n",
    "        \n",
    "        if 'task_context' in context_filters:\n",
    "            where_clauses.append(\"task_context = %s\")\n",
    "            params.append(context_filters['task_context'])\n",
    "    \n",
    "    where_clause = \" AND \".join(where_clauses) if where_clauses else \"1=1\"\n",
    "    \n",
    "    # Generate query embedding for semantic component\n",
    "    query_embedding = generate_embedding(query, input_type='search_query')\n",
    "    \n",
    "    combined_scores = {}\n",
    "    \n",
    "    with conn.cursor() as cur:\n",
    "        # Semantic search with MCP filters\n",
    "        cur.execute(f\"\"\"\n",
    "            SELECT\n",
    "                doc_id, content, persona, timestamp, severity,\n",
    "                1 - (content_embedding <=> %s::vector) as score\n",
    "            FROM incident_logs\n",
    "            WHERE {where_clause}\n",
    "                AND content_embedding IS NOT NULL\n",
    "            ORDER BY content_embedding <=> %s::vector\n",
    "            LIMIT 20;\n",
    "        \"\"\", [query_embedding] + params + [query_embedding])\n",
    "        \n",
    "        for doc_id, content, persona, timestamp, severity, score in cur.fetchall():\n",
    "            combined_scores[doc_id] = {\n",
    "                'content': content,\n",
    "                'persona': persona,\n",
    "                'timestamp': timestamp,\n",
    "                'severity': severity,\n",
    "                'score': score * weights['semantic']\n",
    "            }\n",
    "        \n",
    "        # Trigram search with MCP filters\n",
    "        cur.execute(f\"\"\"\n",
    "            SELECT\n",
    "                doc_id, content, persona, timestamp, severity,\n",
    "                similarity(%s, content) as score\n",
    "            FROM incident_logs\n",
    "            WHERE {where_clause}\n",
    "                AND similarity(%s, content) > 0.1\n",
    "            ORDER BY score DESC\n",
    "            LIMIT 20;\n",
    "        \"\"\", [query] + params + [query])\n",
    "        \n",
    "        for doc_id, content, persona, timestamp, severity, score in cur.fetchall():\n",
    "            if doc_id in combined_scores:\n",
    "                combined_scores[doc_id]['score'] += score * weights['trigram']\n",
    "            else:\n",
    "                combined_scores[doc_id] = {\n",
    "                    'content': content,\n",
    "                    'persona': persona,\n",
    "                    'timestamp': timestamp,\n",
    "                    'severity': severity,\n",
    "                    'score': score * weights['trigram']\n",
    "                }\n",
    "    \n",
    "    # Sort and return structured results\n",
    "    sorted_results = sorted(\n",
    "        combined_scores.items(),\n",
    "        key=lambda x: x[1]['score'],\n",
    "        reverse=True\n",
    "    )[:limit]\n",
    "    \n",
    "    return sorted_results\n",
    "\n",
    "# Demonstrate MCP patterns for different use cases\n",
    "print(\"üéØ MCP-Style Contextual Search Examples\")\n",
    "print(\"   This is how AI assistants build structured context\\n\")\n",
    "\n",
    "# Example 1: Team-specific observations\n",
    "print(\"1Ô∏è‚É£ DBA Team Perspective on Database Issues:\")\n",
    "print(\"-\" * 60)\n",
    "results = mcp_contextual_search(\n",
    "    \"database performance problems\",\n",
    "    conn,\n",
    "    context_filters={'persona': 'dba'},\n",
    "    limit=3\n",
    ")\n",
    "print(f\"Found {len(results)} DBA observations:\")\n",
    "for doc_id, result in results:\n",
    "    print(f\"[{result['timestamp'].strftime('%Y-%m-%d')}] Score: {result['score']:.3f}\")\n",
    "    print(f\"   {result['content'][:100]}...\\n\")\n",
    "\n",
    "# Example 2: Critical severity filter\n",
    "print(\"\\n2Ô∏è‚É£ Critical Incidents Only:\")\n",
    "print(\"-\" * 60)\n",
    "results = mcp_contextual_search(\n",
    "    \"outage incident failure\",\n",
    "    conn,\n",
    "    context_filters={'severity': 'critical'},\n",
    "    limit=3\n",
    ")\n",
    "if results:\n",
    "    print(f\"Found {len(results)} critical incidents:\")\n",
    "    for doc_id, result in results:\n",
    "        print(f\"[{result['persona']}] {result['timestamp'].strftime('%Y-%m-%d %H:%M')}\")\n",
    "        print(f\"   {result['content'][:100]}...\\n\")\n",
    "else:\n",
    "    print(\"   No critical issues found (good news!)\")\n",
    "    print(\"   In production, you'd have more historical data\")\n",
    "\n",
    "print(\"\\nüí° MCP Pattern Benefits:\")\n",
    "print(\"   ‚Ä¢ Precise context building for AI assistants\")\n",
    "print(\"   ‚Ä¢ Structured retrieval beyond simple relevance\")\n",
    "print(\"   ‚Ä¢ Enables persona-aware and time-aware AI responses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 10: Building Your Black Friday Playbook\n",
    "\n",
    "### From Historical Data to Proactive Monitoring\n",
    "\n",
    "**The Goal:** Transform past incidents into future prevention\n",
    "\n",
    "**What We're Building:**\n",
    "1. **Pattern Recognition**: Identify recurring issues across teams\n",
    "2. **Early Warning Signs**: Find patterns that precede outages\n",
    "3. **Monitoring Queries**: Create searches that catch issues early\n",
    "4. **Team Playbooks**: Document what each team should watch for\n",
    "\n",
    "**Why This Matters:**\n",
    "- Last year's \"surprise\" outage had warning signs 3 days earlier\n",
    "- Different teams saw different symptoms but didn't connect them\n",
    "- With hybrid search, we can surface these patterns proactively\n",
    "\n",
    "Let's mine your historical data for Black Friday insights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing Historical Patterns for Peak Event Preparation\n",
    "# This discovers what issues tend to occur and when\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def analyze_patterns(conn, time_window, min_severity='warning'):\n",
    "    \"\"\"\n",
    "    Analyze patterns in historical data to identify early warning signs\n",
    "    \n",
    "    Pattern categories:\n",
    "    - Database: Performance degradation patterns\n",
    "    - Infrastructure: Resource exhaustion signals\n",
    "    - Application: Error rate increases\n",
    "    - Data Pipeline: Processing delays\n",
    "    \n",
    "    This helps answer:\n",
    "    - What issues have we seen before?\n",
    "    - Which patterns precede critical incidents?\n",
    "    - What should each team monitor?\n",
    "    \"\"\"\n",
    "    # Define pattern keywords for each category\n",
    "    # These are based on common incident patterns\n",
    "    patterns = {\n",
    "        'database': [\n",
    "            'slow query', 'high latency', 'connection pool', \n",
    "            'deadlock', 'timeout', 'lock contention', 'autovacuum'\n",
    "        ],\n",
    "        'infrastructure': [\n",
    "            'cpu spike', 'memory pressure', 'disk space', \n",
    "            'network latency', 'load average', 'swap usage'\n",
    "        ],\n",
    "        'application': [\n",
    "            'error rate', 'exception', 'failed request', \n",
    "            'retry storm', 'circuit breaker', 'timeout'\n",
    "        ],\n",
    "        'data_pipeline': [\n",
    "            'etl delay', 'batch failure', 'data lag', \n",
    "            'processing backlog', 'queue depth', 'throughput'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    findings = {}\n",
    "    \n",
    "    print(\"üîç Searching for patterns in each category...\")\n",
    "    \n",
    "    for category, keywords in patterns.items():\n",
    "        category_issues = []\n",
    "        \n",
    "        # Search for each pattern\n",
    "        for keyword in keywords:\n",
    "            results = mcp_contextual_search(\n",
    "                keyword,\n",
    "                conn,\n",
    "                context_filters={'time_range': time_window},\n",
    "                limit=5\n",
    "            )\n",
    "            \n",
    "            if results:\n",
    "                category_issues.extend(results)\n",
    "        \n",
    "        # Deduplicate and keep highest scoring instances\n",
    "        unique_issues = {}\n",
    "        for doc_id, result in category_issues:\n",
    "            if doc_id not in unique_issues or result['score'] > unique_issues[doc_id]['score']:\n",
    "                unique_issues[doc_id] = result\n",
    "        \n",
    "        findings[category] = list(unique_issues.values())\n",
    "    \n",
    "    return findings\n",
    "\n",
    "# Analyze last year's Black Friday period\n",
    "print(\"üìä Analyzing Historical Black Friday Patterns\")\n",
    "print(\"   Looking for issues from November 20-30, 2024\\n\")\n",
    "\n",
    "black_friday_2024 = (\n",
    "    datetime(2024, 11, 20),  # Week before Black Friday\n",
    "    datetime(2024, 11, 30)   # Day after Black Friday\n",
    ")\n",
    "\n",
    "pattern_analysis = analyze_patterns(conn, black_friday_2024)\n",
    "\n",
    "# Display findings by category\n",
    "for category, issues in pattern_analysis.items():\n",
    "    if issues:\n",
    "        print(f\"\\nüîç {category.upper().replace('_', ' ')} PATTERNS:\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Show top issues with insights\n",
    "        for issue in issues[:2]:  # Show top 2 per category\n",
    "            severity_icon = \"üî¥\" if issue['severity'] == 'critical' else \"üü°\" if issue['severity'] == 'warning' else \"üü¢\"\n",
    "            print(f\"{severity_icon} [{issue['persona']}] {issue['timestamp'].strftime('%m/%d %H:%M')}\")\n",
    "            print(f\"   {issue['content'][:100]}...\")\n",
    "        \n",
    "        # Provide actionable insight\n",
    "        if category == 'database':\n",
    "            print(\"   ‚Üí Action: Monitor query performance and connection pools\")\n",
    "        elif category == 'infrastructure':\n",
    "            print(\"   ‚Üí Action: Set up resource utilization alerts\")\n",
    "        elif category == 'application':\n",
    "            print(\"   ‚Üí Action: Implement circuit breakers and retry limits\")\n",
    "        elif category == 'data_pipeline':\n",
    "            print(\"   ‚Üí Action: Add pipeline lag monitoring\")\n",
    "        print()\n",
    "\n",
    "print(\"\\nüí° Key Insight: These patterns often appear 24-48 hours before major incidents!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Proactive Monitoring Queries\n",
    "### Transform discovered patterns into actionable monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_monitoring_queries(patterns):\n",
    "    \"\"\"\n",
    "    Generate monitoring queries based on discovered patterns\n",
    "    \n",
    "    Creates specific queries that operations teams can use\n",
    "    to detect issues before they become critical\n",
    "    \"\"\"\n",
    "    monitoring_playbook = []\n",
    "    \n",
    "    # Analyze patterns to create proactive queries\n",
    "    critical_patterns = {\n",
    "        'autovacuum': {\n",
    "            'query': 'autovacuum long running locks',\n",
    "            'interval': '5 minutes',\n",
    "            'threshold': 0.7,\n",
    "            'team': 'DBA',\n",
    "            'action': 'Check table bloat and vacuum settings'\n",
    "        },\n",
    "        'connection pool': {\n",
    "            'query': 'connection pool exhausted timeout',\n",
    "            'interval': '2 minutes',\n",
    "            'threshold': 0.8,\n",
    "            'team': 'SRE',\n",
    "            'action': 'Scale connection pools or add read replicas'\n",
    "        },\n",
    "        'performance': {\n",
    "            'query': 'query latency slow response degradation',\n",
    "            'interval': '5 minutes',\n",
    "            'threshold': 0.6,\n",
    "            'team': 'Developer',\n",
    "            'action': 'Review slow query log and optimize'\n",
    "        },\n",
    "        'etl': {\n",
    "            'query': 'etl pipeline delay backlog processing',\n",
    "            'interval': '10 minutes',\n",
    "            'threshold': 0.7,\n",
    "            'team': 'Data Engineer',\n",
    "            'action': 'Check data freshness and pipeline health'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Extract patterns from analysis\n",
    "    for category, issues in patterns.items():\n",
    "        for issue in issues:\n",
    "            content_lower = issue['content'].lower()\n",
    "            \n",
    "            # Match against critical patterns\n",
    "            for pattern_key, pattern_config in critical_patterns.items():\n",
    "                if pattern_key in content_lower:\n",
    "                    if pattern_config not in monitoring_playbook:\n",
    "                        monitoring_playbook.append(pattern_config)\n",
    "    \n",
    "    # Add default monitors if empty\n",
    "    if not monitoring_playbook:\n",
    "        monitoring_playbook = list(critical_patterns.values())[:2]\n",
    "    \n",
    "    return monitoring_playbook\n",
    "\n",
    "# Generate the monitoring playbook\n",
    "playbook = create_monitoring_queries(pattern_analysis)\n",
    "\n",
    "print(\"üìö YOUR BLACK FRIDAY MONITORING PLAYBOOK\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nProactive Monitoring Strategy:\")\n",
    "print(\"Save these queries and run them continuously during peak events\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i, monitor in enumerate(playbook, 1):\n",
    "    print(f\"\\n{i}. üéØ MONITOR: {monitor['query'].upper()}\")\n",
    "    print(f\"   Team: {monitor['team']}\")\n",
    "    print(f\"   Check Every: {monitor['interval']}\")\n",
    "    print(f\"   Alert if Score > {monitor['threshold']}\")\n",
    "    print(f\"   Action: {monitor['action']}\")\n",
    "    \n",
    "    # Provide implementation example\n",
    "    print(f\"\\n   Implementation:\")\n",
    "    print(f\"   ```python\")\n",
    "    print(f\"   results = hybrid_search('{monitor['query']}', conn)\")\n",
    "    print(f\"   if results[0][1]['combined_score'] > {monitor['threshold']}:\")\n",
    "    print(f\"       alert_team('{monitor['team']}', results)\")\n",
    "    print(f\"   ```\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üí° Pro Tip: Set up these queries in your monitoring system NOW,\")\n",
    "print(\"   before the next peak event. Prevention is better than reaction!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 11: Performance Optimization and Best Practices\n",
    "\n",
    "### Understanding Search Performance Trade-offs\n",
    "\n",
    "**Performance Characteristics:**\n",
    "- **Trigram Search**: Fastest (~1-5ms) but limited to text similarity\n",
    "- **Full-text Search**: Fast (~5-10ms) but rigid matching\n",
    "- **Semantic Search**: Slower (~50-200ms) but best understanding\n",
    "- **Hybrid Search**: Combines all (~100-300ms) for best results\n",
    "\n",
    "**Optimization Strategies:**\n",
    "1. **Use appropriate search for the query type** (not everything needs semantic)\n",
    "2. **Cache embeddings** to avoid regeneration\n",
    "3. **Tune index parameters** based on your dataset size\n",
    "4. **Implement result caching** for common queries\n",
    "\n",
    "Let's measure and optimize your search performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Benchmarking for Production Optimization\n",
    "# Understanding these metrics helps you choose the right search strategy\n",
    "\n",
    "import time\n",
    "\n",
    "def benchmark_search_methods(query, conn, iterations=5):\n",
    "    \"\"\"\n",
    "    Benchmark different search methods for performance comparison\n",
    "    \n",
    "    Why measure performance:\n",
    "    - Different queries have different performance needs\n",
    "    - Real-time search needs <100ms response\n",
    "    - Batch analysis can tolerate slower but more accurate search\n",
    "    \n",
    "    Performance expectations:\n",
    "    - Interactive search: <100ms\n",
    "    - Background analysis: <1000ms\n",
    "    - Batch processing: Can be slower for better accuracy\n",
    "    \"\"\"\n",
    "    methods = {\n",
    "        'Trigram Search': lambda: trigram_search(query, conn),\n",
    "        'Semantic Search': lambda: semantic_search(query, conn),\n",
    "        'Full-text Search': lambda: fulltext_search(query, conn),\n",
    "        'Hybrid Search': lambda: hybrid_search(query, conn)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    print(f\"Running {iterations} iterations per method...\")\n",
    "    print(\"(First run may be slower due to cold cache)\\n\")\n",
    "    \n",
    "    for method_name, method_func in methods.items():\n",
    "        times = []\n",
    "        for i in range(iterations):\n",
    "            start = time.time()\n",
    "            method_func()\n",
    "            elapsed = time.time() - start\n",
    "            times.append(elapsed * 1000)  # Convert to milliseconds\n",
    "        \n",
    "        results[method_name] = {\n",
    "            'avg_ms': np.mean(times),\n",
    "            'min_ms': np.min(times),\n",
    "            'max_ms': np.max(times),\n",
    "            'std_ms': np.std(times),\n",
    "            'p95_ms': np.percentile(times, 95)\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run performance benchmarks\n",
    "print(\"‚ö° Performance Benchmarks for Production Planning\\n\")\n",
    "query = \"database performance issues\"\n",
    "print(f\"Test Query: '{query}'\")\n",
    "\n",
    "benchmarks = benchmark_search_methods(query, conn, iterations=5)\n",
    "\n",
    "# Display results with insights\n",
    "print(\"\\nüìä Performance Results (in milliseconds):\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Method':<20} {'Avg':<10} {'Min':<10} {'Max':<10} {'P95':<10} {'Std Dev':<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for method, stats in benchmarks.items():\n",
    "    # Color code based on performance\n",
    "    avg_ms = stats['avg_ms']\n",
    "    \n",
    "    print(f\"{method:<20} {avg_ms:<10.2f} {stats['min_ms']:<10.2f} \"\n",
    "          f\"{stats['max_ms']:<10.2f} {stats['p95_ms']:<10.2f} {stats['std_ms']:<10.2f}\")\n",
    "    \n",
    "    # Provide performance guidance\n",
    "    if avg_ms < 10:\n",
    "        print(f\"                     ‚úÖ Excellent for real-time search\")\n",
    "    elif avg_ms < 100:\n",
    "        print(f\"                     ‚úÖ Good for interactive search\")\n",
    "    elif avg_ms < 500:\n",
    "        print(f\"                     ‚ö†Ô∏è  Acceptable for background search\")\n",
    "    else:\n",
    "        print(f\"                     ‚ö†Ô∏è  Consider optimization or caching\")\n",
    "\n",
    "# Identify optimal method\n",
    "fastest = min(benchmarks.items(), key=lambda x: x[1]['avg_ms'])\n",
    "most_stable = min(benchmarks.items(), key=lambda x: x[1]['std_ms'])\n",
    "\n",
    "print(f\"\\nüèÜ Performance Summary:\")\n",
    "print(f\"   Fastest: {fastest[0]} ({fastest[1]['avg_ms']:.2f}ms average)\")\n",
    "print(f\"   Most Stable: {most_stable[0]} ({most_stable[1]['std_ms']:.2f}ms std dev)\")\n",
    "\n",
    "print(\"\\nüí° Optimization Recommendations:\")\n",
    "print(\"   1. Use Trigram for typo-tolerant autocomplete (<10ms)\")\n",
    "print(\"   2. Use Semantic for investigation and discovery\")\n",
    "print(\"   3. Use Hybrid for critical searches where accuracy matters\")\n",
    "print(\"   4. Implement caching for frequently searched queries\")\n",
    "print(\"   5. Consider async processing for non-interactive searches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: Your Peak Event Intelligence System\n",
    "\n",
    "### üéâ Congratulations! You've Built:\n",
    "\n",
    "**A Production-Ready Hybrid Search System** that combines:\n",
    "- **PostgreSQL Trigram Search** for fuzzy matching and typo tolerance\n",
    "- **pgvector Semantic Search** for conceptual understanding\n",
    "- **Cohere Embeddings and Reranking** for state-of-the-art relevance\n",
    "- **MCP-style Structured Retrieval** for precise context building\n",
    "\n",
    "### üéØ Your Black Friday Playbook Includes:\n",
    "\n",
    "1. **Pattern Recognition**: Mine historical data for recurring issues\n",
    "2. **Cross-Team Correlation**: Connect symptoms across different perspectives\n",
    "3. **Proactive Monitoring**: Queries that catch issues before they escalate\n",
    "4. **Optimized Search Strategies**: Right method for each query type\n",
    "\n",
    "### üí° Key Takeaways:\n",
    "\n",
    "**Why Different Personas Matter:**\n",
    "- DBAs see database internals others miss\n",
    "- SREs catch service-level degradation\n",
    "- Developers spot application-layer issues\n",
    "- Data Engineers notice pipeline problems\n",
    "- **Your search system connects all these perspectives!**\n",
    "\n",
    "**Why Hybrid Search Wins:**\n",
    "- No single search method handles all queries well\n",
    "- Trigrams catch typos, semantic understands concepts, full-text finds exact terms\n",
    "- Combining them surfaces insights impossible with any single approach\n",
    "\n",
    "### üìö Take-Home Resources:\n",
    "\n",
    "- Complete hybrid search implementation\n",
    "- Production-ready query templates\n",
    "- Performance optimization strategies\n",
    "- MCP pattern implementations\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "\n",
    "1. **Deploy This System**: Use these patterns in your production environment\n",
    "2. **Customize Weights**: Tune for your specific use cases\n",
    "3. **Expand Personas**: Add more team perspectives\n",
    "4. **Build Dashboards**: Visualize patterns and trends\n",
    "5. **Share Knowledge**: Help other teams implement hybrid search\n",
    "\n",
    "### üèÜ You're Now Equipped To:\n",
    "\n",
    "- Prevent outages by finding patterns others miss\n",
    "- Reduce MTTR by quickly finding relevant historical incidents\n",
    "- Build AI assistants with rich, structured context\n",
    "- Scale your incident knowledge across all teams\n",
    "\n",
    "### Remember:\n",
    "\n",
    "**\"The best time to prepare for Black Friday is 364 days before Black Friday.\"**\n",
    "\n",
    "Your hybrid search system makes every day a learning opportunity,\n",
    "turning past incidents into future resilience.\n",
    "\n",
    "Thank you for participating in this workshop!\n",
    "\n",
    "**#reInvent2025 #HybridSearch #AuroraPostgreSQL #MCP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workshop Cleanup\n",
    "print(\"üßπ Cleaning up resources...\\n\")\n",
    "\n",
    "try:\n",
    "    # Close database connection\n",
    "    conn.close()\n",
    "    print(\"‚úÖ Database connection closed\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nüëã Thank you for participating in DAT409!\")\n",
    "print(\"\\nüåü Please rate this session in the re:Invent mobile app\")\n",
    "print(\"   Your feedback helps us improve future workshops\")\n",
    "print(\"\\nüìß Questions? Find us at the Builder's Fair or contact:\")\n",
    "print(\"   AWS Database Specialists Team\")\n",
    "print(\"\\nüöÄ Now go build amazing search experiences!\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
