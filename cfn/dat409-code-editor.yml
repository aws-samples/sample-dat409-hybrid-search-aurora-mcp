AWSTemplateFormatVersion: '2010-09-09'
Description: 'DAT409 - Code Editor with Automated Database Setup'

Parameters:
  TemplateName:
    Type: String
    Description: Template name prefix for resources
    
  CodeEditorUser:
    Type: String
    Default: participant
    Description: Username for Code Editor
    
  InstanceName:
    Type: String
    Description: Instance name
    
  InstanceVolumeSize:
    Type: Number
    Default: 50
    Description: Volume size in GB
    
  InstanceType:
    Type: String
    Default: t4g.large
    Description: EC2 instance type
    
  InstanceOperatingSystem:
    Type: String
    Default: AmazonLinux-2023
    Description: Operating system
    
  HomeFolder:
    Type: String
    Default: /workshop
    Description: Working directory
    
  RepoUrl:
    Type: String
    Default: https://github.com/aws-samples/sample-dat409-hybrid-search-aurora-mcp.git
    Description: GitHub repository URL
    
  BootstrapScriptUrl:
    Type: String
    Default: https://raw.githubusercontent.com/aws-samples/sample-dat409-hybrid-search-aurora-mcp/main/scripts/bootstrap-code-editor.sh
    Description: URL to the bootstrap script
    
  VPCId:
    Type: String
    Description: VPC ID
    
  SubnetId:
    Type: String
    Description: Subnet ID
    
  VpcCIDR:
    Type: String
    Description: VPC CIDR
    
  DBSecretArn:
    Type: String
    Description: Database secret ARN
    
  DBClusterEndpoint:
    Type: String
    Description: Database endpoint
    
  DBClusterArn:
    Type: String
    Description: Database cluster ARN for Data API
    
  DBName:
    Type: String
    Default: workshop_db
    Description: Database name
  
  PythonVersion:
    Type: String
    Default: "3.13"
    Description: Python version

  PostgreSQLVersion:
    Type: String
    Default: "17.5"
    Description: PostgreSQL version

Conditions:
  IsGraviton: !Or
    - !Equals [!Select [0, !Split ['.', !Ref InstanceType]], 't4g']
    - !Equals [!Select [0, !Split ['.', !Ref InstanceType]], 'c6g']
    - !Equals [!Select [0, !Split ['.', !Ref InstanceType]], 'm6g']
    - !Equals [!Select [0, !Split ['.', !Ref InstanceType]], 'r6g']

Mappings:
  ArmImage:
    AmazonLinux-2023:
      ImageId: '{{resolve:ssm:/aws/service/ami-amazon-linux-latest/al2023-ami-kernel-default-arm64}}'
  AmdImage:
    AmazonLinux-2023:
      ImageId: '{{resolve:ssm:/aws/service/ami-amazon-linux-latest/al2023-ami-kernel-default-x86_64}}'
  AWSRegionsPrefixListID:
    us-east-1:
      PrefixList: pl-3b927c52
    us-east-2:
      PrefixList: pl-b6a144df
    us-west-1:
      PrefixList: pl-4ea04527
    us-west-2:
      PrefixList: pl-82a045eb
    eu-west-1:
      PrefixList: pl-4fa04526
    eu-central-1:
      PrefixList: pl-a3a144ca
    ap-southeast-1:
      PrefixList: pl-31a34658
    ap-southeast-2:
      PrefixList: pl-b8a742d1
    ap-northeast-1:
      PrefixList: pl-58a04531

Resources:
  # Code Editor Secret
  CodeEditorSecret:
    Type: AWS::SecretsManager::Secret
    DeletionPolicy: Delete
    UpdateReplacePolicy: Delete
    Properties:
      Name: !Sub
        - ${InstanceName}-${RandomGUID}
        - RandomGUID: !Select [0, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId ]]]]
      Description: Code Editor user credentials
      GenerateSecretString:
        PasswordLength: 16
        SecretStringTemplate: !Sub '{"username":"${CodeEditorUser}"}'
        GenerateStringKey: 'password'
        ExcludePunctuation: true

  # Lambda for extracting secret
  SecretPlaintextLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: SecretAccess
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action: secretsmanager:GetSecretValue
                Resource: !Ref CodeEditorSecret

  SecretPlaintextLambda:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.lambda_handler
      Runtime: python3.13
      Role: !GetAtt SecretPlaintextLambdaRole.Arn
      Code:
        ZipFile: |
          import boto3
          import json
          import cfnresponse
          def lambda_handler(event, context):
              try:
                  if event['RequestType'] == 'Delete':
                      cfnresponse.send(event, context, cfnresponse.SUCCESS, {})
                      return
                  client = boto3.client('secretsmanager')
                  response = client.get_secret_value(SecretId=event['ResourceProperties']['SecretArn'])
                  secret = json.loads(response['SecretString'])
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, secret, noEcho=True)
              except Exception as e:
                  cfnresponse.send(event, context, cfnresponse.FAILED, {}, str(e))

  SecretPlaintext:
    Type: Custom::SecretPlaintextLambda
    Properties:
      ServiceToken: !GetAtt SecretPlaintextLambda.Arn
      SecretArn: !Ref CodeEditorSecret

  # Security Group
  SecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: !Sub '${TemplateName} Code Editor security group'
      VpcId: !Ref VPCId
      SecurityGroupIngress:
        - Description: CloudFront access
          IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          SourcePrefixListId: !FindInMap [AWSRegionsPrefixListID, !Ref 'AWS::Region', PrefixList]
        - Description: VPC access for HTTP
          IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: !Ref VpcCIDR
      SecurityGroupEgress:
        - Description: Allow all outbound
          IpProtocol: -1
          CidrIp: 0.0.0.0/0

  # IAM Role
  CodeEditorRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: [ec2.amazonaws.com, ssm.amazonaws.com]
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore
        - arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy
        - arn:aws:iam::aws:policy/AmazonBedrockFullAccess
        - arn:aws:iam::aws:policy/AmazonQDeveloperAccess
      Policies:
        - PolicyName: WorkshopAccess
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - secretsmanager:GetSecretValue
                Resource:
                  - !Ref CodeEditorSecret
                  - !Ref DBSecretArn
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:ListBucket
                Resource: '*'
              - Effect: Allow
                Action:
                  - rds:DescribeDBClusters
                  - rds:DescribeDBInstances
                Resource: '*'
              - Effect: Allow
                Action:
                  - rds-data:BeginTransaction
                  - rds-data:CommitTransaction
                  - rds-data:ExecuteStatement
                  - rds-data:RollbackTransaction
                  - rds-data:BatchExecuteStatement
                Resource: '*'

  CodeEditorInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Roles:
        - !Ref CodeEditorRole

  # CloudWatch Log Groups
  BootstrapLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub '/aws/ec2/${TemplateName}/bootstrap'
      RetentionInDays: 7

  SSMDocumentLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub '/aws/ssm/${TemplateName}-bootstrap'
      RetentionInDays: 7

  # SSM Document with Automated Database Setup
  CodeEditorSSMDoc:
    Type: AWS::SSM::Document
    Properties:
      DocumentType: Command
      Content:
        schemaVersion: '2.2'
        description: DAT409 Code Editor Bootstrap with Automated Database Setup
        parameters:
          CodeEditorPassword:
            type: String
            default: 'defaultPassword'
          BootstrapScriptUrl:
            type: String
            default: !Ref BootstrapScriptUrl
          RepoUrl:
            type: String
            default: !Ref RepoUrl
          HomeFolder:
            type: String
            default: !Ref HomeFolder
          DBSecretArn:
            type: String
            default: !Ref DBSecretArn
          DBClusterEndpoint:
            type: String
            default: !Ref DBClusterEndpoint
          DBClusterArn:
            type: String
            default: !Ref DBClusterArn
          DBName:
            type: String
            default: !Ref DBName
        mainSteps:
          - name: InstallCloudWatchAgent
            action: aws:configurePackage
            inputs:
              name: AmazonCloudWatchAgent
              action: Install

          - name: SetupEnvironment
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 300
              runCommand:
                - '#!/bin/bash'
                - 'set -euo pipefail'
                - !Sub |
                  echo "Setting up environment variables..."
                  dnf update -y
                  export AWS_REGION="${AWS::Region}"
                  export AWS_DEFAULT_REGION="${AWS::Region}"
                  export AWS_ACCOUNTID="${AWS::AccountId}"
                  echo "Environment setup completed"

          - name: RunGitHubBootstrap
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 1200
              runCommand:
                - '#!/bin/bash'
                - 'set -euo pipefail'
                - !Sub |
                  echo "=== DAT409 Bootstrap (Infrastructure Only) ==="
                  echo "Timestamp: $$(date)"
                  
                  export DB_SECRET_ARN="{{ DBSecretArn }}"
                  export DB_CLUSTER_ENDPOINT="{{ DBClusterEndpoint }}"
                  export DB_CLUSTER_ARN="{{ DBClusterArn }}"
                  export DB_NAME="{{ DBName }}"
                  export AWS_REGION="${AWS::Region}"
                  
                  curl -fsSL "{{ BootstrapScriptUrl }}" -o /tmp/bootstrap-code-editor.sh
                  
                  if [ ! -f /tmp/bootstrap-code-editor.sh ]; then
                    echo "ERROR: Failed to download bootstrap script"
                    exit 1
                  fi
                  
                  chmod +x /tmp/bootstrap-code-editor.sh
                  
                  echo "Executing infrastructure bootstrap (no database setup yet)..."
                  DB_SECRET_ARN="{{ DBSecretArn }}" \
                  DB_CLUSTER_ENDPOINT="{{ DBClusterEndpoint }}" \
                  DB_CLUSTER_ARN="{{ DBClusterArn }}" \
                  DB_NAME="{{ DBName }}" \
                  AWS_REGION="${AWS::Region}" \
                  /tmp/bootstrap-code-editor.sh "{{ CodeEditorPassword }}"
                  
                  if [ $$? -eq 0 ]; then
                    echo "âœ… Infrastructure bootstrap completed"
                  else
                    echo "âŒ Bootstrap failed"
                    exit 1
                  fi
                  
                  rm -f /tmp/bootstrap-code-editor.sh

          - name: CloneWorkshopRepository
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 600
              runCommand:
                - '#!/bin/bash'
                - |
                  if [ -n "{{ RepoUrl }}" ]; then
                    echo "Cloning workshop repository..."
                    sudo -u participant git clone "{{ RepoUrl }}" /tmp/workshop_repo
                    
                    if [ -d /tmp/workshop_repo ]; then
                      sudo -u participant cp -r /tmp/workshop_repo/* "{{ HomeFolder }}/" || true
                      sudo -u participant cp -r /tmp/workshop_repo/.[!.]* "{{ HomeFolder }}/" 2>/dev/null || true
                      rm -rf /tmp/workshop_repo
                      
                      # Make setup scripts executable
                      chmod +x "{{ HomeFolder }}/scripts/setup-database.sh" 2>/dev/null || true
                      chmod +x "{{ HomeFolder }}/scripts/verify-setup.sh" 2>/dev/null || true
                      
                      echo "âœ… Repository cloned successfully"
                    else
                      echo "WARNING: Repository clone failed"
                    fi
                  fi

          - name: SetupWorkshopEnvironment
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 600
              runCommand:
                - '#!/bin/bash'
                - !Sub |
                  echo "Setting up workshop environment..."
                  
                  # Retrieve database credentials
                  if [ ! -z "{{ DBSecretArn }}" ]; then
                    DB_SECRET=$$(aws secretsmanager get-secret-value \
                      --secret-id "{{ DBSecretArn }}" \
                      --region ${AWS::Region} \
                      --query SecretString \
                      --output text 2>/dev/null)
                    
                    if [ ! -z "$$DB_SECRET" ]; then
                      DB_HOST=$$(echo "$$DB_SECRET" | jq -r '.host // .endpoint // empty')
                      DB_PORT=$$(echo "$$DB_SECRET" | jq -r '.port // "5432"')
                      DB_NAME=$$(echo "$$DB_SECRET" | jq -r '.dbname // .database // empty')
                      DB_USER=$$(echo "$$DB_SECRET" | jq -r '.username // .user // empty')
                      DB_PASSWORD=$$(echo "$$DB_SECRET" | jq -r '.password // empty')
                      
                      if [ -z "$$DB_HOST" ]; then
                        DB_HOST="{{ DBClusterEndpoint }}"
                      fi
                    fi
                  fi
                  
                  # Create .env file
                  sudo -u participant tee "{{ HomeFolder }}/.env" << EOF
                  DB_HOST=$$DB_HOST
                  DB_PORT=$$DB_PORT
                  DB_NAME=$$DB_NAME
                  DB_USER=$$DB_USER
                  DB_PASSWORD=$$DB_PASSWORD
                  DATABASE_URL=postgresql://$$DB_USER:$$DB_PASSWORD@$$DB_HOST:$$DB_PORT/$$DB_NAME
                  DATABASE_SECRET_ARN={{ DBSecretArn }}
                  DATABASE_CLUSTER_ARN={{ DBClusterArn }}
                  AWS_REGION=${AWS::Region}
                  PGHOST=$$DB_HOST
                  PGPORT=$$DB_PORT
                  PGDATABASE=$$DB_NAME
                  PGUSER=$$DB_USER
                  PGPASSWORD=$$DB_PASSWORD
                  EOF
                  
                  chmod 600 "{{ HomeFolder }}/.env"
                  chown participant:participant "{{ HomeFolder }}/.env"
                  
                  # Create .pgpass
                  sudo -u participant bash -c "cat > /home/participant/.pgpass << PGPASS_EOF
                  $$DB_HOST:$$DB_PORT:$$DB_NAME:$$DB_USER:$$DB_PASSWORD
                  $$DB_HOST:$$DB_PORT:*:$$DB_USER:$$DB_PASSWORD
                  *:*:*:$$DB_USER:$$DB_PASSWORD
                  PGPASS_EOF"
                  
                  chmod 600 "/home/participant/.pgpass"
                  chown participant:participant "/home/participant/.pgpass"
                  
                  # Update bashrc
                  cat >> /home/participant/.bashrc << BASHRC_EOF
                  export AWS_REGION="${AWS::Region}"
                  export PATH=\$$PATH:/home/participant/.local/bin
                  
                  alias workshop="cd {{ HomeFolder }}"
                  alias lab1="cd {{ HomeFolder }}/lab1-hybrid-search"
                  alias lab2="cd {{ HomeFolder }}/lab2-mcp-agent"
                  
                  export DB_HOST='$$DB_HOST'
                  export DB_PORT='$$DB_PORT'
                  export DB_NAME='$$DB_NAME'
                  export DB_USER='$$DB_USER'
                  export DB_PASSWORD='$$DB_PASSWORD'
                  export PGHOST='$$DB_HOST'
                  export PGPORT='$$DB_PORT'
                  export PGUSER='$$DB_USER'
                  export PGPASSWORD='$$DB_PASSWORD'
                  export PGDATABASE='$$DB_NAME'
                  
                  if [ -f {{ HomeFolder }}/.env ]; then
                    set -a
                    source {{ HomeFolder }}/.env 2>/dev/null || true
                    set +a
                  fi
                  
                  echo "ðŸ“˜ DAT409 Workshop Ready!"
                  echo "ðŸ”§ Commands: psql, workshop, lab1, lab2"
                  BASHRC_EOF
                  
                  chown -R participant:participant "{{ HomeFolder }}"

          - name: RunAutomatedDatabaseSetup
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 1800
              runCommand:
                - '#!/bin/bash'
                - |
                  echo "=========================================="
                  echo "AUTOMATED DATABASE SETUP"
                  echo "=========================================="
                  echo "Timestamp: $(date)"
                  
                  # Check if setup script exists
                  if [ ! -f "{{ HomeFolder }}/scripts/setup-database.sh" ]; then
                    echo "âŒ ERROR: setup-database.sh not found!"
                    echo "Expected location: {{ HomeFolder }}/scripts/setup-database.sh"
                    ls -la "{{ HomeFolder }}/scripts/" || echo "Scripts directory doesn't exist"
                    exit 1
                  fi
                  
                  # Make executable
                  chmod +x "{{ HomeFolder }}/scripts/setup-database.sh"
                  
                  # Source environment
                  if [ -f "{{ HomeFolder }}/.env" ]; then
                    source "{{ HomeFolder }}/.env"
                    echo "âœ… Environment loaded"
                  else
                    echo "âŒ .env file not found"
                    exit 1
                  fi
                  
                  # Run database setup
                  echo ""
                  echo "Running database setup script..."
                  echo "This will take 6-9 minutes to load 21,704 products with embeddings"
                  echo ""
                  
                  cd "{{ HomeFolder }}"
                  sudo -u participant bash -c 'source /workshop/.env && bash /workshop/scripts/setup-database.sh' 2>&1 | tee /workshop/database_setup.log
                  SETUP_EXIT_CODE=$?
                  
                  if [ $SETUP_EXIT_CODE -eq 0 ]; then
                    echo ""
                    echo "âœ… DATABASE SETUP COMPLETED SUCCESSFULLY"
                    
                    # Verify database
                    PRODUCT_COUNT=$(PGPASSWORD="$DB_PASSWORD" psql -h "$DB_HOST" -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT COUNT(*) FROM bedrock_integration.product_catalog;" 2>/dev/null | xargs)
                    if [ -z "$PRODUCT_COUNT" ]; then PRODUCT_COUNT=0; fi
                    KB_COUNT=$(PGPASSWORD="$DB_PASSWORD" psql -h "$DB_HOST" -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT COUNT(*) FROM public.knowledge_base;" 2>/dev/null | xargs)
                    if [ -z "$KB_COUNT" ]; then KB_COUNT=0; fi
                    
                    echo ""
                    echo "Database Verification:"
                    echo "  Products loaded: $PRODUCT_COUNT"
                    echo "  Knowledge base entries: $KB_COUNT"
                  else
                    echo ""
                    echo "âŒ DATABASE SETUP FAILED"
                    echo "Check /workshop/database_setup.log for details"
                    exit 1
                  fi

          - name: FinalValidation
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 300
              runCommand:
                - '#!/bin/bash'
                - |
                  echo "=== FINAL VALIDATION ==="
                  echo "Timestamp: $(date)"
                  
                  sleep 30
                  
                  # Service status
                  NGINX_STATUS=$(systemctl is-active nginx)
                  CODE_EDITOR_STATUS=$(systemctl is-active code-editor@participant)
                  
                  echo "Service Status:"
                  echo "  Nginx: $NGINX_STATUS"
                  echo "  Code Editor: $CODE_EDITOR_STATUS"
                  
                  # Port check
                  echo ""
                  echo "Listening Ports:"
                  ss -tlpn | grep -E ":(80|8080)" || echo "  WARNING: Expected ports not found"
                  
                  # Connectivity test
                  CODE_RESPONSE=$(curl -s -o /dev/null -w "%{http_code}" http://127.0.0.1:8080/ || echo "failed")
                  NGINX_RESPONSE=$(curl -s -o /dev/null -w "%{http_code}" http://127.0.0.1/ || echo "failed")
                  
                  echo ""
                  echo "Connectivity Tests:"
                  echo "  Code Editor (8080): $CODE_RESPONSE"
                  echo "  Nginx (80): $NGINX_RESPONSE"
                  
                  # Database validation
                  echo ""
                  echo "Database Status:"
                  if [ -f "/workshop/.env" ]; then
                    source /workshop/.env
                    
                    if PGPASSWORD="$DB_PASSWORD" psql -h "$DB_HOST" -U "$DB_USER" -d "$DB_NAME" -c "SELECT 1;" &>/dev/null; then
                      echo "  âœ… Database connection successful"
                      
                      PRODUCT_COUNT=$(PGPASSWORD="$DB_PASSWORD" psql -h "$DB_HOST" -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT COUNT(*) FROM bedrock_integration.product_catalog;" 2>/dev/null | xargs)
                      KB_COUNT=$(PGPASSWORD="$DB_PASSWORD" psql -h "$DB_HOST" -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT COUNT(*) FROM public.knowledge_base;" 2>/dev/null | xargs)
                      
                      echo "  Products: $${PRODUCT_COUNT:-0}"
                      echo "  Knowledge base: $${KB_COUNT:-0}"
                    else
                      echo "  âŒ Database connection failed"
                    fi
                  fi
                  
                  # Overall validation
                  echo ""
                  if [[ "$NGINX_STATUS" == "active" && "$CODE_EDITOR_STATUS" == "active" ]]; then
                    if [[ "$CODE_RESPONSE" =~ ^(200|302|401|403)$ && "$NGINX_RESPONSE" =~ ^(200|302|401|403)$ ]]; then
                      echo "âœ… VALIDATION PASSED"
                      exit 0
                    fi
                  fi
                  
                  echo "âŒ VALIDATION FAILED"
                  exit 1

  # Lambda for running SSM document
  SSMDocLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: SSMDocOnEC2
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - ssm:SendCommand
                Resource:
                  - !Sub arn:${AWS::Partition}:ssm:${AWS::Region}:${AWS::AccountId}:document/${CodeEditorSSMDoc}
                  - !Sub arn:${AWS::Partition}:ec2:${AWS::Region}:${AWS::AccountId}:instance/${CodeEditorInstance}
              - Effect: Allow
                Action:
                  - ssm:ListCommandInvocations
                  - ssm:GetCommandInvocation
                Resource: '*'

  RunSSMDocLambda:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.lambda_handler
      Runtime: python3.13
      MemorySize: 128
      Timeout: 900
      Environment:
        Variables:
          RetrySleep: 2900
          AbortTimeRemaining: 3200
      Architectures:
        - arm64
      Role: !GetAtt SSMDocLambdaRole.Arn
      Code:
        ZipFile: |
          import boto3
          import cfnresponse
          import logging
          import time
          import os

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          def lambda_handler(event, context):
              if event['RequestType'] != 'Create':
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData={}, reason='No action to take')
              else:
                  sleep_ms = int(os.environ.get('RetrySleep'))
                  abort_time_remaining_ms = int(os.environ.get('AbortTimeRemaining'))
                  resource_properties = event['ResourceProperties']
                  instance_id = resource_properties['InstanceId']
                  document_name = resource_properties['DocumentName']
                  cloudwatch_log_group_name = resource_properties['CloudWatchLogGroupName']

                  logger.info(f'Running SSM Document {document_name} on EC2 instance {instance_id}')

                  del resource_properties['ServiceToken']
                  if 'ServiceTimeout' in resource_properties:
                      del resource_properties['ServiceTimeout']
                  del resource_properties['InstanceId']
                  del resource_properties['DocumentName']
                  del resource_properties['CloudWatchLogGroupName']
                  if 'PhysicalResourceId' in resource_properties:
                      del resource_properties['PhysicalResourceId']

                  parameters = {}
                  for key, value in resource_properties.items():
                      parameters[key] = [value]

                  retry = True
                  attempt_no = 0
                  time_remaining_ms = context.get_remaining_time_in_millis()
                  ssm = boto3.client('ssm')

                  while retry:
                      attempt_no += 1
                      logger.info(f'Attempt: {attempt_no}. Time Remaining: {time_remaining_ms/1000}s')
                      try:
                          response = ssm.send_command(
                              InstanceIds = [instance_id],
                              DocumentName = document_name,
                              CloudWatchOutputConfig = {'CloudWatchLogGroupName': cloudwatch_log_group_name, 'CloudWatchOutputEnabled': True},
                              Parameters = parameters
                          )
                          command_id = response['Command']['CommandId']
                          responseData = {'CommandId': command_id}
                          cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData, reason='OK')
                          retry = False

                      except ssm.exceptions.InvalidInstanceId:
                          time_remaining_ms = context.get_remaining_time_in_millis()
                          if time_remaining_ms > abort_time_remaining_ms:
                              logger.info(f'Instance {instance_id} not ready. Sleeping: {sleep_ms/1000}s')
                              time.sleep(sleep_ms/1000)
                              retry = True
                          else:
                              logger.info(f'Instance {instance_id} not ready, timed out.')
                              cfnresponse.send(event, context, cfnresponse.FAILED, responseData={}, reason='Timed out')
                              retry = False

                      except Exception as e:
                          logger.error(e, exc_info=True)
                          cfnresponse.send(event, context, cfnresponse.FAILED, responseData={}, reason=str(e))
                          retry = False

  # EC2 Instance
  CodeEditorInstance:
    Type: AWS::EC2::Instance
    Properties:
      ImageId: !If
        - IsGraviton
        - !FindInMap [ArmImage, !Ref InstanceOperatingSystem, ImageId]
        - !FindInMap [AmdImage, !Ref InstanceOperatingSystem, ImageId]
      InstanceType: !Ref InstanceType
      BlockDeviceMappings:
        - DeviceName: /dev/xvda
          Ebs:
            VolumeSize: !Ref InstanceVolumeSize
            VolumeType: gp3
            DeleteOnTermination: true
            Encrypted: true
      SubnetId: !Ref SubnetId
      SecurityGroupIds:
        - !Ref SecurityGroup
      IamInstanceProfile: !Ref CodeEditorInstanceProfile
      UserData:
        Fn::Base64: !Sub |
          #!/bin/bash
          mkdir -p ${HomeFolder}
      Tags:
        - Key: Name
          Value: !Sub '${TemplateName}-code-editor-instance'

  # Run SSM Document
  RunCodeEditorSSMDoc:
    Type: Custom::RunSSMDocLambda
    Properties:
      ServiceToken: !GetAtt RunSSMDocLambda.Arn
      ServiceTimeout: 905
      InstanceId: !Ref CodeEditorInstance
      DocumentName: !Ref CodeEditorSSMDoc
      CloudWatchLogGroupName: !Ref SSMDocumentLogGroup
      CodeEditorPassword: !GetAtt SecretPlaintext.password
      BootstrapScriptUrl: !Ref BootstrapScriptUrl
      RepoUrl: !Ref RepoUrl
      HomeFolder: !Ref HomeFolder
      DBSecretArn: !Ref DBSecretArn
      DBClusterEndpoint: !Ref DBClusterEndpoint
      DBClusterArn: !Ref DBClusterArn
      DBName: !Ref DBName

  # Cache Policy
  CodeEditorCachePolicy:
    Type: AWS::CloudFront::CachePolicy
    Properties:
      CachePolicyConfig:
        DefaultTTL: 86400
        MaxTTL: 31536000
        MinTTL: 1
        Name: !Sub
          - ${InstanceName}-${RandomGUID}
          - RandomGUID: !Select [0, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId ]]]]
        ParametersInCacheKeyAndForwardedToOrigin:
          CookiesConfig:
            CookieBehavior: all
          EnableAcceptEncodingGzip: False
          HeadersConfig:
            HeaderBehavior: whitelist
            Headers:
              - Accept-Charset
              - Authorization
              - Origin
              - Accept
              - Referer
              - Host
              - Accept-Language
              - Accept-Encoding
              - Accept-Datetime
          QueryStringsConfig:
            QueryStringBehavior: all

  # CloudFront Distribution
  CloudFrontDistribution:
    Type: AWS::CloudFront::Distribution
    DependsOn: RunCodeEditorSSMDoc
    Properties:
      DistributionConfig:
        Enabled: true
        HttpVersion: http2and3
        DefaultCacheBehavior:
          AllowedMethods: [GET, HEAD, OPTIONS, PUT, PATCH, POST, DELETE]
          CachePolicyId: !Ref CodeEditorCachePolicy
          OriginRequestPolicyId: 216adef6-5c7f-47e4-b989-5492eafa07d3
          TargetOriginId: !Sub 'origin-${AWS::StackName}'
          ViewerProtocolPolicy: allow-all
        Origins:
          - DomainName: !GetAtt CodeEditorInstance.PublicDnsName
            Id: !Sub 'origin-${AWS::StackName}'
            CustomOriginConfig:
              OriginProtocolPolicy: http-only

Outputs:
  URL:
    Description: Code Editor URL
    Value: !Sub 'https://${CloudFrontDistribution.DomainName}/?folder=${HomeFolder}&tkn=${SecretPlaintext.password}'
    
  Username:
    Description: Username
    Value: !GetAtt SecretPlaintext.username
    
  Password:
    Description: Password
    Value: !GetAtt SecretPlaintext.password
    
  InstanceId:
    Description: EC2 Instance ID
    Value: !Ref CodeEditorInstance

  BootstrapLogs:
    Description: CloudWatch Logs
    Value: !Sub 'https://console.aws.amazon.com/cloudwatch/home?region=${AWS::Region}#logsV2:log-groups/log-group/${SSMDocumentLogGroup}'