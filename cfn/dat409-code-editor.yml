AWSTemplateFormatVersion: '2010-09-09'
Description: 'DAT409 - Code Editor with GitHub Bootstrap Script'

Parameters:
  TemplateName:
    Type: String
    Description: Template name prefix for resources
    
  CodeEditorUser:
    Type: String
    Default: participant
    Description: Username for Code Editor
    
  InstanceName:
    Type: String
    Description: Instance name
    
  InstanceVolumeSize:
    Type: Number
    Default: 50
    Description: Volume size in GB
    
  InstanceType:
    Type: String
    Default: t4g.large
    Description: EC2 instance type
    
  InstanceOperatingSystem:
    Type: String
    Default: AmazonLinux-2023
    Description: Operating system
    
  HomeFolder:
    Type: String
    Default: /workshop
    Description: Working directory
    
  RepoUrl:
    Type: String
    Default: https://github.com/aws-samples/sample-dat409-hybrid-search-aurora-mcp.git
    Description: GitHub repository URL
    
  BootstrapScriptUrl:
    Type: String
    Default: https://raw.githubusercontent.com/aws-samples/sample-dat409-hybrid-search-aurora-mcp/main/scripts/bootstrap-code-editor.sh
    Description: URL to the bootstrap script
    
  VPCId:
    Type: String
    Description: VPC ID
    
  SubnetId:
    Type: String
    Description: Subnet ID
    
  VpcCIDR:
    Type: String
    Description: VPC CIDR
    
  DBSecretArn:
    Type: String
    Description: Database secret ARN
    
  DBClusterEndpoint:
    Type: String
    Description: Database endpoint
    
  DBClusterArn:
    Type: String
    Description: Database cluster ARN for Data API
    
  DBName:
    Type: String
    Default: workshop_db
    Description: Database name
  
  PythonVersion:
    Type: String
    Default: "3.13"

  PostgreSQLVersion:
    Type: String
    Default: "17.5"

Conditions:
  IsGraviton: !Or
    - !Equals [!Select [0, !Split ['.', !Ref InstanceType]], 't4g']
    - !Equals [!Select [0, !Split ['.', !Ref InstanceType]], 'c6g']
    - !Equals [!Select [0, !Split ['.', !Ref InstanceType]], 'm6g']
    - !Equals [!Select [0, !Split ['.', !Ref InstanceType]], 'r6g']
  HasRepoUrl: !Not [!Equals [!Ref RepoUrl, '']]

Mappings:
  ArmImage:
    AmazonLinux-2023:
      ImageId: '{{resolve:ssm:/aws/service/ami-amazon-linux-latest/al2023-ami-kernel-default-arm64}}'
  AmdImage:
    AmazonLinux-2023:
      ImageId: '{{resolve:ssm:/aws/service/ami-amazon-linux-latest/al2023-ami-kernel-default-x86_64}}'
  AWSRegionsPrefixListID:
    us-east-1:
      PrefixList: pl-3b927c52
    us-east-2:
      PrefixList: pl-b6a144df
    us-west-1:
      PrefixList: pl-4ea04527
    us-west-2:
      PrefixList: pl-82a045eb
    eu-west-1:
      PrefixList: pl-4fa04526
    eu-central-1:
      PrefixList: pl-a3a144ca
    ap-southeast-1:
      PrefixList: pl-31a34658
    ap-southeast-2:
      PrefixList: pl-b8a742d1
    ap-northeast-1:
      PrefixList: pl-58a04531

Resources:
  # Code Editor Secret
  CodeEditorSecret:
    Type: AWS::SecretsManager::Secret
    DeletionPolicy: Delete
    UpdateReplacePolicy: Delete
    Properties:
      Name: !Sub
      - ${InstanceName}-${RandomGUID}
      - RandomGUID: !Select [0, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId ]]]]
      Description: Code Editor user credentials
      GenerateSecretString:
        PasswordLength: 16
        SecretStringTemplate: !Sub '{"username":"${CodeEditorUser}"}'
        GenerateStringKey: 'password'
        ExcludePunctuation: true

  # Lambda for extracting secret
  SecretPlaintextLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: SecretAccess
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action: secretsmanager:GetSecretValue
                Resource: !Ref CodeEditorSecret

  SecretPlaintextLambda:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.lambda_handler
      Runtime: python3.13
      Role: !GetAtt SecretPlaintextLambdaRole.Arn
      Code:
        ZipFile: |
          import boto3
          import json
          import cfnresponse
          def lambda_handler(event, context):
              try:
                  if event['RequestType'] == 'Delete':
                      cfnresponse.send(event, context, cfnresponse.SUCCESS, {})
                      return
                  client = boto3.client('secretsmanager')
                  response = client.get_secret_value(SecretId=event['ResourceProperties']['SecretArn'])
                  secret = json.loads(response['SecretString'])
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, secret, noEcho=True)
              except Exception as e:
                  cfnresponse.send(event, context, cfnresponse.FAILED, {}, str(e))

  SecretPlaintext:
    Type: Custom::SecretPlaintextLambda
    Properties:
      ServiceToken: !GetAtt SecretPlaintextLambda.Arn
      SecretArn: !Ref CodeEditorSecret

  # Security Group
  SecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: !Sub '${TemplateName} Code Editor security group'
      VpcId: !Ref VPCId
      SecurityGroupIngress:
        - Description: CloudFront access
          IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          SourcePrefixListId: !FindInMap [AWSRegionsPrefixListID, !Ref 'AWS::Region', PrefixList]
        - Description: VPC access for HTTP
          IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: !Ref VpcCIDR
      SecurityGroupEgress:
        - Description: Allow all outbound
          IpProtocol: -1
          CidrIp: 0.0.0.0/0

  # IAM Role
  CodeEditorRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: [ec2.amazonaws.com, ssm.amazonaws.com]
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore
        - arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy
        - arn:aws:iam::aws:policy/AmazonBedrockFullAccess
        - arn:aws:iam::aws:policy/AmazonQDeveloperAccess
      Policies:
        - PolicyName: WorkshopAccess
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - secretsmanager:GetSecretValue
                Resource:
                  - !Ref CodeEditorSecret
                  - !Ref DBSecretArn
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:ListBucket
                Resource: '*'
              - Effect: Allow
                Action:
                  - rds:DescribeDBClusters
                  - rds:DescribeDBInstances
                  - rds-data:ExecuteStatement
                  - rds-data:BatchExecuteStatement
                Resource: '*'

  CodeEditorInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Roles:
        - !Ref CodeEditorRole

  # CloudWatch Log Groups for better debugging
  BootstrapLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub '/aws/ec2/${TemplateName}/bootstrap'
      RetentionInDays: 7

  SSMDocumentLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub '/aws/ssm/${TemplateName}-bootstrap'
      RetentionInDays: 7

  # Simplified SSM Document that just calls GitHub script
  CodeEditorSSMDoc:
    Type: AWS::SSM::Document
    Properties:
      DocumentType: Command
      Content:
        schemaVersion: '2.2'
        description: DAT409 Code Editor Bootstrap - GitHub Script Approach
        parameters:
          CodeEditorPassword:
            type: String
            default: 'defaultPassword'
          BootstrapScriptUrl:
            type: String
            default: !Ref BootstrapScriptUrl
          RepoUrl:
            type: String
            default: !Ref RepoUrl
          HomeFolder:
            type: String
            default: !Ref HomeFolder
          DBSecretArn:
            type: String
            default: !Ref DBSecretArn
          DBClusterEndpoint:
            type: String
            default: !Ref DBClusterEndpoint
          DBClusterArn:
            type: String
            default: !Ref DBClusterArn
          DBName:
            type: String
            default: !Ref DBName
        mainSteps:
          - name: InstallCloudWatchAgent
            action: aws:configurePackage
            inputs:
              name: AmazonCloudWatchAgent
              action: Install

          - name: SetupEnvironment
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 300
              runCommand:
                - '#!/bin/bash'
                - 'set -euo pipefail'
                - !Sub |
                  echo "Setting up environment variables..."
                  
                  # Update system first
                  dnf update -y
                  
                  # Setup environment for the participant user
                  export AWS_REGION="${AWS::Region}"
                  export AWS_DEFAULT_REGION="${AWS::Region}"
                  export AWS_ACCOUNTID="${AWS::AccountId}"
                  
                  echo "Environment setup completed"

          - name: RunGitHubBootstrap
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 900
              runCommand:
                - '#!/bin/bash'
                - 'set -euo pipefail'
                - !Sub |
                  echo "=== DAT409 GitHub Bootstrap Script Execution ==="
                  echo "Bootstrap URL: {{ BootstrapScriptUrl }}"
                  echo "Password: {{ CodeEditorPassword:0:4 }}****"
                  echo "DB Secret ARN: {{ DBSecretArn }}"
                  echo "DB Cluster: {{ DBClusterEndpoint }}"
                  echo "Timestamp: $(date)"
                  echo
                  
                  # Set environment variables for the bootstrap script
                  export DB_SECRET_ARN="{{ DBSecretArn }}"
                  export DB_CLUSTER_ENDPOINT="{{ DBClusterEndpoint }}"
                  export DB_CLUSTER_ARN="{{ DBClusterArn }}"
                  export DB_NAME="{{ DBName }}"
                  export AWS_REGION="${AWS::Region}"
                  export AWS_DEFAULT_REGION="${AWS::Region}"
                  
                  # Download the bootstrap script
                  echo "Downloading bootstrap script..."
                  curl -fsSL "{{ BootstrapScriptUrl }}" -o /tmp/bootstrap-code-editor.sh
                  
                  # Verify download
                  if [ ! -f /tmp/bootstrap-code-editor.sh ]; then
                    echo "ERROR: Failed to download bootstrap script"
                    exit 1
                  fi
                  
                  # Make executable
                  chmod +x /tmp/bootstrap-code-editor.sh
                  
                  echo "Script downloaded successfully ($(wc -l < /tmp/bootstrap-code-editor.sh) lines)"
                  echo
                  
                  # Execute the bootstrap script with environment variables
                  echo "Executing bootstrap script (infrastructure only)..."
                  echo "This will take approximately 3-5 minutes:"
                  echo "  - Code Editor setup: ~2-3 minutes"
                  echo "  - Service validation: ~1 minute"
                  echo ""
                  echo "NOTE: Database setup will be done separately by instructors"
                  echo
                  
                  # Pass environment variables to the bootstrap script
                  DB_SECRET_ARN="{{ DBSecretArn }}" \
                  DB_CLUSTER_ENDPOINT="{{ DBClusterEndpoint }}" \
                  DB_CLUSTER_ARN="{{ DBClusterArn }}" \
                  DB_NAME="{{ DBName }}" \
                  AWS_REGION="${AWS::Region}" \
                  /tmp/bootstrap-code-editor.sh "{{ CodeEditorPassword }}"
                  
                  # Check execution result
                  if [ $? -eq 0 ]; then
                    echo
                    echo "=== BOOTSTRAP SUCCESS ==="
                    echo "Code Editor is now accessible"
                    echo "Infrastructure ready - run setup-database.sh after enabling Bedrock"
                    echo "Services status:"
                    systemctl is-active nginx || echo "Nginx: FAILED"
                    systemctl is-active code-editor@participant || echo "Code Editor: FAILED"
                    
                    # Show database loading summary if log exists
                    if [ -f /workshop/data_loader.log ]; then
                      echo
                      echo "Database Loading Summary:"
                      tail -n 20 /workshop/data_loader.log | grep -E "(✅|Total|products|embeddings|time)" || true
                    fi
                  else
                    echo "ERROR: Bootstrap script failed"
                    exit 1
                  fi
                  
                  # Clean up
                  rm -f /tmp/bootstrap-code-editor.sh
                  
                  echo "Bootstrap execution completed successfully"

          - name: CreateCodeEditorSettings
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 300
              runCommand:
                - '#!/bin/bash'
                - !Sub |
                  echo "Configuring Code Editor settings..."
                  
                  # Create settings directory
                  sudo -u ${CodeEditorUser} --login mkdir -p /home/${CodeEditorUser}/.code-editor-server/data/User
                  
                  # Create VS Code settings with Git completely disabled
                  tee /home/${CodeEditorUser}/.code-editor-server/data/User/settings.json <<'EOF'
                  {
                    "workbench.colorTheme": "Default Dark Modern",
                    "git.enabled": false,
                    "git.decorations.enabled": false,
                    "git.showProgress": false,
                    "git.autofetch": false,
                    "scm.diffDecorations": "none",
                    "scm.defaultViewMode": "tree",
                    "aws.telemetry": false,
                    "extensions.autoUpdate": false,
                    "extensions.autoCheckUpdates": false,
                    "telemetry.telemetryLevel": "off",
                    "security.workspace.trust.startupPrompt": "never",
                    "security.workspace.trust.enabled": false,
                    "security.workspace.trust.banner": "never",
                    "security.workspace.trust.emptyWindow": false,
                    "workbench.startupEditor": "none",
                    "terminal.integrated.cwd": "{{ HomeFolder }}",
                    "terminal.integrated.defaultProfile.linux": "bash",
                    "python.defaultInterpreterPath": "/usr/bin/python3.13",
                    "python.terminal.activateEnvironment": true,
                    "python.linting.enabled": true,
                    "jupyter.jupyterServerType": "local",
                    "jupyter.notebookFileRoot": "{{ HomeFolder }}",
                    "notebook.defaultKernel": "python3",
                    "files.autoSave": "afterDelay",
                    "files.autoSaveDelay": 1000
                  }
                  EOF
                  
                  # Set ownership
                  chown ${CodeEditorUser}:${CodeEditorUser} /home/${CodeEditorUser}/.code-editor-server/data/User/settings.json
                  
                  # Create .gitignore for workshop files
                  cat > {{ HomeFolder }}/.gitignore <<'GITIGNORE'
                  # Workshop generated files
                  *.log
                  *.pyc
                  __pycache__/
                  .env
                  .pgpass
                  run_data_loader.py
                  test_db_connection.sh
                  debug_secret.sh
                  fix_setup.sh
                  data_loader.log
                  verify_environment.sh
                  GITIGNORE
                  
                  chown ${CodeEditorUser}:${CodeEditorUser} {{ HomeFolder }}/.gitignore
                  
                  echo "Code Editor settings configured with Git disabled"

          - name: CloneWorkshopRepository
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 600
              runCommand:
                - '#!/bin/bash'
                - !Sub |
                  if [ -n "{{ RepoUrl }}" ]; then
                    echo "Cloning workshop repository..."
                    
                    # Clone as the participant user to avoid permission issues
                    sudo -u participant git clone "{{ RepoUrl }}" /tmp/workshop_repo
                    
                    # Copy contents to workshop directory, preserving permissions
                    if [ -d /tmp/workshop_repo ]; then
                      sudo -u participant cp -r /tmp/workshop_repo/* "{{ HomeFolder }}/" || true
                      sudo -u participant cp -r /tmp/workshop_repo/.[!.]* "{{ HomeFolder }}/" 2>/dev/null || true
                      rm -rf /tmp/workshop_repo
                      echo "Repository cloned successfully"
                    else
                      echo "WARNING: Repository clone failed, continuing without repo"
                    fi
                  else
                    echo "No repository URL provided, skipping clone"
                  fi

          - name: SetupWorkshopEnvironment
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 600
              runCommand:
                - '#!/bin/bash'
                - !Sub |
                  echo "Setting up workshop environment..."
                  
                  # Retrieve database credentials from Secrets Manager
                  if [ ! -z "{{ DBSecretArn }}" ] && [ "{{ DBSecretArn }}" != "none" ]; then
                    echo "Retrieving database credentials..."
                    DB_SECRET=$(aws secretsmanager get-secret-value \
                      --secret-id "{{ DBSecretArn }}" \
                      --region ${AWS::Region} \
                      --query SecretString \
                      --output text 2>/dev/null)
                    
                    if [ ! -z "$DB_SECRET" ]; then
                      DB_HOST=$(echo "$DB_SECRET" | jq -r '.host // .endpoint // empty')
                      DB_PORT=$(echo "$DB_SECRET" | jq -r '.port // "5432"')
                      DB_NAME=$(echo "$DB_SECRET" | jq -r '.dbname // .database // empty')
                      DB_USER=$(echo "$DB_SECRET" | jq -r '.username // .user // empty')
                      DB_PASSWORD=$(echo "$DB_SECRET" | jq -r '.password // empty')
                      
                      # Fallback to cluster endpoint if host is empty
                      if [ -z "$DB_HOST" ] || [ "$DB_HOST" == "null" ]; then
                        DB_HOST="{{ DBClusterEndpoint }}"
                      fi
                    else
                      echo "WARNING: Could not retrieve database secret"
                      DB_HOST="{{ DBClusterEndpoint }}"
                      DB_PORT="5432"
                      DB_NAME="{{ DBName }}"
                      DB_USER="workshop_admin"
                      DB_PASSWORD=""
                    fi
                  else
                    echo "WARNING: No DBSecretArn provided"
                    DB_HOST="{{ DBClusterEndpoint }}"
                    DB_PORT="5432"
                    DB_NAME="{{ DBName }}"
                    DB_USER="workshop_admin"
                    DB_PASSWORD=""
                  fi
                  
                  # Create .env file for workshop with actual credentials
                  sudo -u participant tee "{{ HomeFolder }}/.env" << EOF
                  DB_HOST=$DB_HOST
                  DB_PORT=$DB_PORT
                  DB_NAME=$DB_NAME
                  DB_USER=$DB_USER
                  DB_PASSWORD=$DB_PASSWORD
                  DATABASE_URL=postgresql://$DB_USER:$DB_PASSWORD@$DB_HOST:$DB_PORT/$DB_NAME
                  DATABASE_SECRET_ARN={{ DBSecretArn }}
                  DATABASE_CLUSTER_ARN={{ DBClusterArn }}
                  AWS_REGION=${AWS::Region}
                  
                  # PostgreSQL Client Environment Variables
                  PGHOST=$DB_HOST
                  PGPORT=$DB_PORT
                  PGDATABASE=$DB_NAME
                  PGUSER=$DB_USER
                  PGPASSWORD=$DB_PASSWORD
                  EOF
                  
                  chmod 600 "{{ HomeFolder }}/.env"
                  chown participant:participant "{{ HomeFolder }}/.env"
                  
                  # Also create .pgpass file for passwordless psql access
                  sudo -u participant bash -c "cat > /home/participant/.pgpass << PGPASS_EOF
                  $DB_HOST:$DB_PORT:$DB_NAME:$DB_USER:$DB_PASSWORD
                  $DB_HOST:$DB_PORT:*:$DB_USER:$DB_PASSWORD
                  *:*:*:$DB_USER:$DB_PASSWORD
                  PGPASS_EOF"
                  
                  chmod 600 "/home/participant/.pgpass"
                  chown participant:participant "/home/participant/.pgpass"
                  
                  # Setup bash environment with database credentials
                  cat >> /home/participant/.bashrc << BASHRC_EOF
                  export AWS_REGION="${AWS::Region}"
                  export AWS_DEFAULT_REGION="${AWS::Region}"
                  export PATH=\$PATH:/home/participant/.local/bin:/usr/local/bin
                  
                  # Workshop shortcuts
                  alias workshop="cd {{ HomeFolder }}"
                  alias lab1="cd {{ HomeFolder }}/lab1-hybrid-search"
                  alias lab2="cd {{ HomeFolder }}/lab2-mcp-agent"
                  
                  # Database connection environment - Static values from .env
                  export DB_HOST='$DB_HOST'
                  export DB_PORT='$DB_PORT'
                  export DB_NAME='$DB_NAME'
                  export DB_USER='$DB_USER'
                  export DB_PASSWORD='$DB_PASSWORD'
                  export DATABASE_URL='postgresql://$DB_USER:$DB_PASSWORD@$DB_HOST:$DB_PORT/$DB_NAME'
                  export PGHOST='$DB_HOST'
                  export PGPORT='$DB_PORT'
                  export PGUSER='$DB_USER'
                  export PGPASSWORD='$DB_PASSWORD'
                  export PGDATABASE='$DB_NAME'
                  export DB_SECRET_ARN='{{ DBSecretArn }}'
                  export DATABASE_CLUSTER_ARN='{{ DBClusterArn }}'
                  
                  # Load .env file if it exists (as backup)
                  if [ -f {{ HomeFolder }}/.env ]; then
                    set -a
                    source {{ HomeFolder }}/.env 2>/dev/null || true
                    set +a
                  fi
                  
                  echo ""
                  echo "🔘 DAT409 Workshop Environment Ready!"
                  echo "📊 Database: \$PGDATABASE @ \$PGHOST"
                  echo "🔧 Quick commands: psql, workshop, lab1, lab2"
                  echo "💡 Test connection: psql -c 'SELECT version();'"
                  echo ""
                  BASHRC_EOF
                  
                  chown participant:participant /home/participant/.bashrc
                  chown -R participant:participant "{{ HomeFolder }}"
                  
                  echo "Workshop environment setup completed"
                  echo "Database credentials configured:"
                  echo "  Host: $DB_HOST"
                  echo "  Database: $DB_NAME"
                  echo "  User: $DB_USER"
                  echo "  Password: $([ ! -z "$DB_PASSWORD" ] && echo 'Set' || echo 'Not set')"

          - name: FinalValidation
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 300
              runCommand:
                - '#!/bin/bash'
                - |
                  echo "=== FINAL VALIDATION ==="
                  echo "Timestamp: $(date)"
                  echo
                  
                  # Wait for everything to settle
                  sleep 30
                  
                  # ===== SERVICE STATUS CHECK =====
                  echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
                  echo "SERVICE STATUS:"
                  echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
                  
                  NGINX_STATUS=$(systemctl is-active nginx)
                  CODE_EDITOR_STATUS=$(systemctl is-active code-editor@participant)
                  
                  echo "  Nginx: $NGINX_STATUS"
                  echo "  Code Editor: $CODE_EDITOR_STATUS"
                  echo
                  
                  # Check ports
                  echo "Listening Ports:"
                  ss -tlpn | grep -E ":(80|8080)" || echo "  WARNING: Expected ports not found"
                  echo
                  
                  # Test connectivity
                  CODE_RESPONSE=$(curl -s -o /dev/null -w "%{http_code}" http://127.0.0.1:8080/ || echo "failed")
                  NGINX_RESPONSE=$(curl -s -o /dev/null -w "%{http_code}" http://127.0.0.1/ || echo "failed")
                  
                  echo "Connectivity Tests:"
                  echo "  Code Editor (8080): $CODE_RESPONSE"
                  echo "  Nginx (80): $NGINX_RESPONSE"
                  echo
                  
                  # ===== DATABASE CONFIGURATION VALIDATION =====
                  echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
                  echo "DATABASE CONFIGURATION:"
                  echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
                  
                  # Check .env file
                  echo "📁 Configuration Files:"
                  if [ -f "{{ HomeFolder }}/.env" ]; then
                    echo "  ✅ .env file exists at {{ HomeFolder }}/.env"
                    
                    # Validate .env contents (without showing password)
                    if grep -q "DB_HOST=" "{{ HomeFolder }}/.env"; then
                      DB_HOST=$(grep "^DB_HOST=" "{{ HomeFolder }}/.env" | cut -d'=' -f2)
                      echo "    - DB_HOST: $DB_HOST"
                    else
                      echo "    - ⚠️  DB_HOST: Missing"
                    fi
                    
                    if grep -q "DB_USER=" "{{ HomeFolder }}/.env"; then
                      DB_USER=$(grep "^DB_USER=" "{{ HomeFolder }}/.env" | cut -d'=' -f2)
                      echo "    - DB_USER: $DB_USER"
                    else
                      echo "    - ⚠️  DB_USER: Missing"
                    fi
                    
                    if grep -q "DB_PASSWORD=" "{{ HomeFolder }}/.env"; then
                      DB_PASSWORD_LINE=$(grep "^DB_PASSWORD=" "{{ HomeFolder }}/.env")
                      if [ "${#DB_PASSWORD_LINE}" -gt 12 ]; then
                        echo "    - DB_PASSWORD: ✅ Set (length: $((${#DB_PASSWORD_LINE} - 12)))"
                      else
                        echo "    - ⚠️  DB_PASSWORD: Empty or not set"
                      fi
                    else
                      echo "    - ⚠️  DB_PASSWORD: Missing"
                    fi
                    
                    if grep -q "DB_NAME=" "{{ HomeFolder }}/.env"; then
                      DB_NAME=$(grep "^DB_NAME=" "{{ HomeFolder }}/.env" | cut -d'=' -f2)
                      echo "    - DB_NAME: $DB_NAME"
                    else
                      echo "    - ⚠️  DB_NAME: Missing"
                    fi
                  else
                    echo "  ❌ .env file NOT found at {{ HomeFolder }}/.env"
                  fi
                  
                  # Check .pgpass file
                  if [ -f "/home/participant/.pgpass" ]; then
                    echo "  ✅ .pgpass file exists"
                    PGPASS_LINES=$(wc -l < /home/participant/.pgpass)
                    echo "    - Lines in .pgpass: $PGPASS_LINES"
                  else
                    echo "  ❌ .pgpass file NOT found"
                  fi
                  echo
                  
                  # Check environment variables in participant's shell
                  echo "🔧 Environment Variables (participant user):"
                  sudo -u participant bash -c 'source ~/.bashrc 2>/dev/null; 
                    echo "  PGHOST: ${PGHOST:-Not set}"
                    echo "  PGUSER: ${PGUSER:-Not set}"
                    echo "  PGDATABASE: ${PGDATABASE:-Not set}"
                    echo "  PGPASSWORD: $([ ! -z "$PGPASSWORD" ] && echo "Set (length: ${#PGPASSWORD})" || echo "Not set")"
                    echo "  DB_SECRET_ARN: ${DB_SECRET_ARN:-Not set}"'
                  echo
                  
                  # ===== DATABASE CONNECTION TEST =====
                  echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
                  echo "DATABASE CONNECTION TEST:"
                  echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
                  
                  # Source .env and test database connection
                  if [ -f "{{ HomeFolder }}/.env" ]; then
                    source "{{ HomeFolder }}/.env"
                    
                    if [ ! -z "$DB_HOST" ] && [ ! -z "$DB_USER" ] && [ ! -z "$DB_PASSWORD" ] && [ ! -z "$DB_NAME" ]; then
                      echo "Testing database connection..."
                      
                      # Test with psql
                      if PGPASSWORD="$DB_PASSWORD" psql -h "$DB_HOST" -U "$DB_USER" -d "$DB_NAME" -c "SELECT version();" &>/dev/null; then
                        echo "  ✅ Database connection SUCCESSFUL"
                        
                        # Check for extensions
                        echo
                        echo "  PostgreSQL Extensions:"
                        PGPASSWORD="$DB_PASSWORD" psql -h "$DB_HOST" -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT extname FROM pg_extension WHERE extname IN ('vector', 'pg_trgm');" 2>/dev/null | while read ext; do
                          [ ! -z "$ext" ] && echo "    - $ext"
                        done
                        
                        # Check schema and table
                        # echo
                        # echo "  Database Objects:"
                        # SCHEMA_EXISTS=$(PGPASSWORD="$DB_PASSWORD" psql -h "$DB_HOST" -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT EXISTS(SELECT 1 FROM information_schema.schemata WHERE schema_name = 'bedrock_integration');" 2>/dev/null | xargs)
                        # if [ "$SCHEMA_EXISTS" = "t" ]; then
                        #   echo "    - ✅ Schema 'bedrock_integration' exists"
                          
                        #   TABLE_EXISTS=$(PGPASSWORD="$DB_PASSWORD" psql -h "$DB_HOST" -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT EXISTS(SELECT 1 FROM information_schema.tables WHERE table_schema = 'bedrock_integration' AND table_name = 'product_catalog');" 2>/dev/null | xargs)
                        #   if [ "$TABLE_EXISTS" = "t" ]; then
                        #     echo "    - ✅ Table 'product_catalog' exists"
                            
                            # Check row count
                        #     ROW_COUNT=$(PGPASSWORD="$DB_PASSWORD" psql -h "$DB_HOST" -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT COUNT(*) FROM bedrock_integration.product_catalog;" 2>/dev/null | xargs)
                        #     echo "    - Product count: ${ROW_COUNT:-0}"
                            
                        #     # Check embeddings
                        #     EMB_COUNT=$(PGPASSWORD="$DB_PASSWORD" psql -h "$DB_HOST" -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT COUNT(*) FROM bedrock_integration.product_catalog WHERE embedding IS NOT NULL;" 2>/dev/null | xargs)
                        #     echo "    - Products with embeddings: ${EMB_COUNT:-0}"
                        #   else
                        #     echo "    - ⚠️  Table 'product_catalog' not found"
                        #   fi
                        # else
                        #   echo "    - ⚠️  Schema 'bedrock_integration' not found"
                        # fi
                      else
                        echo "  ❌ Database connection FAILED"
                        echo "    - Host: $DB_HOST"
                        echo "    - User: $DB_USER"
                        echo "    - Database: $DB_NAME"
                        echo "    - Password: $([ ! -z "$DB_PASSWORD" ] && echo 'Set' || echo 'Not set')"
                      fi
                    else
                      echo "  ❌ Missing database credentials in .env"
                      echo "    - DB_HOST: ${DB_HOST:-Missing}"
                      echo "    - DB_USER: ${DB_USER:-Missing}"
                      echo "    - DB_NAME: ${DB_NAME:-Missing}"
                      echo "    - DB_PASSWORD: $([ ! -z "$DB_PASSWORD" ] && echo 'Set' || echo 'Missing')"
                    fi
                  else
                    echo "  ❌ Cannot test - .env file not found"
                  fi
                  echo
                  
                  # ===== DATA LOADER LOG CHECK =====
                  # echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
                  # echo "DATA LOADER STATUS:"
                  # echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
                  
                  # if [ -f "{{ HomeFolder }}/data_loader.log" ]; then
                  #   echo "📋 Data loader log found"
                    
                  #   # Check for success indicators
                  #   if grep -q "FULL DATA LOADING COMPLETE" "{{ HomeFolder }}/data_loader.log"; then
                  #     echo "  ✅ Data loading completed successfully"
                      
                  #     # Extract summary statistics
                  #     tail -n 30 "{{ HomeFolder }}/data_loader.log" | grep -E "(Total rows|embeddings|Total time)" | while IFS= read -r line; do
                  #       echo "    $line"
                  #     done
                  #   elif grep -q "Database connection failed" "{{ HomeFolder }}/data_loader.log"; then
                  #     echo "  ❌ Data loading failed - database connection error"
                  #   elif grep -q "Missing database credentials" "{{ HomeFolder }}/data_loader.log"; then
                  #     echo "  ❌ Data loading failed - missing credentials"
                  #   else
                  #     echo "  ⚠️  Data loading status unclear"
                  #   fi
                    
                    # Show last few error lines if any
                    if grep -q "ERROR\|Failed\|failed" "{{ HomeFolder }}/data_loader.log"; then
                      echo
                      echo "  Recent errors:"
                      grep -E "ERROR|Failed|failed" "{{ HomeFolder }}/data_loader.log" | tail -5 | while IFS= read -r line; do
                        echo "    $line"
                      done
                    fi
                  else
                    echo "  ⚠️  No data loader log found at {{ HomeFolder }}/data_loader.log"
                  fi
                  echo
                  
                  # ===== WORKSHOP FILES CHECK =====
                  echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
                  echo "WORKSHOP FILES:"
                  echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
                  
                  echo "📂 Workshop directory contents:"
                  if [ -d "{{ HomeFolder }}" ]; then
                    ls -la "{{ HomeFolder }}" | head -15
                    TOTAL_FILES=$(find "{{ HomeFolder }}" -type f | wc -l)
                    echo "  Total files in workshop: $TOTAL_FILES"
                  else
                    echo "  ❌ Workshop directory not found"
                  fi
                  echo
                  
                  # ===== OVERALL VALIDATION RESULT =====
                  echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
                  echo "VALIDATION SUMMARY:"
                  echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
                  
                  VALIDATION_PASSED=true
                  ISSUES=""
                  
                  # Check services
                  if [[ "$NGINX_STATUS" != "active" ]]; then
                    VALIDATION_PASSED=false
                    ISSUES="$ISSUES\n  - Nginx service not active"
                  fi
                  
                  if [[ "$CODE_EDITOR_STATUS" != "active" ]]; then
                    VALIDATION_PASSED=false
                    ISSUES="$ISSUES\n  - Code Editor service not active"
                  fi
                  
                  # Check connectivity
                  if [[ ! "$CODE_RESPONSE" =~ ^(200|302|401|403)$ ]]; then
                    VALIDATION_PASSED=false
                    ISSUES="$ISSUES\n  - Code Editor not responding on port 8080"
                  fi
                  
                  if [[ ! "$NGINX_RESPONSE" =~ ^(200|302|401|403)$ ]]; then
                    VALIDATION_PASSED=false
                    ISSUES="$ISSUES\n  - Nginx not responding on port 80"
                  fi
                  
                  # Check database setup
                  if [ ! -f "{{ HomeFolder }}/.env" ]; then
                    VALIDATION_PASSED=false
                    ISSUES="$ISSUES\n  - .env file missing"
                  elif ! grep -q "DB_PASSWORD=" "{{ HomeFolder }}/.env" || [ "${#DB_PASSWORD_LINE}" -le 12 ]; then
                    VALIDATION_PASSED=false
                    ISSUES="$ISSUES\n  - DB_PASSWORD not properly set in .env"
                  fi
                  
                  # Final result
                  if [ "$VALIDATION_PASSED" = true ]; then
                    echo "✅ VALIDATION PASSED"
                    echo
                    echo "Code Editor is accessible via CloudFront"
                    echo "Database configuration is complete"
                    echo "All services are running correctly"
                    exit 0
                  else
                    echo "❌ VALIDATION FAILED"
                    echo
                    echo "Issues found:"
                    echo -e "$ISSUES"
                    echo
                    echo "Please check the logs for more details"
                    exit 1
                  fi

  # Lambda for running SSM document
  SSMDocLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: SSMDocOnEC2
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - ssm:SendCommand
                Resource:
                  - !Sub arn:${AWS::Partition}:ssm:${AWS::Region}:${AWS::AccountId}:document/${CodeEditorSSMDoc}
                  - !Sub arn:${AWS::Partition}:ssm:${AWS::Region}:${AWS::AccountId}:document/AmazonCloudWatch-ManageAgent
                  - !Sub arn:${AWS::Partition}:ec2:${AWS::Region}:${AWS::AccountId}:instance/${CodeEditorInstance}
              - Effect: Allow
                Action:
                  - ssm:ListCommandInvocations
                  - ssm:GetCommandInvocation
                Resource: '*'

  RunSSMDocLambda:
    Type: AWS::Lambda::Function
    Properties:
      Description: Run SSM document on EC2 instance
      Handler: index.lambda_handler
      Runtime: python3.13
      MemorySize: 128
      Timeout: 900
      Environment:
        Variables:
          RetrySleep: 2900
          AbortTimeRemaining: 3200
      Architectures:
        - arm64
      Role: !GetAtt SSMDocLambdaRole.Arn
      Code:
        ZipFile: |
          import boto3
          import cfnresponse
          import logging
          import time
          import os

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          def lambda_handler(event, context):
              if event['RequestType'] != 'Create':
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData={}, reason='No action to take')
              else:
                  sleep_ms = int(os.environ.get('RetrySleep'))
                  abort_time_remaining_ms = int(os.environ.get('AbortTimeRemaining'))
                  resource_properties = event['ResourceProperties']
                  instance_id = resource_properties['InstanceId']
                  document_name = resource_properties['DocumentName']
                  cloudwatch_log_group_name = resource_properties['CloudWatchLogGroupName']

                  logger.info(f'Running GitHub Bootstrap SSM Document {document_name} on EC2 instance {instance_id}')

                  del resource_properties['ServiceToken']
                  if 'ServiceTimeout' in resource_properties:
                      del resource_properties['ServiceTimeout']
                  del resource_properties['InstanceId']
                  del resource_properties['DocumentName']
                  del resource_properties['CloudWatchLogGroupName']
                  if 'PhysicalResourceId' in resource_properties:
                      del resource_properties['PhysicalResourceId']

                  parameters = {}
                  for key, value in resource_properties.items():
                      parameters[key] = [value]

                  retry = True
                  attempt_no = 0
                  time_remaining_ms = context.get_remaining_time_in_millis()
                  ssm = boto3.client('ssm')

                  while (retry == True):
                      attempt_no += 1
                      logger.info(f'Attempt: {attempt_no}. Time Remaining: {time_remaining_ms/1000}s')
                      try:
                          response = ssm.send_command(
                              InstanceIds = [instance_id],
                              DocumentName = document_name,
                              CloudWatchOutputConfig = {'CloudWatchLogGroupName': cloudwatch_log_group_name, 'CloudWatchOutputEnabled': True},
                              Parameters = parameters
                          )
                          command_id = response['Command']['CommandId']
                          responseData = {'CommandId': command_id}
                          cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData, reason='OK')
                          retry = False

                      except ssm.exceptions.InvalidInstanceId as e:
                          time_remaining_ms = context.get_remaining_time_in_millis()
                          if (time_remaining_ms > abort_time_remaining_ms):
                              logger.info(f'Instance {instance_id} not ready. Sleeping: {sleep_ms/1000}s')
                              time.sleep(sleep_ms/1000)
                              retry = True
                          else:
                              logger.info(f'Instance {instance_id} not ready, timed out.')
                              cfnresponse.send(event, context, cfnresponse.FAILED, responseData={}, reason='Timed out')
                              retry = False

                      except Exception as e:
                          logger.error(e, exc_info=True)
                          cfnresponse.send(event, context, cfnresponse.FAILED, responseData={}, reason=str(e))
                          retry = False

  # EC2 Instance
  CodeEditorInstance:
    Type: AWS::EC2::Instance
    Properties:
      ImageId: !If
        - IsGraviton
        - !FindInMap [ArmImage, !Ref InstanceOperatingSystem, ImageId]
        - !FindInMap [AmdImage, !Ref InstanceOperatingSystem, ImageId]
      InstanceType: !Ref InstanceType
      BlockDeviceMappings:
        - DeviceName: /dev/xvda
          Ebs:
            VolumeSize: !Ref InstanceVolumeSize
            VolumeType: gp3
            DeleteOnTermination: true
            Encrypted: true
      SubnetId: !Ref SubnetId
      SecurityGroupIds:
        - !Ref SecurityGroup
      IamInstanceProfile: !Ref CodeEditorInstanceProfile
      UserData:
        Fn::Base64: !Sub |
          #!/bin/bash
          mkdir -p ${HomeFolder}
      Tags:
        - Key: Name
          Value: !Sub '${TemplateName}-code-editor-instance'

  # Run SSM Document
  RunCodeEditorSSMDoc:
    Type: Custom::RunSSMDocLambda
    DependsOn:
      - CodeEditorInstance
      - CodeEditorSSMDoc
    Properties:
      ServiceToken: !GetAtt RunSSMDocLambda.Arn
      ServiceTimeout: 905
      InstanceId: !Ref CodeEditorInstance
      DocumentName: !Ref CodeEditorSSMDoc
      CloudWatchLogGroupName: !Ref SSMDocumentLogGroup
      CodeEditorPassword: !GetAtt SecretPlaintext.password
      BootstrapScriptUrl: !Ref BootstrapScriptUrl
      RepoUrl: !Ref RepoUrl
      HomeFolder: !Ref HomeFolder
      DBSecretArn: !Ref DBSecretArn
      DBClusterEndpoint: !Ref DBClusterEndpoint
      DBClusterArn: !Ref DBClusterArn
      DBName: !Ref DBName

  # Cache Policy for CloudFront
  CodeEditorCachePolicy:
    Type: AWS::CloudFront::CachePolicy
    Properties:
      CachePolicyConfig:
        DefaultTTL: 86400
        MaxTTL: 31536000
        MinTTL: 1
        Name: !Sub
        - ${InstanceName}-${RandomGUID}
        - RandomGUID: !Select [0, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId ]]]]
        ParametersInCacheKeyAndForwardedToOrigin:
          CookiesConfig:
            CookieBehavior: all
          EnableAcceptEncodingGzip: False
          HeadersConfig:
            HeaderBehavior: whitelist
            Headers:
              - Accept-Charset
              - Authorization
              - Origin
              - Accept
              - Referer
              - Host
              - Accept-Language
              - Accept-Encoding
              - Accept-Datetime
          QueryStringsConfig:
            QueryStringBehavior: all

  # CloudFront Distribution
  CloudFrontDistribution:
    Type: AWS::CloudFront::Distribution
    DependsOn: RunCodeEditorSSMDoc
    Properties:
      DistributionConfig:
        Enabled: true
        HttpVersion: http2and3
        DefaultCacheBehavior:
          AllowedMethods: [GET, HEAD, OPTIONS, PUT, PATCH, POST, DELETE]
          CachePolicyId: !Ref CodeEditorCachePolicy
          OriginRequestPolicyId: 216adef6-5c7f-47e4-b989-5492eafa07d3
          TargetOriginId: !Sub 'origin-${AWS::StackName}'
          ViewerProtocolPolicy: allow-all
        Origins:
          - DomainName: !GetAtt CodeEditorInstance.PublicDnsName
            Id: !Sub 'origin-${AWS::StackName}'
            CustomOriginConfig:
              OriginProtocolPolicy: http-only

Outputs:
  URL:
    Description: Code Editor URL (with token authentication)
    Value: !Sub 'https://${CloudFrontDistribution.DomainName}/?folder=${HomeFolder}&tkn=${SecretPlaintext.password}'
    
  Username:
    Description: Username
    Value: !GetAtt SecretPlaintext.username
    
  Password:
    Description: Password (use for token authentication)
    Value: !GetAtt SecretPlaintext.password
    
  CloudFrontURL:
    Description: CloudFront URL (base)
    Value: !Sub 'https://${CloudFrontDistribution.DomainName}'
    
  TokenAuthURL:
    Description: Direct token authentication URL
    Value: !Sub 'https://${CloudFrontDistribution.DomainName}/?tkn=${SecretPlaintext.password}'
    
  InstanceId:
    Description: EC2 Instance ID
    Value: !Ref CodeEditorInstance

  BootstrapLogs:
    Description: CloudWatch Logs for bootstrap execution
    Value: !Sub 'https://console.aws.amazon.com/cloudwatch/home?region=${AWS::Region}#logsV2:log-groups/log-group/${SSMDocumentLogGroup}'