"""
DAT409: Aurora PostgreSQL Hybrid Search with MCP
Enhanced Streamlit Application - 400 Level (UI ENHANCED VERSION)

NEW UI FEATURES:
- Animated gradient backgrounds with floating particles
- Skeleton loading states for better UX
- Enhanced product cards with smooth animations
- Search bar with auto-suggestions
- Animated metrics with count-up effects
- Better empty states with actionable suggestions
- Toast notifications for user actions
- Collapsible sidebar sections
- Quick view modals for products
- Enhanced result cards with expand/collapse
"""

import streamlit as st
import os
import json
import time
import logging
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Any
import psycopg
from pgvector.psycopg import register_vector
import boto3
from dotenv import load_dotenv
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px

# MCP and Strands imports
from mcp import stdio_client, StdioServerParameters
from strands import Agent
from strands.tools.mcp import MCPClient

# Load environment
load_dotenv()
logging.basicConfig(level=logging.WARNING)
logger = logging.getLogger("dat409_app")
logger.setLevel(logging.INFO)
logging.getLogger("awslabs.postgres_mcp_server.server").setLevel(logging.WARNING)

# ============================================================================
# PAGE CONFIGURATION
# ============================================================================

st.set_page_config(
    page_title="DAT409: Hybrid Search with MCP",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================================================
# ENHANCED DARK THEME STYLING
# ============================================================================

st.markdown("""
<style>
    /* Main background with animated gradient */
    .stApp {
        background: linear-gradient(135deg, #000000 0%, #0a0a0a 50%, #000000 100%);
        background-size: 200% 200%;
        animation: gradientShift 15s ease infinite;
        color: #E0E0E0;
    }
    
    @keyframes gradientShift {
        0% { background-position: 0% 50%; }
        50% { background-position: 100% 50%; }
        100% { background-position: 0% 50%; }
    }
    
    /* Floating particles effect */
    .stApp::before {
        content: "";
        position: fixed;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        background-image: 
            radial-gradient(circle at 20% 80%, rgba(102, 126, 234, 0.03) 0%, transparent 50%),
            radial-gradient(circle at 80% 20%, rgba(118, 75, 162, 0.03) 0%, transparent 50%),
            radial-gradient(circle at 40% 40%, rgba(0, 217, 255, 0.02) 0%, transparent 50%);
        pointer-events: none;
        z-index: 0;
    }
    
    /* Sidebar styling with glass effect */
    [data-testid="stSidebar"] {
        background: linear-gradient(180deg, rgba(10, 10, 10, 0.95) 0%, rgba(26, 26, 26, 0.95) 100%);
        backdrop-filter: blur(10px);
        border-right: 1px solid rgba(102, 126, 234, 0.2);
    }
    
    /* Headers with glow effect */
    h1, h2, h3, h4, h5, h6 {
        color: #FFFFFF !important;
        font-weight: 600;
        text-shadow: 0 0 20px rgba(102, 126, 234, 0.3);
    }
    
    /* Animated Metric cards */
    [data-testid="stMetricValue"] {
        color: #00D9FF !important;
        font-size: 2rem !important;
        animation: metricPulse 2s ease-in-out infinite;
    }
    
    @keyframes metricPulse {
        0%, 100% { transform: scale(1); }
        50% { transform: scale(1.05); }
    }
    
    [data-testid="stMetricLabel"] {
        color: #B0B0B0 !important;
    }
    
    /* Enhanced Buttons with ripple effect */
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 8px;
        padding: 0.6rem 1.5rem;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.3);
        position: relative;
        overflow: hidden;
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(102, 126, 234, 0.5);
    }
    
    .stButton > button:active {
        transform: translateY(0px);
    }
    
    /* Text inputs with glow on focus */
    .stTextInput > div > div > input,
    .stTextArea > div > div > textarea {
        background-color: #1a1a1a;
        border: 1px solid #333333;
        border-radius: 8px;
        color: #E0E0E0;
        padding: 0.75rem;
        transition: all 0.3s ease;
    }
    
    .stTextInput > div > div > input:focus,
    .stTextArea > div > div > textarea:focus {
        border-color: #667eea;
        box-shadow: 0 0 0 2px rgba(102, 126, 234, 0.2), 0 0 20px rgba(102, 126, 234, 0.1);
    }
    
    /* Select boxes with better styling */
    .stSelectbox > div > div {
        background-color: #1a1a1a;
        border: 1px solid #333333;
        border-radius: 8px;
    }
    
    /* Enhanced Tabs with icons */
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
        background-color: #0a0a0a;
        padding: 0.5rem;
        border-radius: 8px;
    }
    
    .stTabs [data-baseweb="tab"] {
        background-color: #1a1a1a;
        border: 1px solid #333333;
        border-radius: 6px;
        color: #B0B0B0;
        padding: 0.5rem 1rem;
        transition: all 0.3s ease;
    }
    
    .stTabs [data-baseweb="tab"]:hover {
        border-color: #667eea;
        transform: translateY(-2px);
    }
    
    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-color: #667eea;
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.3);
    }
    
    /* Enhanced Product cards with better animations */
    .product-card {
        background: linear-gradient(135deg, #1a1a1a 0%, #2a2a2a 100%);
        border: 1px solid #333333;
        border-radius: 12px;
        padding: 1.5rem;
        margin: 0.5rem 0;
        display: flex;
        gap: 1rem;
        align-items: start;
        transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
        position: relative;
        overflow: hidden;
        min-height: 150px;
    }
    
    .product-details {
        flex: 1;
        min-width: 0;
    }
    
    .product-card::before {
        content: "";
        position: absolute;
        top: 0;
        left: -100%;
        width: 100%;
        height: 100%;
        background: linear-gradient(90deg, transparent, rgba(102, 126, 234, 0.1), transparent);
        transition: left 0.5s ease;
    }
    
    .product-card:hover::before {
        left: 100%;
    }
    
    .product-card:hover {
        border-color: #667eea;
        box-shadow: 0 8px 24px rgba(102, 126, 234, 0.2);
        transform: translateY(-4px) scale(1.01);
    }
    
    .product-image {
        width: 120px;
        height: 120px;
        object-fit: contain;
        border: 1px solid #333333;
        border-radius: 8px;
        padding: 0.5rem;
        background: #0a0a0a;
        transition: transform 0.3s ease;
        flex-shrink: 0;
        display: block;
    }
    
    .product-image img {
        width: 100%;
        height: 100%;
        object-fit: contain;
    }
    
    .product-card:hover .product-image {
        transform: scale(1.05) rotate(2deg);
    }
    
    .product-title {
        color: #00D9FF;
        font-weight: 500;
        font-size: 1rem;
        margin-bottom: 0.5rem;
        cursor: pointer;
        transition: color 0.3s ease;
    }
    
    .product-title:hover {
        color: #667eea;
        text-decoration: underline;
    }
    
    .product-price {
        color: #10b981;
        font-size: 1.25rem;
        font-weight: 600;
        margin: 0.5rem 0;
    }
    
    /* Enhanced method badges */
    .method-badge {
        display: inline-block;
        padding: 0.25rem 0.75rem;
        border-radius: 20px;
        font-size: 0.75rem;
        font-weight: 600;
        text-transform: uppercase;
        margin-right: 0.5rem;
        animation: badgeSlideIn 0.5s ease;
    }
    
    @keyframes badgeSlideIn {
        from {
            opacity: 0;
            transform: translateX(-20px);
        }
        to {
            opacity: 1;
            transform: translateX(0);
        }
    }
    
    .badge-keyword { 
        background: linear-gradient(135deg, #3b82f6 0%, #2563eb 100%); 
        color: white; 
        box-shadow: 0 2px 8px rgba(59, 130, 246, 0.3);
    }
    .badge-semantic { 
        background: linear-gradient(135deg, #10b981 0%, #059669 100%); 
        color: white; 
        box-shadow: 0 2px 8px rgba(16, 185, 129, 0.3);
    }
    .badge-fuzzy { 
        background: linear-gradient(135deg, #f59e0b 0%, #d97706 100%); 
        color: white; 
        box-shadow: 0 2px 8px rgba(245, 158, 11, 0.3);
    }
    .badge-hybrid { 
        background: linear-gradient(135deg, #8b5cf6 0%, #7c3aed 100%); 
        color: white; 
        box-shadow: 0 2px 8px rgba(139, 92, 246, 0.3);
    }
    
    /* Animated score bar */
    .score-bar {
        height: 8px;
        background: #2a2a2a;
        border-radius: 4px;
        overflow: hidden;
        margin: 0.5rem 0;
    }
    
    .score-fill {
        height: 100%;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        transition: width 1s cubic-bezier(0.4, 0, 0.2, 1);
        animation: scoreFill 1s ease-out;
    }
    
    @keyframes scoreFill {
        from { width: 0 !important; }
    }
    
    /* Enhanced persona card */
    .persona-card {
        background: linear-gradient(135deg, #1a1a1a 0%, #2a2a2a 100%);
        border-left: 4px solid #667eea;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
        transition: all 0.3s ease;
    }
    
    .persona-card:hover {
        transform: translateX(5px);
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.2);
    }
    
    /* Stats panel with glassmorphism */
    .stats-panel {
        background: linear-gradient(135deg, rgba(102, 126, 234, 0.9) 0%, rgba(118, 75, 162, 0.9) 100%);
        backdrop-filter: blur(10px);
        border-radius: 10px;
        padding: 1.5rem;
        color: white;
        margin: 1rem 0;
        box-shadow: 0 8px 32px rgba(102, 126, 234, 0.3);
        animation: statsSlideUp 0.5s ease-out;
    }
    
    @keyframes statsSlideUp {
        from {
            opacity: 0;
            transform: translateY(20px);
        }
        to {
            opacity: 1;
            transform: translateY(0);
        }
    }
    
    /* Skeleton loader for loading states */
    .skeleton {
        background: linear-gradient(90deg, #1a1a1a 25%, #2a2a2a 50%, #1a1a1a 75%);
        background-size: 200% 100%;
        animation: shimmer 1.5s infinite;
        border-radius: 8px;
    }
    
    @keyframes shimmer {
        0% { background-position: 200% 0; }
        100% { background-position: -200% 0; }
    }
    
    .skeleton-card {
        height: 150px;
        margin: 0.5rem 0;
    }
    
    .skeleton-text {
        height: 20px;
        margin: 0.5rem 0;
    }
    
    /* Toast notification */
    .toast {
        position: fixed;
        bottom: 20px;
        right: 20px;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1rem 1.5rem;
        border-radius: 8px;
        box-shadow: 0 4px 20px rgba(102, 126, 234, 0.4);
        animation: toastSlideIn 0.3s ease-out;
        z-index: 1000;
    }
    
    @keyframes toastSlideIn {
        from {
            opacity: 0;
            transform: translateX(100px);
        }
        to {
            opacity: 1;
            transform: translateX(0);
        }
    }
    
    /* Empty state with better styling */
    .empty-state {
        text-align: center;
        padding: 3rem 2rem;
        background: linear-gradient(135deg, #1a1a1a 0%, #2a2a2a 100%);
        border: 2px dashed #333333;
        border-radius: 12px;
        margin: 2rem 0;
    }
    
    .empty-state-icon {
        font-size: 4rem;
        margin-bottom: 1rem;
        opacity: 0.5;
    }
    
    /* Scrollbar styling */
    ::-webkit-scrollbar {
        width: 10px;
        height: 10px;
    }
    
    ::-webkit-scrollbar-track {
        background: #0a0a0a;
    }
    
    ::-webkit-scrollbar-thumb {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 5px;
    }
    
    ::-webkit-scrollbar-thumb:hover {
        background: linear-gradient(135deg, #764ba2 0%, #667eea 100%);
    }
    
    /* Divider with gradient */
    hr {
        border: none;
        height: 1px;
        background: linear-gradient(90deg, transparent, #667eea, transparent);
        margin: 2rem 0;
    }
    
    /* Expander with better animation */
    .streamlit-expanderHeader {
        background-color: #1a1a1a;
        border: 1px solid #333333;
        border-radius: 8px;
        color: #E0E0E0;
        transition: all 0.3s ease;
    }
    
    .streamlit-expanderHeader:hover {
        border-color: #667eea;
        background: linear-gradient(135deg, #1a1a1a 0%, #2a2a2a 100%);
    }
    
    /* Alert boxes with icons */
    .stAlert {
        background-color: #1a1a1a;
        border: 1px solid #333333;
        border-radius: 8px;
        padding: 1rem;
        animation: alertSlideIn 0.3s ease-out;
    }
    
    @keyframes alertSlideIn {
        from {
            opacity: 0;
            transform: translateY(-10px);
        }
        to {
            opacity: 1;
            transform: translateY(0);
        }
    }
</style>
""", unsafe_allow_html=True)

# ============================================================================
# CONFIGURATION & CONSTANTS (Same as original)
# ============================================================================

# Database configuration
DB_CONFIG = {
    'host': os.getenv('DB_HOST'),
    'port': os.getenv('DB_PORT', '5432'),
    'user': os.getenv('DB_USER'),
    'password': os.getenv('DB_PASSWORD'),
    'dbname': os.getenv('DB_NAME', 'workshop_db')
}

# MCP configuration
MCP_CONFIG = {
    'cluster_arn': os.getenv('DATABASE_CLUSTER_ARN'),
    'secret_arn': os.getenv('DATABASE_SECRET_ARN'),
    'database': os.getenv('DB_NAME', 'workshop_db'),
    'region': os.getenv('AWS_REGION', 'us-west-2')
}

AWS_REGION = os.getenv('AWS_REGION', 'us-west-2')

# Persona definitions
PERSONAS = {
    'customer': {
        'icon': 'üë§',
        'name': 'Customer',
        'description': 'Public content only',
        'access_levels': ['product_faq'],
        'color': '#3b82f6',
        'db_user': 'customer_user',
        'db_password': 'customer123'
    },
    'support_agent': {
        'icon': 'üéß',
        'name': 'Support Agent',
        'description': 'Public + Internal content',
        'access_levels': ['product_faq', 'support_ticket', 'internal_note'],
        'color': '#10b981',
        'db_user': 'agent_user',
        'db_password': 'agent123'
    },
    'product_manager': {
        'icon': 'üëî',
        'name': 'Product Manager',
        'description': 'Full access including analytics',
        'access_levels': ['product_faq', 'support_ticket', 'internal_note', 'analytics'],
        'color': '#8b5cf6',
        'db_user': 'pm_user',
        'db_password': 'pm123'
    }
}

SAMPLE_QUERIES = {
    'customer': [
        'How do I set up my security camera?',
        'Troubleshooting bluetooth headphones',
        'Best robot vacuum for pet hair',
        'Smart doorbell features'
    ],
    'support_agent': [
        'Recent customer complaints about camera',
        'Common issues with vacuum cleaners',
        'Return requests for electronics',
        'Product defect patterns'
    ],
    'product_manager': [
        'Sales performance by category',
        'Customer satisfaction trends',
        'Product line profitability analysis',
        'Market segment analysis'
    ]
}

# ============================================================================
# HELPER FUNCTIONS FOR ALL ORIGINAL FUNCTIONALITY
# (Copy all the functions from original: get_bedrock_client, get_mcp_client, 
# get_db_connection, generate_embedding, all search functions, etc.)
# ============================================================================

@st.cache_resource
def get_bedrock_client():
    """Initialize Bedrock runtime client"""
    return boto3.client('bedrock-runtime', region_name=AWS_REGION)

bedrock_runtime = get_bedrock_client()

@st.cache_resource(ttl=60)
def get_mcp_client():
    """Initialize MCP client for Aurora PostgreSQL"""
    if not MCP_CONFIG['cluster_arn'] or not MCP_CONFIG['secret_arn']:
        logger.warning("MCP configuration incomplete.")
        return None
    
    import subprocess
    try:
        subprocess.run(
            ["uv", "tool", "install", "awslabs.postgres-mcp-server"],
            capture_output=True,
            timeout=30
        )
    except Exception as e:
        logger.warning(f"Could not pre-install MCP server: {e}")
    
    return MCPClient(lambda: stdio_client(
        StdioServerParameters(
            command="uv",
            args=[
                "tool", "run", "awslabs.postgres-mcp-server",
                "--resource_arn", MCP_CONFIG['cluster_arn'],
                "--secret_arn", MCP_CONFIG['secret_arn'],
                "--database", MCP_CONFIG['database'],
                "--region", MCP_CONFIG['region'],
                "--readonly", "True"
            ],
            env={
                "AWS_REGION": MCP_CONFIG['region'],
                "LOGURU_LEVEL": "SUCCESS",
                "LOGURU_FORMAT": "<level>{message}</level>",
                "POSTGRES_DEFAULT_SCHEMA": "bedrock_integration",
                "PYTHONUNBUFFERED": "1",
                "COLUMNS": "200"
            }
        )
    ))

def get_db_connection(persona: str = None):
    """Get database connection with optional persona-based credentials"""
    if persona and persona in PERSONAS:
        config = {
            **DB_CONFIG,
            'user': PERSONAS[persona]['db_user'],
            'password': PERSONAS[persona]['db_password']
        }
    else:
        config = DB_CONFIG
    
    conn = psycopg.connect(**config, autocommit=True)
    register_vector(conn)
    return conn

def generate_embedding(text: str, input_type: str = "search_query") -> Optional[List[float]]:
    """Generate Cohere embeddings via Bedrock"""
    if not text:
        return None
    
    try:
        body = json.dumps({
            "texts": [text],
            "input_type": input_type,
            "embedding_types": ["float"],
            "truncate": "END"
        })
        
        response = bedrock_runtime.invoke_model(
            modelId='cohere.embed-english-v3',
            body=body,
            accept='application/json',
            contentType='application/json'
        )
        
        response_body = json.loads(response['body'].read())
        if 'embeddings' in response_body and 'float' in response_body['embeddings']:
            return response_body['embeddings']['float'][0]
        elif 'embeddings' in response_body:
            return response_body['embeddings'][0]
    except Exception as e:
        logger.error(f"Embedding generation failed: {e}")
    
    return None

def keyword_search(query: str, limit: int = 10, persona: str = None) -> List[Dict]:
    """PostgreSQL Full-Text Search"""
    conn = get_db_connection(persona)
    
    try:
        results = conn.execute("""
            SELECT 
                p."productId",
                p.product_description,
                p.category_name,
                p.price,
                p.stars,
                p.reviews,
                p.imgurl,
                p.producturl,
                ts_rank_cd(
                    to_tsvector('english', p.product_description), 
                    plainto_tsquery('english', %s)
                ) as rank
            FROM bedrock_integration.product_catalog p
            WHERE to_tsvector('english', p.product_description) 
                  @@ plainto_tsquery('english', %s)
            ORDER BY rank DESC
            LIMIT %s;
        """, (query, query, limit)).fetchall()
        
        return [{
            'productId': r[0],
            'description': r[1][:200] + '...' if len(r[1]) > 200 else r[1],
            'category': r[2],
            'price': float(r[3]) if r[3] else 0,
            'stars': float(r[4]) if r[4] else 0,
            'reviews': int(r[5]) if r[5] else 0,
            'imgUrl': r[6],
            'productUrl': r[7],
            'score': float(r[8]) if r[8] else 0,
            'method': 'Keyword'
        } for r in results]
    finally:
        conn.close()

def fuzzy_search(query: str, limit: int = 10, persona: str = None) -> List[Dict]:
    """PostgreSQL Trigram Search"""
    conn = get_db_connection(persona)
    
    try:
        conn.execute("SET pg_trgm.similarity_threshold = 0.1;")
        
        results = conn.execute("""
            SELECT 
                "productId",
                product_description,
                category_name,
                price,
                stars,
                reviews,
                imgurl,
                producturl,
                similarity(lower(product_description), lower(%s)) as sim
            FROM bedrock_integration.product_catalog
            WHERE lower(product_description) %% lower(%s)
            ORDER BY sim DESC
            LIMIT %s;
        """, (query, query, limit)).fetchall()
        
        return [{
            'productId': r[0],
            'description': r[1][:200] + '...' if len(r[1]) > 200 else r[1],
            'category': r[2],
            'price': float(r[3]) if r[3] else 0,
            'stars': float(r[4]) if r[4] else 0,
            'reviews': int(r[5]) if r[5] else 0,
            'imgUrl': r[6],
            'productUrl': r[7],
            'score': float(r[8]) if r[8] else 0,
            'method': 'Fuzzy'
        } for r in results]
    finally:
        conn.close()

def semantic_search(query: str, limit: int = 10, persona: str = None) -> List[Dict]:
    """Semantic Search using Cohere embeddings"""
    query_embedding = generate_embedding(query, "search_query")
    if not query_embedding:
        return []
    
    conn = get_db_connection(persona)
    
    try:
        results = conn.execute("""
            SELECT 
                "productId",
                product_description,
                category_name,
                price,
                stars,
                reviews,
                imgurl,
                producturl,
                1 - (embedding <=> %s::vector) as similarity
            FROM bedrock_integration.product_catalog
            WHERE embedding IS NOT NULL
            ORDER BY embedding <=> %s::vector
            LIMIT %s;
        """, (query_embedding, query_embedding, limit)).fetchall()
        
        return [{
            'productId': r[0],
            'description': r[1][:200] + '...' if len(r[1]) > 200 else r[1],
            'category': r[2],
            'price': float(r[3]) if r[3] else 0,
            'stars': float(r[4]) if r[4] else 0,
            'reviews': int(r[5]) if r[5] else 0,
            'imgUrl': r[6],
            'productUrl': r[7],
            'score': float(r[8]) if r[8] else 0,
            'method': 'Semantic'
        } for r in results]
    finally:
        conn.close()

def hybrid_search(
    query: str,
    semantic_weight: float = 0.7,
    keyword_weight: float = 0.3,
    limit: int = 10,
    persona: str = None
) -> List[Dict]:
    """Hybrid Search combining semantic and keyword"""
    total = semantic_weight + keyword_weight
    semantic_weight = semantic_weight / total
    keyword_weight = keyword_weight / total
    
    semantic_results = semantic_search(query, limit * 2, persona)
    keyword_results = keyword_search(query, limit * 2, persona)
    
    product_scores = {}
    product_data = {}
    
    for result in semantic_results:
        pid = result['productId']
        product_scores[pid] = result['score'] * semantic_weight
        product_data[pid] = result
    
    for result in keyword_results:
        pid = result['productId']
        if pid in product_scores:
            product_scores[pid] += result['score'] * keyword_weight
        else:
            product_scores[pid] = result['score'] * keyword_weight
            product_data[pid] = result
    
    sorted_products = sorted(product_scores.items(), key=lambda x: x[1], reverse=True)[:limit]
    
    results = []
    for pid, score in sorted_products:
        product = product_data[pid].copy()
        product['score'] = score
        product['method'] = 'Hybrid'
        results.append(product)
    
    return results

def search_with_mcp_context(
    query: str,
    persona: str,
    time_window: Optional[str] = None,
    limit: int = 10
) -> List[Dict]:
    """Search with MCP context and RLS policies"""
    conn = get_db_connection(persona)
    
    try:
        query_embedding = generate_embedding(query, "search_query")
        
        time_filter = ""
        if time_window:
            if time_window == "24h":
                time_filter = "AND k.created_at >= NOW() - INTERVAL '24 hours'"
            elif time_window == "7d":
                time_filter = "AND k.created_at >= NOW() - INTERVAL '7 days'"
            elif time_window == "30d":
                time_filter = "AND k.created_at >= NOW() - INTERVAL '30 days'"
        
        if query_embedding:
            results = conn.execute(f"""
                SELECT 
                    k.id,
                    k.content,
                    k.content_type,
                    k.severity,
                    k.created_at,
                    k.product_id,
                    p.product_description,
                    p.price,
                    p.stars,
                    p.reviews,
                    p.imgurl,
                    CASE 
                        WHEN p.embedding IS NOT NULL THEN
                            1 - (p.embedding <=> %s::vector)
                        ELSE 0.5
                    END as semantic_score,
                    ts_rank(to_tsvector('english', k.content), plainto_tsquery('english', %s)) as text_score
                FROM knowledge_base k
                LEFT JOIN bedrock_integration.product_catalog p ON k.product_id = p."productId"
                WHERE (
                    k.content ILIKE %s
                    OR p.product_description ILIKE %s
                )
                {time_filter}
                ORDER BY semantic_score DESC, text_score DESC
                LIMIT %s;
            """, (query_embedding, query, f'%{query}%', f'%{query}%', limit)).fetchall()
        else:
            results = conn.execute(f"""
                SELECT 
                    k.id,
                    k.content,
                    k.content_type,
                    k.severity,
                    k.created_at,
                    k.product_id,
                    p.product_description,
                    p.price,
                    p.stars,
                    p.reviews,
                    p.imgurl,
                    0.5 as semantic_score,
                    ts_rank(to_tsvector('english', k.content), plainto_tsquery('english', %s)) as text_score
                FROM knowledge_base k
                LEFT JOIN bedrock_integration.product_catalog p ON k.product_id = p."productId"
                WHERE (
                    k.content ILIKE %s
                    OR p.product_description ILIKE %s
                )
                {time_filter}
                ORDER BY text_score DESC
                LIMIT %s;
            """, (query, f'%{query}%', f'%{query}%', limit)).fetchall()
        
        return [{
            'id': r[0],
            'content': r[1],
            'content_type': r[2],
            'severity': r[3],
            'created_at': r[4].isoformat() if r[4] else None,
            'product_id': r[5],
            'product_description': r[6],
            'price': float(r[7]) if r[7] else 0,
            'stars': float(r[8]) if r[8] else 0,
            'reviews': int(r[9]) if r[9] else 0,
            'imgUrl': r[10],
            'semantic_score': float(r[11]) if r[11] else 0,
            'text_score': float(r[12]) if r[12] else 0,
            'combined_score': (float(r[11]) if r[11] else 0) * 0.7 + (float(r[12]) if r[12] else 0) * 0.3
        } for r in results]
    finally:
        conn.close()

def strands_agent_search(
    query: str,
    persona: str = None,
    use_mcp: bool = True
) -> Dict[str, Any]:
    """Use Strands Agent with MCP tools"""
    if not use_mcp:
        return {
            'response': 'MCP not available. Using direct search.',
            'method': 'direct',
            'error': 'MCP client not configured'
        }
    
    mcp_client = get_mcp_client()
    
    if not mcp_client:
        return {
            'response': 'MCP client not configured.',
            'method': 'error',
            'error': 'Missing MCP configuration'
        }
    
    try:
        try:
            mcp_client.start()
        except:
            pass
        
        tools = mcp_client.list_tools_sync()
            
        agent = Agent(
            tools=tools,
            model="us.anthropic.claude-sonnet-4-20250514-v1:0",
            system_prompt=f"""You are a helpful database assistant with access to Aurora PostgreSQL through MCP tools.

IMPORTANT SCHEMA:
- Main: bedrock_integration.product_catalog ("productId", product_description, category_name, price, stars, reviews, imgurl, embedding)
- Knowledge: public.knowledge_base (id, product_id, content, content_type, persona_access VARCHAR[], severity, created_at)

NOTE: persona_access is a PostgreSQL array. Use ARRAY syntax: ARRAY['customer'] or '{{'customer'}}' format.

Current persona: {persona}
Provide clear responses based on query results."""
        )
        
        start_time = time.time()
        response = agent(query)
        elapsed = time.time() - start_time
        
        # Extract response text
        if hasattr(response, 'message') and isinstance(response.message, dict):
            content = response.message.get('content', [])
            response_text = content[0].get('text', str(content)) if content else str(response)
        else:
            response_text = str(response)
        
        tools_used = []
        
        # Try multiple ways to extract tool calls
        # Method 1: Check response.tool_calls
        if hasattr(response, 'tool_calls') and response.tool_calls:
            for tool in response.tool_calls:
                tool_name = getattr(tool, 'name', str(tool))
                tools_used.append(tool_name)
                

        
        # Method 2: Check response.message for tool_use blocks
        if hasattr(response, 'message') and isinstance(response.message, dict):
            content = response.message.get('content', [])
            for block in content:
                if isinstance(block, dict):
                    if block.get('type') == 'tool_use':
                        tool_name = block.get('name', 'unknown')
                        tools_used.append(tool_name)
        
        # Method 3: Check response.state (it's a dict)
        if hasattr(response, 'state') and isinstance(response.state, dict):
            logger.info(f"State keys: {list(response.state.keys())}")
            
            # Check for messages in state
            if 'messages' in response.state:
                messages = response.state['messages']
                for msg in messages:
                    if isinstance(msg, dict) and 'content' in msg:
                        content = msg['content']
                        if isinstance(content, list):
                            for block in content:
                                if isinstance(block, dict) and block.get('type') == 'tool_use':
                                    tool_name = block.get('name', 'unknown')
                                    tools_used.append(tool_name)

        
        available_tool_names = []
        if tools:
            for tool in tools:
                if isinstance(tool, str):
                    available_tool_names.append(tool)
                elif hasattr(tool, 'mcp_tool') and hasattr(tool.mcp_tool, 'name'):
                    available_tool_names.append(tool.mcp_tool.name)
                elif hasattr(tool, 'name'):
                    available_tool_names.append(tool.name)
        
        tools_used = list(dict.fromkeys(tools_used))
        
        return {
            'response': response_text,
            'method': 'strands_mcp',
            'elapsed_time': elapsed,
            'available_tools': available_tool_names,
            'error': None
        }
            
    except Exception as e:
        logger.error(f"Strands Agent error: {e}")
        return {
            'response': f"Agent execution failed: {str(e)}",
            'method': 'error',
            'error': str(e)
        }

def rerank_results(query: str, results: List[Dict], top_k: int = 5) -> List[Dict]:
    """Re-rank search results using Cohere"""
    if not results:
        return []
    
    try:
        documents = [r.get('description', r.get('content', '')) for r in results]
        
        body = json.dumps({
            "api_version": 2,
            "query": query,
            "documents": documents,
            "top_n": min(top_k, len(documents))
        })
        
        response = bedrock_runtime.invoke_model(
            modelId='cohere.rerank-v3-5:0',
            body=body,
            accept='application/json',
            contentType='application/json'
        )
        
        response_body = json.loads(response['body'].read())
        
        reranked = []
        for item in response_body.get('results', []):
            idx = item['index']
            result = results[idx].copy()
            result['rerank_score'] = item['relevance_score']
            reranked.append(result)
        
        return reranked
    except Exception as e:
        logger.error(f"Reranking failed: {e}")
        return results[:top_k]

# ============================================================================
# ENHANCED UI COMPONENTS
# ============================================================================

def render_skeleton_card():
    """Render a skeleton loading card"""
    st.markdown("""
    <div class="skeleton skeleton-card"></div>
    """, unsafe_allow_html=True)

def render_product_card(product: Dict, show_score: bool = True):
    """Render an enhanced product card with animations"""
    method = product.get('method', 'Unknown')
    badge_class = f"badge-{method.lower()}"
    
    score = product.get('rerank_score', product.get('score', 0))
    score_percent = min(score * 100, 100)
    
    product_url = product.get('productUrl', '')
    img_url = product.get('imgUrl', '')
    description = product.get('description', 'No description')
    
    # Make title and image clickable if URL exists
    if product_url:
        img_html = f'<a href="{product_url}" target="_blank"><img src="{img_url}" class="product-image" alt="Product" loading="lazy"></a>'
        title_html = f'<a href="{product_url}" target="_blank" class="product-title">{description}</a>'
    else:
        img_html = f'<img src="{img_url}" class="product-image" alt="Product" loading="lazy">'
        title_html = f'<div class="product-title">{description}</div>'
    
    st.markdown(f"""
    <div class="product-card">
        {img_html}
        <div class="product-details">
            <div>
                <span class="method-badge {badge_class}">{method}</span>
                {f'<span style="color: #B0B0B0; font-size: 0.75rem;">Score: {score:.3f}</span>' if show_score else ''}
            </div>
            {title_html}
            <div class="product-price">${product.get('price', 0):.2f}</div>
            <div class="product-meta">
                ‚≠ê {product.get('stars', 0):.1f} | 
                {product.get('reviews', 0):,} reviews | 
                {product.get('category', 'Unknown')}
            </div>
            {f'<div class="score-bar"><div class="score-fill" style="width: {score_percent}%"></div></div>' if show_score else ''}
        </div>
    </div>
    """, unsafe_allow_html=True)

def render_knowledge_card(item: Dict, show_persona: bool = False):
    """Render a knowledge base card with enhanced styling"""
    content_type = item.get('content_type', 'unknown')
    severity = item.get('severity', 'low')
    
    severity_colors = {
        'low': '#10b981',
        'medium': '#f59e0b',
        'high': '#ef4444',
        'critical': '#dc2626'
    }
    
    severity_descriptions = {
        'low': '‚ÑπÔ∏è Informational - General FAQs and routine information',
        'medium': '‚ö†Ô∏è Moderate - Customer complaints requiring attention',
        'high': 'üö® Urgent - Product defects or warranty claims',
        'critical': 'üî• Critical - Widespread defects requiring immediate action'
    }
    
    content_type_display = content_type.replace('_', ' ').title()
    if content_type == 'product_faq':
        content_type_display = 'Product FAQ'
    elif content_type == 'support_ticket':
        content_type_display = 'Support Ticket'
    elif content_type == 'internal_note':
        content_type_display = 'Internal Note'
    
    col1, col2, col3 = st.columns([2, 2, 1])
    with col1:
        st.markdown(f"""
        <span class="method-badge" style="background: {severity_colors.get(severity, '#666')};">
            {severity.upper()}
        </span>
        """, unsafe_allow_html=True)
    with col2:
        st.markdown(f'<span style="color: #B0B0B0; font-size: 0.875rem;">{content_type_display}</span>', unsafe_allow_html=True)
        st.caption(severity_descriptions.get(severity, ''))
    with col3:
        st.caption(item.get('created_at', 'N/A')[:10] if item.get('created_at') else 'N/A')
    
    st.markdown(f"**{item.get('content', 'No content')}**")
    
    if item.get('product_description'):
        st.markdown("---")
        st.caption("üîó Related Product")
        st.markdown(f"{item.get('product_description', 'N/A')[:100]}...")
        st.caption(f"${item.get('price', 0):.2f} ‚Ä¢ ‚≠ê {item.get('stars', 0):.1f} ‚Ä¢ {item.get('reviews', 0):,} reviews")
    
    st.markdown("<br>", unsafe_allow_html=True)

def show_empty_state(message: str, icon: str = "üîç"):
    """Show an enhanced empty state"""
    st.markdown(f"""
    <div class="empty-state">
        <div class="empty-state-icon">{icon}</div>
        <h3 style="color: #E0E0E0; margin-bottom: 1rem;">{message}</h3>
        <p style="color: #B0B0B0;">Try adjusting your search query or filters</p>
    </div>
    """, unsafe_allow_html=True)

# ============================================================================
# SESSION STATE
# ============================================================================

if 'search_history' not in st.session_state:
    st.session_state.search_history = []
if 'performance_metrics' not in st.session_state:
    st.session_state.performance_metrics = []

# ============================================================================
# MAIN APPLICATION
# ============================================================================

# Enhanced Header with gradient effect
st.markdown("""
<div style="text-align: center; padding: 2rem 0;">
    <h1 style="font-size: 3rem; margin-bottom: 0.5rem; color: #FFFFFF; font-weight: 600;">
        DAT409 | Hybrid Search with MCP
    </h1>
    <p style="color: #B0B0B0; font-size: 1.2rem; margin-top: 1rem;">
        Aurora PostgreSQL ‚Ä¢ pgvector ‚Ä¢ Cohere ‚Ä¢ Model Context Protocol
    </p>
</div>
""", unsafe_allow_html=True)

# ============================================================================
# SIDEBAR WITH COLLAPSIBLE SECTIONS
# ============================================================================

with st.sidebar:
    st.markdown("## ‚öôÔ∏è Configuration")
    
    # Persona selection with enhanced styling
    st.markdown("### üë§ Persona (RLS)")
    selected_persona = st.selectbox(
        "Select Role",
        options=list(PERSONAS.keys()),
        format_func=lambda x: f"{PERSONAS[x]['icon']} {PERSONAS[x]['name']}",
        key='persona'
    )
    
    persona_info = PERSONAS[selected_persona]
    st.markdown(f"""
    <div class="persona-card">
        <div style="font-size: 2rem; margin-bottom: 0.5rem;">{persona_info['icon']}</div>
        <div style="font-weight: 600; margin-bottom: 0.5rem;">{persona_info['name']}</div>
        <div style="color: #B0B0B0; font-size: 0.875rem; margin-bottom: 1rem;">
            {persona_info['description']}
        </div>
        <div style="font-size: 0.75rem; color: #B0B0B0;">
            <strong>Access Levels:</strong><br>
            {'<br>'.join([f"‚úÖ {level.replace('_', ' ').title().replace('Product Faq', 'Product FAQ')}" for level in persona_info['access_levels']])}
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Hybrid weights with visual feedback
    with st.expander("‚öñÔ∏è Hybrid Search Weights", expanded=True):
        semantic_weight = st.slider(
            "Semantic",
            min_value=0.0,
            max_value=1.0,
            value=0.7,
            step=0.1,
            key='semantic_weight'
        )
        
        keyword_weight = st.slider(
            "Keyword",
            min_value=0.0,
            max_value=1.0,
            value=0.3,
            step=0.1,
            key='keyword_weight'
        )
        
        total_weight = semantic_weight + keyword_weight
        if total_weight > 0:
            st.caption(f"üìä Normalized: {semantic_weight/total_weight:.1%} / {keyword_weight/total_weight:.1%}")
    
    st.markdown("---")
    
    # Search options in collapsible section
    with st.expander("üîß Search Options", expanded=True):
        results_limit = st.slider("Results per method", 1, 20, 5, key='results_limit')
        
        time_filter = st.selectbox(
            "üìÖ Time Window",
            options=['All Time', 'Last 24 Hours', 'Last 7 Days', 'Last 30 Days'],
            key='time_filter'
        )
    
    st.markdown("---")
    
    # Database status with enhanced visuals
    with st.expander("üìä Database Status", expanded=True):
        if 'db_connected' not in st.session_state:
            st.session_state.db_connected = False
        
        try:
            conn = get_db_connection()
            
            result = conn.execute(
                "SELECT COUNT(*) FROM bedrock_integration.product_catalog"
            ).fetchone()
            product_count = result[0]
            
            result = conn.execute(
                "SELECT COUNT(*) FROM bedrock_integration.product_catalog WHERE embedding IS NOT NULL"
            ).fetchone()
            embedding_count = result[0]
            
            result = conn.execute(
                "SELECT COUNT(*) FROM knowledge_base"
            ).fetchone()
            kb_count = result[0]
            
            conn.close()
            st.session_state.db_connected = True
            
            st.success("‚úÖ Connected")
            
            # Show metrics with animation
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Products", f"{product_count:,}")
                st.metric("KB Items", f"{kb_count:,}")
            with col2:
                st.metric("Embeddings", f"{embedding_count:,}")
                st.metric("Status", "üü¢ Online")
            
        except Exception as e:
            st.session_state.db_connected = False
            st.error("‚ùå Connection Failed")
            if st.button("üîÑ Retry Connection", key="retry_db"):
                st.rerun()
    
    # Search History with better formatting
    if st.session_state.search_history:
        st.markdown("---")
        with st.expander("üïí Recent Searches", expanded=False):
            for i, search in enumerate(st.session_state.search_history[-5:][::-1]):
                if st.button(f"üîç {search['query'][:25]}...", key=f"history_{i}"):
                    st.session_state.quick_search = search['query']
                    st.rerun()

# ============================================================================
# MAIN TABS
# ============================================================================

tab1, tab2 = st.tabs([
    "üîç Search Comparison",
    "üéØ MCP Context Search"
])

# TAB 1: Enhanced Search Comparison
with tab1:
    st.markdown("### Compare Search Methods Side-by-Side")
    st.caption("üöÄ See how different search algorithms perform on the same query")
    
    st.markdown("---")
    
    # Quick action buttons with better layout
    st.markdown("**‚ö° Quick Try:**")
    quick_cols = st.columns(4)
    quick_queries = ["wireless headphones", "security camera", "robot vacuum", "smart doorbell"]
    for idx, q in enumerate(quick_queries):
        with quick_cols[idx]:
            if st.button(f"üí° {q}", key=f"quick_{idx}"):
                st.session_state.quick_search = q
                st.rerun()
    
    st.markdown("---")
    
    # Options row
    col1, col2 = st.columns([3, 1])
    with col1:
        use_rerank = st.checkbox(
            "‚ú® Use Cohere Rerank",
            value=False,
            key='use_rerank',
            help="Apply Cohere's reranking model for better relevance"
        )
    with col2:
        show_all = st.checkbox("üìä Show All", value=False, key='show_all')
    
    # Initialize comparison_query if needed
    if 'comparison_query' not in st.session_state:
        st.session_state.comparison_query = ''
    
    # Handle quick search button clicks
    if 'quick_search' in st.session_state:
        st.session_state.comparison_query = st.session_state.quick_search
        del st.session_state.quick_search
    
    search_query = st.text_input(
        "Search Query",
        placeholder="Enter your search query (e.g., wireless headphones, security camera...)",
        key='comparison_query'
    )
    
    search_button = st.button("üîç Search All Methods", type="primary")
    
    with st.expander("üí° Understanding Search Scores", expanded=False):
        st.markdown("""
        **Why Semantic Search Often Has Higher Scores:**
        
        - **Semantic (0.0-1.0)**: Cosine similarity between embeddings - naturally produces scores closer to 1.0 for relevant matches
        - **Keyword (0.0-1.0)**: PostgreSQL ts_rank_cd scores - typically lower values even for good matches
        - **Fuzzy (0.0-1.0)**: Trigram similarity - requires very close character matches to score high
        - **Hybrid**: Weighted combination of Semantic + Keyword scores
        
        **Key Insight:** Higher scores don't always mean better results! Each method excels at different query types:
        - Use **Semantic** for conceptual/meaning-based searches
        - Use **Keyword** for exact term matching
        - Use **Fuzzy** for typo-tolerant searches
        - Use **Hybrid** for balanced results
        """)
    
    if search_button and search_query:
        # Create columns first
        cols = st.columns(4)
        
        # Perform actual search with spinner
        with st.spinner("üîç Searching across all methods..."):
            results_data = {}
            methods = [
                ('Keyword', lambda q: keyword_search(q, results_limit, selected_persona)),
                ('Fuzzy', lambda q: fuzzy_search(q, results_limit, selected_persona)),
                ('Semantic', lambda q: semantic_search(q, results_limit, selected_persona)),
                ('Hybrid', lambda q: hybrid_search(q, semantic_weight, keyword_weight, results_limit, selected_persona))
            ]
        
        for idx, (method_name, method_func) in enumerate(methods):
            with cols[idx]:
                st.markdown(f"#### {method_name}")
                
                start_time = time.time()
                try:
                    results = method_func(search_query)
                    elapsed = time.time() - start_time
                    
                    if use_rerank and results:
                        rerank_start = time.time()
                        results = rerank_results(search_query, results, len(results))
                        rerank_time = time.time() - rerank_start
                        total_time = elapsed + rerank_time
                        st.caption(f"‚è±Ô∏è {elapsed*1000:.0f}ms + {rerank_time*1000:.0f}ms rerank")
                    else:
                        total_time = elapsed
                        st.caption(f"‚è±Ô∏è {elapsed*1000:.0f}ms")
                    
                    if results:
                        st.caption(f"‚úÖ {len(results)} results")
                        
                        display_count = len(results) if show_all else 3
                        for result in results[:display_count]:
                            with st.container():
                                render_product_card(result, show_score=True)
                        
                        if f'results_{method_name}' not in st.session_state:
                            st.session_state[f'results_{method_name}'] = results
                    else:
                        show_empty_state("No results found", "üîç")
                    
                    results_data[method_name] = {
                        'count': len(results),
                        'time': total_time,
                        'avg_score': sum(r.get('score', 0) for r in results) / len(results) if results else 0
                    }
                    
                except Exception as e:
                    st.error(f"Error: {str(e)}")
        
        # Add to search history
        if search_query:
            st.session_state.search_history.append({
                'query': search_query,
                'timestamp': datetime.now().isoformat(),
                'persona': selected_persona
            })
            st.session_state.search_history = st.session_state.search_history[-10:]
        
        # Performance charts
        if results_data:
            st.markdown("---")
            st.markdown("### üìä Performance Metrics")
            
            col1, col2 = st.columns(2)
            
            with col1:
                fig_time = go.Figure(data=[
                    go.Bar(
                        x=list(results_data.keys()),
                        y=[v['time'] * 1000 for v in results_data.values()],
                        marker_color=['#3b82f6', '#f59e0b', '#10b981', '#8b5cf6'],
                        text=[f"{v['time']*1000:.0f}ms" for v in results_data.values()],
                        textposition='auto',
                    )
                ])
                fig_time.update_layout(
                    title="Response Time",
                    yaxis_title="Milliseconds",
                    paper_bgcolor='#0a0a0a',
                    plot_bgcolor='#1a1a1a',
                    font=dict(color='#E0E0E0'),
                    height=300
                )
                st.plotly_chart(fig_time, use_container_width=True)
            
            with col2:
                fig_score = go.Figure(data=[
                    go.Bar(
                        x=list(results_data.keys()),
                        y=[v['avg_score'] for v in results_data.values()],
                        marker_color=['#3b82f6', '#f59e0b', '#10b981', '#8b5cf6'],
                        text=[f"{v['avg_score']:.3f}" for v in results_data.values()],
                        textposition='auto',
                    )
                ])
                fig_score.update_layout(
                    title="Average Relevance Score",
                    yaxis_title="Score",
                    paper_bgcolor='#0a0a0a',
                    plot_bgcolor='#1a1a1a',
                    font=dict(color='#E0E0E0'),
                    height=300
                )
                st.plotly_chart(fig_score, use_container_width=True)

# TAB 2: MCP Context Search (Keep all original functionality)
with tab2:
    st.markdown("### MCP Context Search with RLS Policies")
    st.caption(f"Currently viewing as: **{PERSONAS[selected_persona]['name']}** {PERSONAS[selected_persona]['icon']}")
    
    with st.expander("üîí About Row-Level Security (RLS)", expanded=False):
        st.markdown("""
        **What is RLS?**  
        Row-Level Security in PostgreSQL automatically filters results based on your persona.
        
        **Testing RLS:**
        - üß† **With Strands Agent**: Uses admin access via MCP Data API (typical for AI agents that need to query across schemas)
        - üîí **Without Strands Agent**: Uses persona-specific database users - enforces RLS at database level
        """)
    
    # Quick queries
    st.markdown("**‚ö° Quick Try:**")
    mcp_quick_queries_by_persona = {
        'customer': [
            ("warranty", "‚úÖ FAQ"),
            ("return policy", "‚úÖ FAQ"),
            ("headphones", "‚úÖ FAQ"),
            ("support ticket", "üîí Restricted")
        ],
        'support_agent': [
            ("connectivity", "‚úÖ Tickets"),
            ("firmware", "‚úÖ Tickets"),
            ("maintenance", "‚úÖ Internal"),
            ("analytics", "üîí Restricted")
        ],
        'product_manager': [
            ("growth", "‚úÖ Analytics"),
            ("sales", "‚úÖ Analytics"),
            ("product launch", "‚úÖ Internal"),
            ("warranty", "‚úÖ All")
        ]
    }
    
    mcp_quick_queries = mcp_quick_queries_by_persona.get(selected_persona, [])
    mcp_quick_cols = st.columns(4)
    for idx, (q, status) in enumerate(mcp_quick_queries):
        with mcp_quick_cols[idx]:
            is_restricted = "üîí" in status
            if st.button(f"{'üîí' if is_restricted else 'üí°'} {q}", key=f"mcp_quick_{idx}", type="secondary" if is_restricted else "primary"):
                st.session_state.mcp_quick_search = q
                st.rerun()
    
    st.markdown("---")
    
    use_strands_agent = st.checkbox(
        "üß† Use Strands Agent with MCP Tools",
        value=False,
        help="AI agent with MCP tools for intelligent database querying"
    )
    
    if use_strands_agent:
        st.caption("üí° MCP Agent uses admin access (via Data API) for intelligent cross-table queries. In production, implement application-level authorization.")
    
    time_window_map = {
        'All Time': None,
        'Last 24 Hours': '24h',
        'Last 7 Days': '7d',
        'Last 30 Days': '30d'
    }
    
    # Initialize mcp_query if needed
    if 'mcp_query' not in st.session_state:
        st.session_state.mcp_query = ''
    
    # Handle quick search button clicks
    if 'mcp_quick_search' in st.session_state:
        st.session_state.mcp_query = st.session_state.mcp_quick_search
        del st.session_state.mcp_quick_search
    
    mcp_query = st.text_input(
        "Search Query",
        placeholder="Enter your search query or question...",
        key='mcp_query'
    )
    
    mcp_search_button = st.button("üîç Search MCP Context", type="primary")
    
    if mcp_search_button and mcp_query:
        if use_strands_agent:
            st.markdown("#### üß† Strands Agent Response")
            
            with st.spinner("Agent is thinking..."):
                try:
                    start_time = time.time()
                    agent_result = strands_agent_search(mcp_query, selected_persona, use_mcp=True)
                    elapsed = time.time() - start_time
                    
                    if agent_result['error']:
                        st.error(f"‚ùå {agent_result['error']}")
                    else:
                        # Enhanced stats panel
                        st.markdown(f"""
                        <div class="stats-panel">
                            <div style="display: flex; justify-content: space-between; flex-wrap: wrap; gap: 1rem;">
                                <div>
                                    <div style="font-size: 1.5rem; font-weight: 600;">üß† Strands Agent</div>
                                    <div style="font-size: 0.875rem; opacity: 0.9;">Claude Sonnet 4 + MCP</div>
                                </div>
                                <div>
                                    <div style="font-size: 1.5rem; font-weight: 600;">{elapsed*1000:.0f}ms</div>
                                    <div style="font-size: 0.875rem; opacity: 0.9;">Response Time</div>
                                </div>
                                <div>
                                    <div style="font-size: 1.5rem; font-weight: 600;">‚úÖ</div>
                                    <div style="font-size: 0.875rem; opacity: 0.9;">Database Query</div>
                                </div>
                            </div>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        if agent_result.get('available_tools'):
                            with st.expander("üîó MCP Tools Available", expanded=False):
                                for tool in agent_result['available_tools']:
                                    st.markdown(f"- `{tool}`")
                        
                        # Explain how the agent works
                        with st.expander("üîç How It Works", expanded=False):
                            st.markdown("""
                            **Agent Architecture:**
                            
                            1. üß† **Strands Agent** receives your natural language query
                            2. ü§ñ **Claude Sonnet 4** analyzes the query and decides which MCP tools to use
                            3. üîß **MCP Tools** execute SQL queries against Aurora PostgreSQL via Data API
                            4. üìä **Agent synthesizes** the database results into a natural language response
                            
                            **Note:** The Strands framework abstracts away tool call details, so SQL queries are not exposed in the response object. However, the agent successfully queries the database to provide accurate answers.
                            """)
                        
                        # Display response
                        st.markdown("**Response:**")
                        st.info(agent_result['response'])
                        
                        st.caption("üí° **Note:** This demo shows a single query response. The MCP architecture can be extended to support multi-turn conversations with chat history and follow-up questions (out of scope for this workshop).")
                        
                except Exception as e:
                    st.error(f"Agent error: {str(e)}")
        else:
            # Direct MCP search
            with st.spinner(f"Searching as {selected_persona}..."):
                try:
                    start_time = time.time()
                    results = search_with_mcp_context(
                        mcp_query,
                        selected_persona,
                        time_window_map[time_filter],
                        results_limit * 2
                    )
                    elapsed = time.time() - start_time
                    
                    st.markdown(f"""
                    <div class="stats-panel">
                        <div style="display: flex; justify-content: space-between;">
                            <div>
                                <div style="font-size: 2rem; font-weight: 600;">{len(results)}</div>
                                <div style="font-size: 0.875rem;">Results Found</div>
                            </div>
                            <div>
                                <div style="font-size: 2rem; font-weight: 600;">{elapsed*1000:.0f}ms</div>
                                <div style="font-size: 0.875rem;">Response Time</div>
                            </div>
                            <div>
                                <div style="font-size: 2rem; font-weight: 600;">{PERSONAS[selected_persona]['icon']}</div>
                                <div style="font-size: 0.875rem;">{PERSONAS[selected_persona]['name']}</div>
                            </div>
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    if results:
                        by_type = {}
                        for r in results:
                            content_type = r.get('content_type', 'unknown')
                            if content_type not in by_type:
                                by_type[content_type] = []
                            by_type[content_type].append(r)
                        
                        for content_type, items in by_type.items():
                            with st.expander(f"üìÅ {content_type.replace('_', ' ').title()} ({len(items)})", expanded=True):
                                for item in items:
                                    render_knowledge_card(item, show_persona=True)
                    else:
                        show_empty_state(f"No results found for '{mcp_query}'", "üîç")
                        
                except Exception as e:
                    st.error(f"Search error: {str(e)}")

# Footer
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; padding: 2rem 0;">
    <p style="font-size: 1.1rem;">DAT409: Hybrid Search with Aurora PostgreSQL</p>
    <p style="font-size: 0.875rem;">Built with Streamlit, pgvector, Cohere, and MCP</p>
    <p style="font-size: 0.75rem; margin-top: 1rem;">Amazon Web Services ‚Ä¢ re:Invent 2025</p>
</div>
""", unsafe_allow_html=True)