{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT409: Implement hybrid search with Aurora PostgreSQL for MCP retrieval\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Workshop Learning Objectives\n",
    "\n",
    "In this hands-on workshop, you will:\n",
    "\n",
    "1. **Understand** the fundamental differences between keyword, semantic, and hybrid search\n",
    "2. **Implement** multiple search strategies using PostgreSQL and pgvector\n",
    "3. **Compare** tsvector vs pg_trgm for full-text search performance\n",
    "4. **Build** an enterprise-ready hybrid search system with Cohere embeddings\n",
    "5. **Visualize** search results interactively to understand trade-offs\n",
    "\n",
    "### üìä Our Dataset: E-commerce Product Catalog\n",
    "\n",
    "We're working with a real-world product catalog containing:\n",
    "- **21,704** products across multiple categories\n",
    "- Rich product descriptions for semantic understanding\n",
    "- Metadata including prices, ratings, and reviews\n",
    "- Pre-generated embeddings for immediate experimentation\n",
    "\n",
    "### üîç Search Methods We'll Explore\n",
    "\n",
    "| Search Type | Method | Strengths | Limitations |\n",
    "|------------|--------|-----------|-------------|\n",
    "| **Keyword Search** | Exact/fuzzy matching | Fast, precise for known terms | Misses semantic meaning |\n",
    "| **Semantic Search** | Vector embeddings | Understands context & intent | May miss exact matches |\n",
    "| **Hybrid Search** | Combined approach | Best of both worlds | Requires tuning |\n",
    "\n",
    "---\n",
    "\n",
    "Let's begin! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Environment Setup & Dependencies\n",
    "\n",
    "First, let's install and import all necessary libraries.\n",
    "\n",
    "**Note**: The workshop environment should already have all dependencies installed via the bootstrap script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Environment Setup & Dependencies\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check Python version\n",
    "print(f\"üêç Python version: {sys.version.split()[0]}\")\n",
    "\n",
    "# Verify we're using Python 3.13 as configured in bootstrap\n",
    "if not sys.version.startswith('3.13'):\n",
    "    print(f\"‚ö†Ô∏è Warning: Expected Python 3.13, but running {sys.version.split()[0]}\")\n",
    "\n",
    "# Check for requirements.txt in the correct location\n",
    "requirements_path = '/workshop/lab1-hybrid-search/requirements.txt'\n",
    "if os.path.exists(requirements_path):\n",
    "    # Check if packages are already installed\n",
    "    try:\n",
    "        import pgvector\n",
    "        import psycopg\n",
    "        import pandas\n",
    "        import numpy\n",
    "        import boto3\n",
    "        from dotenv import load_dotenv\n",
    "        print(\"‚úÖ All required packages already installed from bootstrap\")\n",
    "    except ImportError as e:\n",
    "        print(f\"üì• Installing dependencies from {requirements_path}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--user\", \"-q\", \"-r\", requirements_path])\n",
    "        print(\"‚úÖ Dependencies installed\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Requirements file not found at {requirements_path}\")\n",
    "    print(\"   Packages should already be installed from bootstrap\")\n",
    "\n",
    "# Import all required libraries\n",
    "import boto3\n",
    "import json\n",
    "import psycopg\n",
    "from pgvector.psycopg import register_vector\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from typing import Optional\n",
    "from pathlib import Path\n",
    "\n",
    "# Load environment variables from .env file created by bootstrap\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "env_path = Path('/workshop/.env')\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path, override=True)\n",
    "    print(f\"‚úÖ Loaded environment from {env_path}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No .env file found at /workshop/.env\")\n",
    "    print(\"   Bootstrap may not have completed successfully\")\n",
    "\n",
    "# Verify database environment is set\n",
    "db_vars = ['DB_HOST', 'DB_USER', 'DB_PASSWORD', 'DB_NAME']\n",
    "db_status = []\n",
    "for var in db_vars:\n",
    "    value = os.getenv(var)\n",
    "    if value:\n",
    "        if var == 'DB_PASSWORD':\n",
    "            db_status.append(f\"  {var}: {'*' * 8}\")\n",
    "        else:\n",
    "            db_status.append(f\"  {var}: {value}\")\n",
    "    else:\n",
    "        db_status.append(f\"  {var}: ‚ùå Missing\")\n",
    "\n",
    "print(\"üìä Database configuration:\")\n",
    "print('\\n'.join(db_status))\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"\\n‚úÖ Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîê Step 2: Database Connection & Model Setup\n",
    "\n",
    "Let's establish connections to our Aurora PostgreSQL database and initialize the Cohere client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Database Connection & Model Setup\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import boto3\n",
    "import json\n",
    "import psycopg\n",
    "from pgvector.psycopg import register_vector\n",
    "\n",
    "# Load environment variables from the correct path\n",
    "env_path = Path('/workshop/.env')\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path, override=True)\n",
    "    print(f\"‚úÖ Loaded environment from {env_path}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Warning: /workshop/.env not found, using environment variables\")\n",
    "\n",
    "# Configuration\n",
    "dbhost = os.getenv('DB_HOST')\n",
    "dbport = os.getenv('DB_PORT', '5432')\n",
    "dbuser = os.getenv('DB_USER')\n",
    "dbpass = os.getenv('DB_PASSWORD')\n",
    "dbname = os.getenv('DB_NAME', 'workshop_db')\n",
    "region = os.getenv('AWS_REGION', 'us-west-2')\n",
    "\n",
    "# Verify we have all required credentials\n",
    "if not all([dbhost, dbuser, dbpass]):\n",
    "    print(\"‚ùå Missing database credentials. Please check your .env file\")\n",
    "    print(f\"   DB_HOST: {'‚úì' if dbhost else '‚úó'}\")\n",
    "    print(f\"   DB_USER: {'‚úì' if dbuser else '‚úó'}\")\n",
    "    print(f\"   DB_PASSWORD: {'‚úì' if dbpass else '‚úó'}\")\n",
    "else:\n",
    "    print(\"‚úÖ All database credentials loaded\")\n",
    "\n",
    "# Initialize Bedrock client\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name=region\n",
    ")\n",
    "\n",
    "print(\"\\nüîß Configuration:\")\n",
    "print(f\"   ‚Ä¢ Database: {dbuser}@{dbhost}:{dbport}/{dbname}\")\n",
    "print(f\"   ‚Ä¢ AWS Region: {region}\")\n",
    "\n",
    "# Test database connection\n",
    "try:\n",
    "    with psycopg.connect(\n",
    "        host=dbhost, \n",
    "        port=dbport, \n",
    "        user=dbuser,\n",
    "        password=dbpass, \n",
    "        dbname=dbname, \n",
    "        autocommit=True\n",
    "    ) as conn:\n",
    "        register_vector(conn)\n",
    "        \n",
    "        # Get PostgreSQL version\n",
    "        result = conn.execute(\"SELECT version()\").fetchone()\n",
    "        print(f\"   ‚Ä¢ PostgreSQL: {result[0].split(',')[0]}\")\n",
    "        \n",
    "        # Check pgvector extension\n",
    "        result = conn.execute(\"SELECT extversion FROM pg_extension WHERE extname = 'vector'\").fetchone()\n",
    "        if result:\n",
    "            print(f\"   ‚Ä¢ pgvector: v{result[0]}\")\n",
    "        \n",
    "        # Check data is loaded\n",
    "        result = conn.execute(\"\"\"\n",
    "            SELECT COUNT(*) as count, \n",
    "                   COUNT(embedding) as with_embeddings \n",
    "            FROM bedrock_integration.product_catalog\n",
    "        \"\"\").fetchone()\n",
    "        if result and result[0] > 0:\n",
    "            print(f\"   ‚Ä¢ Data: {result[0]:,} products ({result[1]:,} with embeddings)\")\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è No data found in product_catalog table\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Database connection failed: {e}\")\n",
    "    print(\"   Check that the database is running and credentials are correct\")\n",
    "\n",
    "# Embedding function for Cohere via Bedrock\n",
    "def generate_embedding_cohere(text: str, input_type: str = \"search_query\") -> list[float] | None:\n",
    "    \"\"\"Generate Cohere embeddings via Amazon Bedrock\"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        body = json.dumps({\n",
    "            \"texts\": [text],\n",
    "            \"input_type\": input_type,\n",
    "            \"embedding_types\": [\"float\"],\n",
    "            \"truncate\": \"END\"\n",
    "        })\n",
    "        \n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId='cohere.embed-english-v3',\n",
    "            body=body,\n",
    "            accept='application/json',\n",
    "            contentType='application/json'\n",
    "        )\n",
    "        \n",
    "        response_body = json.loads(response['body'].read())\n",
    "        if 'embeddings' in response_body and 'float' in response_body['embeddings']:\n",
    "            return response_body['embeddings']['float'][0]\n",
    "        elif 'embeddings' in response_body:\n",
    "            return response_body['embeddings'][0]\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   Cohere embedding failed: {e}, trying Titan...\")\n",
    "        # Fallback to Titan\n",
    "        try:\n",
    "            payload = json.dumps({'inputText': text[:8000]})\n",
    "            response = bedrock_runtime.invoke_model(\n",
    "                body=payload,\n",
    "                modelId='amazon.titan-embed-text-v2:0',\n",
    "                accept=\"application/json\",\n",
    "                contentType=\"application/json\"\n",
    "            )\n",
    "            return json.loads(response.get(\"body\").read()).get(\"embedding\")\n",
    "        except Exception as e2:\n",
    "            print(f\"   Titan embedding also failed: {e2}\")\n",
    "            return None\n",
    "\n",
    "# Display models being used\n",
    "print(\"\\nü§ñ Models via Amazon Bedrock:\")\n",
    "print(\"   ‚Ä¢ cohere.embed-english-v3 (1024-dim embeddings)\")\n",
    "print(\"   ‚Ä¢ amazon.titan-embed-text-v2:0 (fallback embeddings)\")\n",
    "print(\"   ‚Ä¢ cohere.rerank-v3-5:0 (result re-ranking)\")\n",
    "\n",
    "print(\"\\n‚úÖ Database and models ready for hybrid search!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 3: Data Overview & Verification\n",
    "\n",
    "Let's verify that our pre-loaded product catalog is ready for searching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Data Overview & Verification\n",
    "\n",
    "import psycopg\n",
    "from pgvector.psycopg import register_vector\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Connect and verify data\n",
    "with psycopg.connect(\n",
    "    host=dbhost, port=dbport, user=dbuser,\n",
    "    password=dbpass, dbname=dbname, autocommit=True\n",
    ") as conn:\n",
    "    register_vector(conn)\n",
    "    \n",
    "    # Check if table exists\n",
    "    exists = conn.execute(\"\"\"\n",
    "        SELECT EXISTS (\n",
    "            SELECT 1 FROM information_schema.tables \n",
    "            WHERE table_schema = 'bedrock_integration' \n",
    "            AND table_name = 'product_catalog'\n",
    "        );\n",
    "    \"\"\").fetchone()[0]\n",
    "    \n",
    "    if not exists:\n",
    "        print(\"‚ùå Data not found. Please run: python parallel-fast-loader.py\")\n",
    "    else:\n",
    "        # Get statistics\n",
    "        stats = conn.execute(\"\"\"\n",
    "            SELECT \n",
    "                COUNT(*) as total,\n",
    "                COUNT(embedding) as with_embeddings,\n",
    "                COUNT(DISTINCT category_name) as categories,\n",
    "                AVG(price)::NUMERIC(10,2) as avg_price\n",
    "            FROM bedrock_integration.product_catalog;\n",
    "        \"\"\").fetchone()\n",
    "        \n",
    "        print(\"üìä DATA OVERVIEW\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Total Products: {stats[0]:,}\")\n",
    "        print(f\"With Embeddings: {stats[1]:,} ({stats[1]/stats[0]*100:.0f}%)\")\n",
    "        print(f\"Categories: {stats[2]}\")\n",
    "        print(f\"Avg Price: ${stats[3]}\")\n",
    "        \n",
    "        # Show top categories\n",
    "        print(\"\\nüì¶ TOP CATEGORIES\")\n",
    "        print(\"-\" * 40)\n",
    "        categories = conn.execute(\"\"\"\n",
    "            SELECT category_name, COUNT(*) as count\n",
    "            FROM bedrock_integration.product_catalog\n",
    "            GROUP BY category_name\n",
    "            ORDER BY count DESC\n",
    "            LIMIT 5;\n",
    "        \"\"\").fetchall()\n",
    "        \n",
    "        for cat, count in categories:\n",
    "            print(f\"  ‚Ä¢ {cat}: {count:,}\")\n",
    "        \n",
    "        # Show indexes\n",
    "        print(\"\\nüîç INDEXES\")\n",
    "        print(\"-\" * 40)\n",
    "        indexes = conn.execute(\"\"\"\n",
    "            SELECT indexname FROM pg_indexes\n",
    "            WHERE schemaname = 'bedrock_integration'\n",
    "            AND tablename = 'product_catalog';\n",
    "        \"\"\").fetchall()\n",
    "        \n",
    "        for idx in indexes:\n",
    "            name = idx[0]\n",
    "            if 'embedding' in name:\n",
    "                print(f\"  ‚Ä¢ {name} (Vector search)\")\n",
    "            elif 'fts' in name:\n",
    "                print(f\"  ‚Ä¢ {name} (Full-text search)\")\n",
    "            elif 'trgm' in name:\n",
    "                print(f\"  ‚Ä¢ {name} (Fuzzy search)\")\n",
    "            elif 'pkey' in name:\n",
    "                print(f\"  ‚Ä¢ {name} (Primary key)\")\n",
    "            elif 'category' in name:\n",
    "                print(f\"  ‚Ä¢ {name} (Category filter)\")\n",
    "            elif 'price' in name:\n",
    "                print(f\"  ‚Ä¢ {name} (Price range)\")\n",
    "            else:\n",
    "                print(f\"  ‚Ä¢ {name}\")\n",
    "        \n",
    "        print(\"\\n‚úÖ Database ready for hybrid search!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Step 4: Implementing Search Functions\n",
    "\n",
    "Now let's implement different search methods and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Search Function Implementations\n",
    "\n",
    "# ============================================================\n",
    "# EMBEDDING GENERATION\n",
    "# ============================================================\n",
    "\n",
    "def generate_embedding(text: str, input_type: str = \"search_query\") -> list[float] | None:\n",
    "    \"\"\"Generate embeddings using Cohere embed-english-v3\"\"\"\n",
    "    try:\n",
    "        body = json.dumps({\n",
    "            \"texts\": [text],\n",
    "            \"input_type\": input_type,\n",
    "            \"embedding_types\": [\"float\"],\n",
    "            \"truncate\": \"END\"\n",
    "        })\n",
    "        \n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId='cohere.embed-english-v3',\n",
    "            body=body,\n",
    "            accept='application/json',\n",
    "            contentType='application/json'\n",
    "        )\n",
    "        \n",
    "        response_body = json.loads(response['body'].read())\n",
    "        \n",
    "        if 'embeddings' in response_body and 'float' in response_body['embeddings']:\n",
    "            return response_body['embeddings']['float'][0]\n",
    "        elif 'embeddings' in response_body:\n",
    "            return response_body['embeddings'][0]\n",
    "        return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating embedding: {e}\")\n",
    "        return None\n",
    "\n",
    "# ============================================================\n",
    "# 1. KEYWORD SEARCH - FULL TEXT\n",
    "# ============================================================\n",
    "\n",
    "def keyword_search(query: str, limit: int = 10) -> list[dict]:\n",
    "    \"\"\"PostgreSQL Full-Text Search using TSVector\"\"\"\n",
    "    with psycopg.connect(\n",
    "        host=dbhost, port=dbport, user=dbuser,\n",
    "        password=dbpass, autocommit=True\n",
    "    ) as conn:\n",
    "        results = conn.execute(\"\"\"\n",
    "            SELECT \n",
    "                \"productId\",\n",
    "                product_description,\n",
    "                category_name,\n",
    "                price,\n",
    "                stars,\n",
    "                reviews,\n",
    "                imgurl as \"imgUrl\",\n",
    "                ts_rank_cd(\n",
    "                    to_tsvector('english', product_description), \n",
    "                    plainto_tsquery('english', %s)\n",
    "                ) as rank\n",
    "            FROM bedrock_integration.product_catalog\n",
    "            WHERE to_tsvector('english', product_description) \n",
    "                  @@ plainto_tsquery('english', %s)\n",
    "            ORDER BY rank DESC\n",
    "            LIMIT %s;\n",
    "        \"\"\", (query, query, limit)).fetchall()\n",
    "        \n",
    "        return [{\n",
    "            'productId': r[0],\n",
    "            'description': r[1][:200] + '...',\n",
    "            'category': r[2],\n",
    "            'price': float(r[3]) if r[3] else 0,\n",
    "            'stars': float(r[4]) if r[4] else 0,\n",
    "            'reviews': int(r[5]) if r[5] else 0,\n",
    "            'imgUrl': r[6],\n",
    "            'score': float(r[7]) if r[7] else 0,\n",
    "            'method': 'Keyword'\n",
    "        } for r in results]\n",
    "\n",
    "# ============================================================\n",
    "# 2. FUZZY SEARCH - TYPO TOLERANCE\n",
    "# ============================================================\n",
    "\n",
    "def fuzzy_search(query: str, limit: int = 10) -> list[dict]:\n",
    "    \"\"\"PostgreSQL Trigram Search for typo tolerance\"\"\"\n",
    "    with psycopg.connect(\n",
    "        host=dbhost, port=dbport, user=dbuser,\n",
    "        password=dbpass, autocommit=True\n",
    "    ) as conn:\n",
    "        conn.execute(\"SET pg_trgm.similarity_threshold = 0.1;\")\n",
    "        \n",
    "        results = conn.execute(\"\"\"\n",
    "            SELECT \n",
    "                \"productId\",\n",
    "                product_description,\n",
    "                category_name,\n",
    "                price,\n",
    "                stars,\n",
    "                reviews,\n",
    "                imgurl as \"imgUrl\",\n",
    "                similarity(lower(product_description), lower(%s)) as sim\n",
    "            FROM bedrock_integration.product_catalog\n",
    "            WHERE lower(product_description) %% lower(%s)\n",
    "            ORDER BY sim DESC\n",
    "            LIMIT %s;\n",
    "        \"\"\", (query, query, limit)).fetchall()\n",
    "        \n",
    "        return [{\n",
    "            'productId': r[0],\n",
    "            'description': r[1][:200] + '...',\n",
    "            'category': r[2],\n",
    "            'price': float(r[3]) if r[3] else 0,\n",
    "            'stars': float(r[4]) if r[4] else 0,\n",
    "            'reviews': int(r[5]) if r[5] else 0,\n",
    "            'imgUrl': r[6],\n",
    "            'score': float(r[7]) if r[7] else 0,\n",
    "            'method': 'Fuzzy'\n",
    "        } for r in results]\n",
    "\n",
    "# ============================================================\n",
    "# 3. SEMANTIC SEARCH - VECTOR SIMILARITY\n",
    "# ============================================================\n",
    "\n",
    "def semantic_search(query: str, limit: int = 10) -> list[dict]:\n",
    "    \"\"\"Semantic Search using Cohere embeddings\"\"\"\n",
    "    \n",
    "    # Generate query embedding\n",
    "    query_embedding = generate_embedding(query, \"search_query\")\n",
    "    if not query_embedding:\n",
    "        return []\n",
    "    \n",
    "    with psycopg.connect(\n",
    "        host=dbhost, port=dbport, user=dbuser,\n",
    "        password=dbpass, autocommit=True\n",
    "    ) as conn:\n",
    "        register_vector(conn)\n",
    "        \n",
    "        results = conn.execute(\"\"\"\n",
    "            SELECT \n",
    "                \"productId\",\n",
    "                product_description,\n",
    "                category_name,\n",
    "                price,\n",
    "                stars,\n",
    "                reviews,\n",
    "                imgurl as \"imgUrl\",\n",
    "                1 - (embedding <=> %s::vector) as similarity\n",
    "            FROM bedrock_integration.product_catalog\n",
    "            WHERE embedding IS NOT NULL\n",
    "            ORDER BY embedding <=> %s::vector\n",
    "            LIMIT %s;\n",
    "        \"\"\", (query_embedding, query_embedding, limit)).fetchall()\n",
    "        \n",
    "        return [{\n",
    "            'productId': r[0],\n",
    "            'description': r[1][:200] + '...',\n",
    "            'category': r[2],\n",
    "            'price': float(r[3]) if r[3] else 0,\n",
    "            'stars': float(r[4]) if r[4] else 0,\n",
    "            'reviews': int(r[5]) if r[5] else 0,\n",
    "            'imgUrl': r[6],\n",
    "            'score': float(r[7]) if r[7] else 0,\n",
    "            'method': 'Semantic'\n",
    "        } for r in results]\n",
    "\n",
    "# ============================================================\n",
    "# 4. HYBRID SEARCH - BEST OF BOTH\n",
    "# ============================================================\n",
    "\n",
    "def hybrid_search(\n",
    "    query: str,\n",
    "    semantic_weight: float = 0.7,\n",
    "    keyword_weight: float = 0.3,\n",
    "    limit: int = 10\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Hybrid Search combining semantic and keyword approaches using weighted score fusion.\n",
    "    \n",
    "    IMPORTANT: This implementation intentionally does NOT normalize scores to demonstrate\n",
    "    a common production challenge. Different search methods produce vastly different score ranges:\n",
    "    - Semantic (cosine similarity): typically 0.7-1.0 for good matches\n",
    "    - Keyword (ts_rank_cd): typically 0.01-0.1 even for good matches\n",
    "    \n",
    "    This causes semantic scores to dominate the final ranking even with equal weights.\n",
    "    \n",
    "    Example with 70/30 weights:\n",
    "      Semantic: 0.90 √ó 0.7 = 0.63\n",
    "      Keyword:  0.05 √ó 0.3 = 0.015\n",
    "      Combined: 0.645 (semantic dominates!)\n",
    "    \n",
    "    Production solutions:\n",
    "    1. Cohere Rerank (ML-based, no normalization needed) - demonstrated in this notebook\n",
    "    2. Reciprocal Rank Fusion (RRF) - rank-based, no normalization needed\n",
    "    3. Min-Max normalization - scale each method's scores to [0,1] before weighting\n",
    "    \"\"\"\n",
    "    \n",
    "    # Normalize weights\n",
    "    total = semantic_weight + keyword_weight\n",
    "    semantic_weight = semantic_weight / total\n",
    "    keyword_weight = keyword_weight / total\n",
    "    \n",
    "    # Get results from both methods\n",
    "    semantic_results = semantic_search(query, limit * 2)\n",
    "    keyword_results = keyword_search(query, limit * 2)\n",
    "    \n",
    "    # Combine and score\n",
    "    product_scores = {}\n",
    "    product_data = {}\n",
    "    \n",
    "    # Process semantic results\n",
    "    for result in semantic_results:\n",
    "        pid = result['productId']\n",
    "        product_scores[pid] = result['score'] * semantic_weight\n",
    "        product_data[pid] = result\n",
    "    \n",
    "    # Process keyword results\n",
    "    for result in keyword_results:\n",
    "        pid = result['productId']\n",
    "        if pid in product_scores:\n",
    "            product_scores[pid] += result['score'] * keyword_weight\n",
    "        else:\n",
    "            product_scores[pid] = result['score'] * keyword_weight\n",
    "            product_data[pid] = result\n",
    "    \n",
    "    # Sort and return top results\n",
    "    sorted_products = sorted(product_scores.items(), key=lambda x: x[1], reverse=True)[:limit]\n",
    "    \n",
    "    results = []\n",
    "    for pid, score in sorted_products:\n",
    "        product = product_data[pid].copy()\n",
    "        product['score'] = score\n",
    "        product['method'] = 'Hybrid'\n",
    "        results.append(product)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ============================================================\n",
    "# COHERE RERANK FUNCTION\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. HYBRID SEARCH - RRF (Reciprocal Rank Fusion)\n",
    "# ============================================================\n",
    "\n",
    "def hybrid_search_rrf(\n",
    "    query: str,\n",
    "    k: int = 60,\n",
    "    limit: int = 10\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Hybrid Search using Reciprocal Rank Fusion (RRF).\n",
    "    \n",
    "    RRF is a rank-based fusion method that does NOT require score normalization.\n",
    "    Instead of combining raw scores, it combines ranks using the formula:\n",
    "    \n",
    "    RRF_score = sum(1 / (k + rank)) for each method\n",
    "    \n",
    "    Where k is a constant (typically 60) that reduces the impact of high ranks.\n",
    "    \n",
    "    Benefits:\n",
    "    - No score normalization needed\n",
    "    - Robust to different score scales\n",
    "    - Simple and effective\n",
    "    - Used by major search engines\n",
    "    \"\"\"\n",
    "    \n",
    "    query_embedding = generate_embedding(query, \"search_query\")\n",
    "    if not query_embedding:\n",
    "        return []\n",
    "    \n",
    "    with psycopg.connect(\n",
    "        host=dbhost, port=dbport, user=dbuser,\n",
    "        password=dbpass, autocommit=True\n",
    "    ) as conn:\n",
    "        register_vector(conn)\n",
    "        \n",
    "        results = conn.execute(\"\"\"\n",
    "            WITH semantic_search AS (\n",
    "                SELECT \n",
    "                    \"productId\",\n",
    "                    product_description,\n",
    "                    category_name,\n",
    "                    price,\n",
    "                    stars,\n",
    "                    reviews,\n",
    "                    imgurl,\n",
    "                    RANK() OVER (ORDER BY embedding <=> %s::vector) AS rank\n",
    "                FROM bedrock_integration.product_catalog\n",
    "                WHERE embedding IS NOT NULL\n",
    "                ORDER BY embedding <=> %s::vector\n",
    "                LIMIT 20\n",
    "            ),\n",
    "            keyword_search AS (\n",
    "                SELECT \n",
    "                    \"productId\",\n",
    "                    product_description,\n",
    "                    category_name,\n",
    "                    price,\n",
    "                    stars,\n",
    "                    reviews,\n",
    "                    imgurl,\n",
    "                    RANK() OVER (ORDER BY ts_rank_cd(to_tsvector('english', product_description), query) DESC) AS rank\n",
    "                FROM bedrock_integration.product_catalog, plainto_tsquery('english', %s) query\n",
    "                WHERE to_tsvector('english', product_description) @@ query\n",
    "                LIMIT 20\n",
    "            )\n",
    "            SELECT\n",
    "                COALESCE(s.\"productId\", k.\"productId\") AS product_id,\n",
    "                COALESCE(s.product_description, k.product_description) AS description,\n",
    "                COALESCE(s.category_name, k.category_name) AS category,\n",
    "                COALESCE(s.price, k.price) AS price,\n",
    "                COALESCE(s.stars, k.stars) AS stars,\n",
    "                COALESCE(s.reviews, k.reviews) AS reviews,\n",
    "                COALESCE(s.imgurl, k.imgurl) AS imgurl,\n",
    "                (COALESCE(1.0 / (60 + s.rank), 0.0) + COALESCE(1.0 / (60 + k.rank), 0.0)) AS rrf_score\n",
    "            FROM semantic_search s\n",
    "            FULL OUTER JOIN keyword_search k ON s.\"productId\" = k.\"productId\"\n",
    "            ORDER BY rrf_score DESC\n",
    "            LIMIT %s\n",
    "        \"\"\", (query_embedding, query_embedding, query, limit)).fetchall()\n",
    "        \n",
    "        return [{\n",
    "            'productId': r[0],\n",
    "            'description': r[1][:200] + '...',\n",
    "            'category': r[2],\n",
    "            'price': float(r[3]) if r[3] else 0,\n",
    "            'stars': float(r[4]) if r[4] else 0,\n",
    "            'reviews': int(r[5]) if r[5] else 0,\n",
    "            'imgUrl': r[6],\n",
    "            'score': float(r[7]) if r[7] else 0,\n",
    "            'method': 'Hybrid-RRF'\n",
    "        } for r in results]\n",
    "\n",
    "def rerank_results(query: str, results: list[dict], top_k: int = 5) -> list[dict]:\n",
    "    \"\"\"Re-rank search results using Cohere Rerank model\"\"\"\n",
    "    if not results:\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # Prepare documents for reranking\n",
    "        documents = [r['description'] for r in results]\n",
    "        \n",
    "        body = json.dumps({\n",
    "            \"query\": query,\n",
    "            \"documents\": documents,\n",
    "            \"top_n\": top_k,\n",
    "            \"api_version\": 2\n",
    "        })\n",
    "        \n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId='cohere.rerank-v3-5:0',\n",
    "            body=body,\n",
    "            accept='application/json',\n",
    "            contentType='application/json'\n",
    "        )\n",
    "        \n",
    "        response_body = json.loads(response['body'].read())\n",
    "        \n",
    "        # Reorder results based on rerank scores\n",
    "        reranked = []\n",
    "        for item in response_body.get('results', []):\n",
    "            idx = item['index']\n",
    "            result = results[idx].copy()\n",
    "            result['rerank_score'] = item['relevance_score']\n",
    "            reranked.append(result)\n",
    "        \n",
    "        return reranked\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Reranking failed: {e}\")\n",
    "        return results[:top_k]\n",
    "\n",
    "print(\"‚úÖ Search functions loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéÆ Step 5: Interactive Search Interface\n",
    "\n",
    "Now let's create an interactive interface to explore and compare different search methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Interactive Search Interface with Product Display\n",
    "\n",
    "def create_search_interface():\n",
    "    \"\"\"Create an interactive search interface with proper product display\"\"\"\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, HTML\n",
    "    \n",
    "    # Professional style definitions\n",
    "    style = \"\"\"\n",
    "    <style>\n",
    "        .search-container { padding: 20px; background: #f8f9fa; border-radius: 10px; }\n",
    "        .result-card { \n",
    "            margin: 15px 0; padding: 20px; background: white; \n",
    "            border-radius: 8px; border: 1px solid #e3e6e8;\n",
    "            transition: all 0.3s; position: relative;\n",
    "            box-shadow: 0 1px 2px rgba(0,0,0,0.05);\n",
    "        }\n",
    "        .result-card:hover { \n",
    "            box-shadow: 0 8px 20px rgba(0,0,0,0.12); \n",
    "            transform: translateY(-2px);\n",
    "            border-color: #ff9900;\n",
    "        }\n",
    "        .method-badge {\n",
    "            position: absolute; top: 15px; right: 15px;\n",
    "            padding: 5px 12px; border-radius: 20px;\n",
    "            font-size: 11px; font-weight: bold;\n",
    "            text-transform: uppercase;\n",
    "        }\n",
    "        .keyword { background: #e3f2fd; color: #1565c0; }\n",
    "        .fuzzy { background: #fce4ec; color: #c2185b; }\n",
    "        .semantic { background: #e8f5e9; color: #2e7d32; }\n",
    "        .hybrid { background: #fff3e0; color: #e65100; }\n",
    "        \n",
    "        .product-content { display: flex; gap: 20px; }\n",
    "        .product-image {\n",
    "            flex-shrink: 0; width: 150px; height: 150px;\n",
    "            object-fit: contain; border: 1px solid #e3e6e8;\n",
    "            border-radius: 4px; padding: 10px; background: white;\n",
    "        }\n",
    "        .product-details { flex-grow: 1; }\n",
    "        .product-title {\n",
    "            font-size: 16px; color: #0066c0; text-decoration: none;\n",
    "            font-weight: 500; line-height: 1.4; display: block; margin-bottom: 8px;\n",
    "        }\n",
    "        .product-title:hover { color: #c7511f; text-decoration: underline; }\n",
    "        .product-price {\n",
    "            font-size: 21px; color: #B12704; font-weight: 500; margin: 8px 0;\n",
    "        }\n",
    "        .product-rating {\n",
    "            display: flex; align-items: center; gap: 8px; margin: 8px 0;\n",
    "        }\n",
    "        .stars { color: #ff9900; }\n",
    "        .product-category { color: #565959; font-size: 12px; margin-top: 8px; }\n",
    "        .score-info {\n",
    "            margin-top: 12px; padding-top: 12px; border-top: 1px solid #e3e6e8;\n",
    "            display: flex; justify-content: space-between; align-items: center;\n",
    "        }\n",
    "        .score-bar {\n",
    "            height: 6px; background: #e9ecef; border-radius: 3px;\n",
    "            overflow: hidden; flex-grow: 1; margin-right: 10px; max-width: 200px;\n",
    "        }\n",
    "        .score-fill {\n",
    "            height: 100%; background: linear-gradient(90deg, #ff9900, #ff6600);\n",
    "            transition: width 0.5s;\n",
    "        }\n",
    "        .score-text { color: #565959; font-size: 12px; font-weight: 500; }\n",
    "        .comparison-grid {\n",
    "            display: grid; grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));\n",
    "            gap: 20px; margin-top: 20px;\n",
    "        }\n",
    "        .no-results {\n",
    "            padding: 40px; text-align: center; color: #565959;\n",
    "            background: #f7f8f8; border-radius: 8px;\n",
    "        }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Widget definitions\n",
    "    query_input = widgets.Text(\n",
    "        value='',\n",
    "        placeholder='Try \"Apple AirPods\" or \"coffee maker\" or \"laptop bag\"...',\n",
    "        description='Search:',\n",
    "        style={'description_width': '80px'},\n",
    "        layout=widgets.Layout(width='700px')\n",
    "    )\n",
    "    \n",
    "    search_method = widgets.RadioButtons(\n",
    "        options=[\n",
    "            ('Keyword (Exact Match)', 'keyword'),\n",
    "            ('Fuzzy (Typo Tolerance)', 'fuzzy'),\n",
    "            ('Semantic (Conceptual)', 'semantic'),\n",
    "            ('Hybrid (Combined)', 'hybrid'),\n",
    "            ('Hybrid-RRF (Rank Fusion)', 'hybrid_rrf'),\n",
    "            ('üîç Compare All Methods', 'compare')\n",
    "        ],\n",
    "        value='compare',\n",
    "        description='Method:',\n",
    "        style={'description_width': '80px'}\n",
    "    )\n",
    "    \n",
    "    # Hybrid search weight sliders\n",
    "    semantic_weight = widgets.FloatSlider(\n",
    "        value=0.7, min=0, max=1, step=0.1,\n",
    "        description='Semantic:',\n",
    "        style={'description_width': '80px'},\n",
    "        layout=widgets.Layout(width='350px')\n",
    "    )\n",
    "    \n",
    "    keyword_weight = widgets.FloatSlider(\n",
    "        value=0.3, min=0, max=1, step=0.1,\n",
    "        description='Keyword:',\n",
    "        style={'description_width': '80px'},\n",
    "        layout=widgets.Layout(width='350px')\n",
    "    )\n",
    "    \n",
    "    results_limit = widgets.IntSlider(\n",
    "        value=3, min=1, max=10, step=1,\n",
    "        description='Results:',\n",
    "        style={'description_width': '80px'},\n",
    "        layout=widgets.Layout(width='300px')\n",
    "    )\n",
    "    \n",
    "    search_button = widgets.Button(\n",
    "        description='üîç Search Products',\n",
    "        button_style='primary',\n",
    "        layout=widgets.Layout(width='200px', height='40px')\n",
    "    )\n",
    "    \n",
    "    rerank_checkbox = widgets.Checkbox(\n",
    "        value=False,\n",
    "        description='Use Cohere Rerank',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    results_output = widgets.Output()\n",
    "    \n",
    "    # Example queries that demonstrate real differences\n",
    "    example_queries = [\n",
    "        # Exact keyword matches\n",
    "        (\"wireless bluetooth headphones\", \"Common Terms\", \"keyword\"),\n",
    "        (\"stainless steel water bottle\", \"Product Type\", \"keyword\"),\n",
    "        \n",
    "        # Conceptual searches\n",
    "        (\"something to keep coffee hot all day\", \"Problem Solving\", \"semantic\"),\n",
    "        (\"gift for someone who loves cooking\", \"Gift Ideas\", \"semantic\"),\n",
    "        \n",
    "        # Typo tolerance\n",
    "        (\"wireles blutooth hedphones\", \"With Typos\", \"fuzzy\"),\n",
    "        (\"stainles steel watter botle\", \"Misspellings\", \"fuzzy\"),\n",
    "        \n",
    "        # Balanced hybrid (RRF excels here)\n",
    "        (\"durable laptop backpack with USB charging\", \"Multi-Feature\", \"hybrid_rrf\"),\n",
    "        (\"ergonomic office chair under 300 dollars\", \"Specs + Price\", \"hybrid_rrf\"),\n",
    "        \n",
    "        # Mixed queries\n",
    "        (\"organic sustainable water bottle\", \"Features + Product\", \"hybrid\"),\n",
    "        (\"affordable noise canceling headphones under 200\", \"Specs + Budget\", \"hybrid\"),\n",
    "        \n",
    "        # Activity based\n",
    "        (\"equipment for home yoga practice\", \"Activity Based\", \"semantic\"),\n",
    "        (\"tools for remote work from home\", \"Use Case\", \"semantic\")\n",
    "    ]\n",
    "    \n",
    "    def format_result(result: dict, method_class: str = '') -> str:\n",
    "        \"\"\"Format a single search result with full product display\"\"\"\n",
    "        # Extract product details\n",
    "        product_id = result.get('productId', 'Unknown')\n",
    "        description = result.get('description', 'No description available')\n",
    "        price = result.get('price', 0)\n",
    "        stars = result.get('stars', 0)\n",
    "        reviews = result.get('reviews', 0)\n",
    "        category = result.get('category', 'Unknown Category')\n",
    "        score = result.get('score', 0)\n",
    "        rerank_score = result.get('rerank_score', None)\n",
    "        img_url = result.get('imgUrl', '')  # Changed to imgUrl with capital U\n",
    "        \n",
    "        # Create star display\n",
    "        star_display = '‚òÖ' * int(stars) + '‚òÜ' * (5 - int(stars))\n",
    "        \n",
    "        # Generate Amazon search link\n",
    "        search_terms = description.split()[:5]\n",
    "        link_url = f\"https://www.amazon.com/s?k={'+'.join(search_terms)}\"\n",
    "        \n",
    "        # Calculate score percentage for visual bar\n",
    "        display_score = rerank_score if rerank_score is not None else score\n",
    "        score_percent = min(display_score * 100, 100) if display_score > 0 else 0\n",
    "        \n",
    "        # Score label\n",
    "        score_label = \"Rerank Score\" if rerank_score is not None else \"Relevance\"\n",
    "        \n",
    "        # Simple direct image embed exactly like Part 2 notebook\n",
    "        return f\"\"\"\n",
    "        <div class=\"result-card\">\n",
    "            <div class=\"method-badge {method_class}\">{result.get('method', 'Unknown')}</div>\n",
    "            \n",
    "            <div class=\"product-content\">\n",
    "                <img src=\"{img_url}\" style=\"width: 150px; height: 150px; object-fit: contain; border: 1px solid #e3e6e8; border-radius: 4px; padding: 10px; background: white;\">\n",
    "                \n",
    "                <div class=\"product-details\">\n",
    "                    <a href=\"{link_url}\" target=\"_blank\" class=\"product-title\">\n",
    "                        {description}\n",
    "                    </a>\n",
    "                    \n",
    "                    <div class=\"product-price\">${price:.2f}</div>\n",
    "                    \n",
    "                    <div class=\"product-rating\">\n",
    "                        <span class=\"stars\">{star_display}</span>\n",
    "                        <span style=\"color: #007185; font-size: 14px;\">({reviews:,} reviews)</span>\n",
    "                    </div>\n",
    "                    \n",
    "                    <div class=\"product-category\">Category: {category}</div>\n",
    "                    \n",
    "                    <div class=\"score-info\">\n",
    "                        <div style=\"display: flex; align-items: center; flex-grow: 1;\">\n",
    "                            <div class=\"score-bar\">\n",
    "                                <div class=\"score-fill\" style=\"width: {score_percent}%\"></div>\n",
    "                            </div>\n",
    "                            <span class=\"score-text\">{score_label}: {display_score:.3f}</span>\n",
    "                        </div>\n",
    "                        <a href=\"{link_url}\" target=\"_blank\" style=\"color: #ff9900; text-decoration: none; font-size: 13px;\">\n",
    "                            View on Amazon ‚Üí\n",
    "                        </a>\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    \n",
    "    def set_example_query(query: str, method: str | None = None):\n",
    "        \"\"\"Set an example query and optionally the search method\"\"\"\n",
    "        query_input.value = query\n",
    "        if method:\n",
    "            search_method.value = method\n",
    "    \n",
    "    # Create example buttons\n",
    "    example_buttons = []\n",
    "    for query, label, best_method in example_queries:\n",
    "        btn = widgets.Button(\n",
    "            description=f\"{label}: {query[:30]}...\" if len(query) > 30 else f\"{label}: {query}\",\n",
    "            layout=widgets.Layout(width='auto', margin='2px'),\n",
    "            tooltip=f\"Best with: {best_method}\"\n",
    "        )\n",
    "        btn.on_click(lambda b, q=query, m=best_method: set_example_query(q, m))\n",
    "        example_buttons.append(btn)\n",
    "    \n",
    "    def on_search_clicked(b):\n",
    "        \"\"\"Handle search button click\"\"\"\n",
    "        results_output.clear_output()\n",
    "        \n",
    "        with results_output:\n",
    "            display(HTML(style))\n",
    "            \n",
    "            query = query_input.value\n",
    "            method = search_method.value\n",
    "            limit = results_limit.value\n",
    "            use_rerank = rerank_checkbox.value\n",
    "            \n",
    "            if not query:\n",
    "                display(HTML('<div class=\"no-results\">Please enter a search query!</div>'))\n",
    "                return\n",
    "            \n",
    "            display(HTML(f'<h3 style=\"color: #0f1111;\">üîç Results for: \"{query}\"</h3>'))\n",
    "            \n",
    "            if method == 'compare':\n",
    "                # Compare all methods\n",
    "                methods_to_compare = [\n",
    "                    ('Keyword (Exact)', keyword_search, 'keyword'),\n",
    "                    ('Fuzzy (Typos)', fuzzy_search, 'fuzzy'),\n",
    "                    ('Semantic (Cohere)', semantic_search, 'semantic'),\n",
    "                    ('Hybrid (70/30)', lambda q, l: hybrid_search(q, 0.7, 0.3, l), 'hybrid'),\n",
    "                    ('Hybrid-RRF (k=60)', lambda q, l: hybrid_search_rrf(q, 60, l), 'hybrid')\n",
    "                ]\n",
    "                \n",
    "                # Method colors\n",
    "                method_colors = {\n",
    "                    'keyword': '1565c0',\n",
    "                    'fuzzy': 'c2185b',\n",
    "                    'semantic': '2e7d32',\n",
    "                    'hybrid': 'e65100'\n",
    "                }\n",
    "                \n",
    "                html_output = '<div class=\"comparison-grid\">'\n",
    "                \n",
    "                for method_name, func, css_class in methods_to_compare:\n",
    "                    border_color = method_colors.get(css_class, '666666')\n",
    "                    html_output += f'<div><h4 style=\"color: #0f1111; border-bottom: 2px solid #{border_color}; padding-bottom: 8px; margin-bottom: 15px;\">{method_name}</h4>'\n",
    "                    \n",
    "                    try:\n",
    "                        import time\n",
    "                        start = time.time()\n",
    "                        results = func(query, limit)\n",
    "                        elapsed = time.time() - start\n",
    "                        \n",
    "                        # Apply reranking if enabled\n",
    "                        if use_rerank and results:\n",
    "                            results = rerank_results(query, results, min(len(results), 2))\n",
    "                        \n",
    "                        if results:\n",
    "                            html_output += f'<p style=\"color: #565959; font-size: 12px;\">Found {len(results)} results in {elapsed:.3f}s</p>'\n",
    "                            for result in results[:2]:  # Show top 2 per method\n",
    "                                html_output += format_result(result, css_class)\n",
    "                        else:\n",
    "                            html_output += '<div class=\"no-results\">No results found with this method</div>'\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        html_output += f'<div class=\"no-results\">Error: {str(e)}</div>'\n",
    "                    \n",
    "                    html_output += '</div>'\n",
    "                \n",
    "                html_output += '</div>'\n",
    "                display(HTML(html_output))\n",
    "                \n",
    "            else:\n",
    "                # Single method search\n",
    "                try:\n",
    "                    import time\n",
    "                    start = time.time()\n",
    "                    \n",
    "                    if method == 'keyword':\n",
    "                        results = keyword_search(query, limit)\n",
    "                        css_class = 'keyword'\n",
    "                        method_name = 'Keyword (Exact Match)'\n",
    "                    elif method == 'fuzzy':\n",
    "                        results = fuzzy_search(query, limit)\n",
    "                        css_class = 'fuzzy'\n",
    "                        method_name = 'Fuzzy (Typo Tolerance)'\n",
    "                    elif method == 'semantic':\n",
    "                        results = semantic_search(query, limit)\n",
    "                        css_class = 'semantic'\n",
    "                        method_name = 'Semantic Search (Cohere)'\n",
    "                    elif method == 'hybrid':\n",
    "                        results = hybrid_search(\n",
    "                            query, \n",
    "                            semantic_weight.value,\n",
    "                            keyword_weight.value,\n",
    "                            limit\n",
    "                        )\n",
    "                        css_class = 'hybrid'\n",
    "                        method_name = f'Hybrid (S:{semantic_weight.value:.1f}/K:{keyword_weight.value:.1f})'\n",
    "                    elif method == 'hybrid_rrf':\n",
    "                        results = hybrid_search_rrf(query, 60, limit)\n",
    "                        css_class = 'hybrid'\n",
    "                        method_name = 'Hybrid-RRF (k=60)'\n",
    "                    \n",
    "                    elapsed = time.time() - start\n",
    "                    \n",
    "                    # Apply reranking if enabled\n",
    "                    if use_rerank and results:\n",
    "                        rerank_start = time.time()\n",
    "                        results = rerank_results(query, results, len(results))\n",
    "                        rerank_time = time.time() - rerank_start\n",
    "                        total_time = elapsed + rerank_time\n",
    "                        \n",
    "                        display(HTML(f'''\n",
    "                            <p style=\"color: #565959;\">\n",
    "                                Method: <strong>{method_name}</strong> | \n",
    "                                Search: <strong>{elapsed:.3f}s</strong> | \n",
    "                                Rerank: <strong>{rerank_time:.3f}s</strong> |\n",
    "                                Total: <strong>{total_time:.3f}s</strong> | \n",
    "                                Results: <strong>{len(results)}</strong>\n",
    "                            </p>\n",
    "                        '''))\n",
    "                    else:\n",
    "                        display(HTML(f'''\n",
    "                            <p style=\"color: #565959;\">\n",
    "                                Method: <strong>{method_name}</strong> | \n",
    "                                Time: <strong>{elapsed:.3f}s</strong> | \n",
    "                                Results: <strong>{len(results)}</strong>\n",
    "                            </p>\n",
    "                        '''))\n",
    "                    \n",
    "                    if results:\n",
    "                        for result in results:\n",
    "                            display(HTML(format_result(result, css_class)))\n",
    "                    else:\n",
    "                        display(HTML('<div class=\"no-results\">No products found. Try a different search term or method.</div>'))\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    display(HTML(f'<div class=\"no-results\">Error: {str(e)}</div>'))\n",
    "                    import traceback\n",
    "                    print(traceback.format_exc())\n",
    "    \n",
    "    search_button.on_click(on_search_clicked)\n",
    "    \n",
    "    # Create status display for weights\n",
    "    weight_status = widgets.HTML(\n",
    "        value=\"<div style='padding: 5px; font-size: 0.9em; color: #2E8B57;'>‚úì Weights sum to 1.0</div>\"\n",
    "    )\n",
    "\n",
    "    def validate_and_update_weights(change):\n",
    "        current_sum = round(semantic_weight.value + keyword_weight.value, 1)\n",
    "        \n",
    "        if current_sum > 1:\n",
    "            # If semantic weight was changed\n",
    "            if change.owner == semantic_weight:\n",
    "                keyword_weight.value = max(0, round(1 - semantic_weight.value, 1))\n",
    "            # If keyword weight was changed\n",
    "            else:\n",
    "                semantic_weight.value = max(0, round(1 - keyword_weight.value, 1))\n",
    "            \n",
    "            current_sum = round(semantic_weight.value + keyword_weight.value, 1)\n",
    "        \n",
    "        # Update status display\n",
    "        if current_sum > 1:\n",
    "            weight_status.value = f\"<div style='padding: 5px; font-size: 0.9em; color: #DC143C;'>‚ö†Ô∏è Sum exceeds 1 (Current: {current_sum})</div>\"\n",
    "        elif current_sum == 1:\n",
    "            weight_status.value = f\"<div style='padding: 5px; font-size: 0.9em; color: #2E8B57;'>‚úì Weights sum to {current_sum}</div>\"\n",
    "        else:\n",
    "            weight_status.value = f\"<div style='padding: 5px; font-size: 0.9em; color: #DAA520;'>‚ÑπÔ∏è Sum is {current_sum}</div>\"\n",
    "\n",
    "    # Observe changes in both sliders\n",
    "    semantic_weight.observe(validate_and_update_weights, names='value')\n",
    "    keyword_weight.observe(validate_and_update_weights, names='value')\n",
    "    \n",
    "    # Layout\n",
    "    display(HTML(\"\"\"\n",
    "        <style>\n",
    "            .adaptive-title { \n",
    "                color: #0f1111; \n",
    "            }\n",
    "            @media (prefers-color-scheme: dark) {\n",
    "                .adaptive-title { color: #e3e6e8; }\n",
    "            }\n",
    "            body.vscode-dark .adaptive-title,\n",
    "            body.vscode-high-contrast .adaptive-title,\n",
    "            .jp-Notebook-dark .adaptive-title {\n",
    "                color: #e3e6e8;\n",
    "            }\n",
    "        </style>\n",
    "        <h2 class=\"adaptive-title\">üõçÔ∏è Amazon Product Search Comparison</h2>\n",
    "        <div style=\"background: #f7f8f8; padding: 15px; border-radius: 8px; margin: 15px 0;\">\n",
    "            <h4 style=\"color: #0f1111; margin-top: 0;\">Search Method Strengths:</h4>\n",
    "            <ul style=\"color: #565959; margin: 10px 0;\">\n",
    "                <li><strong style=\"color: #1565c0;\">Keyword:</strong> Perfect for exact product names, SKUs, brand searches</li>\n",
    "                <li><strong style=\"color: #c2185b;\">Fuzzy:</strong> Handles typos and misspellings</li>\n",
    "                <li><strong style=\"color: #2e7d32;\">Semantic:</strong> Understands intent and concepts using Cohere embeddings</li>\n",
    "                <li><strong style=\"color: #e65100;\">Hybrid:</strong> Best overall - combines keyword matching with semantic understanding</li>\n",
    "            </ul>\n",
    "           <div style=\"border-left: 4px solid #4CAF50; padding-left: 10px; margin-top: 10px; color: black;\"> \n",
    "                <strong>ü§ñ Cohere Models:</strong> embed-english-v3 (embeddings) ‚Ä¢ rerank-v3-5:0 (re-ranking)\n",
    "            </div>\n",
    "            <div style=\"background: #fff3e0; border-left: 4px solid #e65100; padding: 12px; margin-top: 15px; border-radius: 4px;\">\n",
    "                <h4 style=\"color: #2e7d32; margin-top: 0; margin-bottom: 8px;\">üí° Understanding Hybrid Search Approaches</h4>\n",
    "                <p style=\"color: #1b5e20; margin: 8px 0; font-size: 13px;\">\n",
    "                    <strong>Challenge:</strong> Different search methods produce vastly different score ranges (semantic: 0.7-1.0, keyword: 0.01-0.1), causing one method to dominate weighted combinations.\n",
    "                </p>\n",
    "                <p style=\"color: #1b5e20; margin: 8px 0; font-size: 13px;\">\n",
    "                    <strong>Solutions Demonstrated:</strong>\n",
    "                </p>\n",
    "                <ul style=\"color: #1b5e20; margin: 8px 0; font-size: 13px; padding-left: 20px;\">\n",
    "                    <li><strong>Hybrid (70/30):</strong> Weighted score fusion - simple but requires careful tuning</li>\n",
    "                    <li><strong>Hybrid-RRF:</strong> Rank-based fusion - robust, no normalization needed ‚ú®</li>\n",
    "                    <li><strong>Cohere Rerank:</strong> ML-based re-ranking - most sophisticated approach</li>\n",
    "                </ul>\n",
    "                <div style=\"background: #e8f5e9; border-left: 4px solid #4caf50; padding: 10px; margin: 8px 0; font-size: 13px; color: #1b5e20;\">\n",
    "                    <strong>üí° Try the examples below</strong> to see how each method handles different query types!\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    \"\"\"))\n",
    "    \n",
    "    # Display interface\n",
    "    display(widgets.VBox([\n",
    "        widgets.HTML('<h4 style=\"color: #0f1111; margin: 15px 0;\">üìù Example Searches (Click to Try):</h4>'),\n",
    "        widgets.GridBox(\n",
    "            example_buttons,\n",
    "            layout=widgets.Layout(\n",
    "                grid_template_columns='repeat(3, 1fr)',\n",
    "                grid_gap='5px'\n",
    "            )\n",
    "        ),\n",
    "        widgets.HTML('<hr style=\"margin: 20px 0; border-color: #e3e6e8;\">'),\n",
    "        query_input,\n",
    "        search_method,\n",
    "        widgets.HTML('<h4 style=\"color: #0f1111;\">‚öôÔ∏è Options:</h4>'),\n",
    "        widgets.HBox([\n",
    "            widgets.VBox([\n",
    "                widgets.HTML('<strong>Hybrid Weights:</strong>'),\n",
    "                semantic_weight,\n",
    "                keyword_weight,\n",
    "                weight_status\n",
    "            ]),\n",
    "            widgets.VBox([\n",
    "                results_limit,\n",
    "                rerank_checkbox\n",
    "            ])\n",
    "        ]),\n",
    "        search_button,\n",
    "        results_output\n",
    "    ]))\n",
    "\n",
    "# Create and display the interface\n",
    "create_search_interface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Step 6: Performance Analysis & Insights (OPTIONAL)\n",
    "\n",
    "Let's analyze the performance characteristics of different search methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Performance Analysis & Optimization Insights\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def performance_analysis():\n",
    "    \"\"\"Analyze and visualize performance of different search methods\"\"\"\n",
    "    \n",
    "    # Test queries representing different search scenarios\n",
    "    test_queries = [\n",
    "        # Exact match scenarios\n",
    "        (\"Apple AirPods\", \"Exact Product\"),\n",
    "        (\"wireless headphones\", \"Product Category\"),\n",
    "        \n",
    "        # Semantic scenarios\n",
    "        (\"gift for coffee lover\", \"Intent-based\"),\n",
    "        (\"eco-friendly water bottle\", \"Attribute-focused\"),\n",
    "        \n",
    "        # Typo scenarios\n",
    "        (\"wireles hedphones\", \"Spelling Errors\"),\n",
    "        (\"bose quitcomfort\", \"Brand Typos\"),\n",
    "        \n",
    "        # Complex scenarios\n",
    "        (\"best camera under 500\", \"Budget Constraint\"),\n",
    "        (\"lightweight laptop for travel\", \"Multi-attribute\")\n",
    "    ]\n",
    "    \n",
    "    results_data = []\n",
    "    \n",
    "    print(\"üîÑ Running performance analysis...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for query, scenario in tqdm(test_queries, desc=\"Testing queries\"):\n",
    "        # Test each method\n",
    "        methods = [\n",
    "            ('Keyword', lambda q: keyword_search(q, 5)),\n",
    "            ('Fuzzy', lambda q: fuzzy_search(q, 5)),\n",
    "            ('Semantic', lambda q: semantic_search(q, 5)),\n",
    "            ('Hybrid', lambda q: hybrid_search(q, semantic_weight=0.7, keyword_weight=0.3, limit=5))\n",
    "        ]\n",
    "        \n",
    "        for method_name, method_func in methods:\n",
    "            try:\n",
    "                # Measure performance\n",
    "                start_time = time.time()\n",
    "                results = method_func(query)\n",
    "                elapsed = time.time() - start_time\n",
    "                \n",
    "                # Calculate metrics\n",
    "                results_data.append({\n",
    "                    'Query': query[:25] + '...' if len(query) > 25 else query,\n",
    "                    'Scenario': scenario,\n",
    "                    'Method': method_name,\n",
    "                    'Results': len(results),\n",
    "                    'Avg Score': np.mean([r['score'] for r in results]) if results else 0,\n",
    "                    'Max Score': max([r['score'] for r in results]) if results else 0,\n",
    "                    'Time (ms)': elapsed * 1000,\n",
    "                    'Success': len(results) > 0\n",
    "                })\n",
    "            except Exception as e:\n",
    "                results_data.append({\n",
    "                    'Query': query[:25] + '...' if len(query) > 25 else query,\n",
    "                    'Scenario': scenario,\n",
    "                    'Method': method_name,\n",
    "                    'Results': 0,\n",
    "                    'Avg Score': 0,\n",
    "                    'Max Score': 0,\n",
    "                    'Time (ms)': 0,\n",
    "                    'Success': False\n",
    "                })\n",
    "    \n",
    "    df = pd.DataFrame(results_data)\n",
    "    \n",
    "    # Create comprehensive visualizations\n",
    "    fig = plt.figure(figsize=(18, 10))\n",
    "    gs = fig.add_gridspec(2, 3, hspace=0.25, wspace=0.3)\n",
    "    \n",
    "    # 1. Success Rate by Scenario\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    success_pivot = df.pivot_table(\n",
    "        values='Success',\n",
    "        index='Scenario',\n",
    "        columns='Method',\n",
    "        aggfunc='mean'\n",
    "    ) * 100\n",
    "    success_pivot.plot(kind='bar', ax=ax1, width=0.8)\n",
    "    ax1.set_title('Success Rate by Scenario (%)', fontsize=12, fontweight='bold')\n",
    "    ax1.set_ylabel('Success Rate (%)')\n",
    "    ax1.set_xlabel('')\n",
    "    ax1.legend(title='Method', loc='lower right')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 2. Average Score Heatmap\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    score_pivot = df.pivot_table(\n",
    "        values='Avg Score',\n",
    "        index='Scenario',\n",
    "        columns='Method'\n",
    "    )\n",
    "    sns.heatmap(score_pivot, annot=True, fmt='.3f', cmap='RdYlGn', ax=ax2, vmin=0, vmax=1, cbar_kws={'label': 'Score'})\n",
    "    ax2.set_title('Average Relevance Score', fontsize=12, fontweight='bold')\n",
    "    ax2.set_xlabel('Method')\n",
    "    ax2.set_ylabel('')\n",
    "    \n",
    "    # 3. Best Method by Scenario\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    \n",
    "    # Calculate best method for each scenario\n",
    "    scenario_matrix = pd.crosstab(df['Scenario'], df['Method'], values=df['Avg Score'], aggfunc='mean')\n",
    "    \n",
    "    # Create a normalized version for visualization\n",
    "    scenario_norm = scenario_matrix.div(scenario_matrix.max(axis=1), axis=0)\n",
    "    \n",
    "    sns.heatmap(scenario_norm, annot=scenario_matrix.round(2), fmt='', cmap='YlOrRd', ax=ax3, vmin=0, vmax=1, cbar_kws={'label': 'Score'})\n",
    "    ax3.set_title('Best Method by Scenario', fontsize=12, fontweight='bold')\n",
    "    ax3.set_xlabel('Method')\n",
    "    ax3.set_ylabel('')\n",
    "    \n",
    "    # 4. Method Performance Radar Chart\n",
    "    ax4 = fig.add_subplot(gs[1, 0], projection='polar')\n",
    "    \n",
    "    # Calculate aggregate metrics\n",
    "    metrics = df.groupby('Method').agg({\n",
    "        'Time (ms)': lambda x: 1 / (1 + x.mean()/100),  # Inverse for better = higher, normalized\n",
    "        'Results': lambda x: x.mean() / 5,  # Normalize by max results\n",
    "        'Avg Score': 'mean',\n",
    "        'Success': 'mean'\n",
    "    })\n",
    "    \n",
    "    categories = ['Speed', 'Coverage', 'Relevance', 'Reliability']\n",
    "    angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()\n",
    "    angles += angles[:1]\n",
    "    \n",
    "    colors = {'Keyword': '#1f77b4', 'Fuzzy': '#ff7f0e', 'Semantic': '#2ca02c', 'Hybrid': '#d62728'}\n",
    "    \n",
    "    for method in metrics.index:\n",
    "        values = metrics.loc[method].values.tolist()\n",
    "        values += values[:1]\n",
    "        ax4.plot(angles, values, 'o-', linewidth=2, label=method, color=colors.get(method, 'gray'))\n",
    "        ax4.fill(angles, values, alpha=0.15, color=colors.get(method, 'gray'))\n",
    "    \n",
    "    ax4.set_xticks(angles[:-1])\n",
    "    ax4.set_xticklabels(categories, size=11)\n",
    "    ax4.set_ylim(0, 1)\n",
    "    ax4.set_title('Normalized Performance Comparison', fontsize=12, fontweight='bold', pad=20)\n",
    "    ax4.legend(loc='upper right', bbox_to_anchor=(1.2, 1.1))\n",
    "    ax4.grid(True)\n",
    "    \n",
    "    # 5. Speed vs Accuracy Trade-off\n",
    "    ax5 = fig.add_subplot(gs[1, 1])\n",
    "    \n",
    "    colors_scatter = {'Keyword': '#1f77b4', 'Fuzzy': '#ff7f0e', 'Semantic': '#2ca02c', 'Hybrid': '#d62728'}\n",
    "    \n",
    "    for method in df['Method'].unique():\n",
    "        method_data = df[df['Method'] == method]\n",
    "        ax5.scatter(method_data['Time (ms)'], method_data['Avg Score'], \n",
    "                   label=method, alpha=0.7, s=120, color=colors_scatter.get(method, 'gray'),\n",
    "                   edgecolors='black', linewidth=0.5)\n",
    "    \n",
    "    ax5.set_xlabel('Response Time (ms)', fontsize=11)\n",
    "    ax5.set_ylabel('Average Score', fontsize=11)\n",
    "    ax5.set_title('Speed vs Accuracy Trade-off', fontsize=12, fontweight='bold')\n",
    "    ax5.legend(loc='best')\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add ideal zone annotation\n",
    "    ax5.axhspan(0.4, 0.6, alpha=0.1, color='green', label='Optimal Zone')\n",
    "    ax5.axvspan(0, 2500, alpha=0.1, color='green')\n",
    "    \n",
    "    # 6. Method Rankings\n",
    "    ax6 = fig.add_subplot(gs[1, 2])\n",
    "    \n",
    "    # Calculate rankings\n",
    "    rankings = []\n",
    "    for scenario in df['Scenario'].unique():\n",
    "        scenario_data = df[df['Scenario'] == scenario]\n",
    "        scenario_ranked = scenario_data.sort_values('Avg Score', ascending=False)\n",
    "        for i, (_, row) in enumerate(scenario_ranked.iterrows(), 1):\n",
    "            rankings.append({\n",
    "                'Scenario': scenario,\n",
    "                'Method': row['Method'],\n",
    "                'Rank': i\n",
    "            })\n",
    "    \n",
    "    ranking_df = pd.DataFrame(rankings)\n",
    "    ranking_pivot = ranking_df.pivot_table(values='Rank', index='Method', aggfunc='mean')\n",
    "    \n",
    "    # Create bar chart with colors - convert to numpy array to fix the error\n",
    "    bars = ax6.bar(ranking_pivot.index, ranking_pivot.values.flatten(), \n",
    "                   color=[colors_scatter.get(m, 'gray') for m in ranking_pivot.index])\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax6.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.2f}', ha='center', va='bottom')\n",
    "    \n",
    "    ax6.set_title('Average Ranking Across Scenarios', fontsize=12, fontweight='bold')\n",
    "    ax6.set_ylabel('Average Rank (Lower is Better)', fontsize=11)\n",
    "    ax6.set_xlabel('Method', fontsize=11)\n",
    "    ax6.set_ylim(0.5, 4.5)\n",
    "    ax6.invert_yaxis()\n",
    "    ax6.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.suptitle('Search Method Performance Analysis', fontsize=14, fontweight='bold', y=0.98)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Display summary statistics\n",
    "    print(\"\\nüìä Performance Summary Statistics:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    summary = df.groupby('Method').agg({\n",
    "        'Time (ms)': ['mean', 'std', 'min', 'max'],\n",
    "        'Results': ['mean', 'std'],\n",
    "        'Avg Score': ['mean', 'std'],\n",
    "        'Success': lambda x: f\"{x.mean()*100:.1f}%\"\n",
    "    }).round(2)\n",
    "    \n",
    "    display(summary)\n",
    "    \n",
    "    # Recommendations based on analysis\n",
    "    print(\"\\nüí° Method Recommendations by Use Case:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    recommendations = {\n",
    "        \"Exact Product Search\": \"Keyword (TSVector) - Fastest and most accurate for exact matches\",\n",
    "        \"Typo Tolerance\": \"Fuzzy (pg_trgm) - Best at handling misspellings\",\n",
    "        \"Conceptual Search\": \"Semantic - Understanding intent and context\",\n",
    "        \"General Purpose\": \"Hybrid - Balanced performance across all scenarios\",\n",
    "        \"Speed Critical\": \"Keyword - Lowest latency\",\n",
    "        \"Accuracy Critical\": \"Hybrid/Semantic - Highest relevance scores\"\n",
    "    }\n",
    "    \n",
    "    for use_case, rec in recommendations.items():\n",
    "        print(f\"‚Ä¢ {use_case}: {rec}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Additional optimization insights function\n",
    "def optimization_insights(df: pd.DataFrame):\n",
    "    \"\"\"Generate specific optimization recommendations\"\"\"\n",
    "    \n",
    "    print(\"\\nüîß Optimization Insights:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Calculate insights\n",
    "    avg_times = df.groupby('Method')['Time (ms)'].mean()\n",
    "    avg_scores = df.groupby('Method')['Avg Score'].mean()\n",
    "    \n",
    "    # Speed analysis\n",
    "    fastest = avg_times.idxmin()\n",
    "    slowest = avg_times.idxmax()\n",
    "    speed_diff = (avg_times[slowest] - avg_times[fastest]) / avg_times[fastest] * 100\n",
    "    \n",
    "    print(f\"\\n‚ö° Speed Analysis:\")\n",
    "    print(f\"  ‚Ä¢ Fastest: {fastest} ({avg_times[fastest]:.1f}ms)\")\n",
    "    print(f\"  ‚Ä¢ Slowest: {slowest} ({avg_times[slowest]:.1f}ms)\")\n",
    "    print(f\"  ‚Ä¢ Performance gap: {speed_diff:.0f}% slower\")\n",
    "    \n",
    "    # Accuracy analysis\n",
    "    most_accurate = avg_scores.idxmax()\n",
    "    least_accurate = avg_scores.idxmin()\n",
    "    \n",
    "    print(f\"\\nüéØ Accuracy Analysis:\")\n",
    "    print(f\"  ‚Ä¢ Most accurate: {most_accurate} (avg score: {avg_scores[most_accurate]:.3f})\")\n",
    "    print(f\"  ‚Ä¢ Least accurate: {least_accurate} (avg score: {avg_scores[least_accurate]:.3f})\")\n",
    "    \n",
    "    # SQL Optimization Commands for DBAs\n",
    "    print(f\"\\nüìù SQL OPTIMIZATION COMMANDS FOR DBAs:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\n-- 1. KEYWORD SEARCH OPTIMIZATION (TSVector)\")\n",
    "    print(\"\"\"\n",
    "    -- Check if GIN index exists on tsvector\n",
    "    SELECT indexname, indexdef \n",
    "    FROM pg_indexes \n",
    "    WHERE tablename = 'product_catalog' \n",
    "    AND indexdef LIKE '%gin%tsvector%';\n",
    "    \n",
    "    -- Create optimized GIN index if missing\n",
    "    CREATE INDEX CONCURRENTLY IF NOT EXISTS product_catalog_fts_gin_idx \n",
    "    ON bedrock_integration.product_catalog \n",
    "    USING GIN (to_tsvector('english', product_description));\n",
    "    \n",
    "    -- Analyze table statistics\n",
    "    ANALYZE bedrock_integration.product_catalog;\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"\\n-- 2. FUZZY SEARCH OPTIMIZATION (pg_trgm)\")\n",
    "    print(\"\"\"\n",
    "    -- Check trigram extension\n",
    "    SELECT * FROM pg_extension WHERE extname = 'pg_trgm';\n",
    "    \n",
    "    -- Create trigram GIN index\n",
    "    CREATE INDEX CONCURRENTLY IF NOT EXISTS product_catalog_trgm_idx \n",
    "    ON bedrock_integration.product_catalog \n",
    "    USING GIN (product_description gin_trgm_ops);\n",
    "    \n",
    "    -- Optimize similarity threshold\n",
    "    SET pg_trgm.similarity_threshold = 0.3;  -- Adjust based on requirements\n",
    "    \n",
    "    -- Check current threshold\n",
    "    SHOW pg_trgm.similarity_threshold;\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"\\n-- 3. VECTOR SEARCH OPTIMIZATION (pgvector)\")\n",
    "    print(\"\"\"\n",
    "    -- Check HNSW index parameters\n",
    "    SELECT indexname, indexdef \n",
    "    FROM pg_indexes \n",
    "    WHERE tablename = 'product_catalog' \n",
    "    AND indexdef LIKE '%hnsw%';\n",
    "    \n",
    "    -- Create optimized HNSW index for Cohere embeddings\n",
    "    CREATE INDEX CONCURRENTLY IF NOT EXISTS product_catalog_embedding_hnsw_idx \n",
    "    ON bedrock_integration.product_catalog \n",
    "    USING hnsw (embedding vector_cosine_ops)\n",
    "    WITH (m = 16, ef_construction = 64);\n",
    "    \n",
    "    -- Optimize work_mem for vector operations\n",
    "    SET work_mem = '256MB';  -- Increase for large vector operations\n",
    "    \n",
    "    -- Check vector dimension statistics\n",
    "    SELECT \n",
    "        COUNT(*) as total_products,\n",
    "        COUNT(embedding) as products_with_embeddings,\n",
    "        AVG(vector_dims(embedding)) as avg_dimensions\n",
    "    FROM bedrock_integration.product_catalog;\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"\\n-- 4. QUERY PERFORMANCE ANALYSIS\")\n",
    "    print(\"\"\"\n",
    "    -- Enable query timing\n",
    "    \\\\timing on\n",
    "    \n",
    "    -- Analyze slow queries\n",
    "    SELECT \n",
    "        query,\n",
    "        calls,\n",
    "        mean_exec_time,\n",
    "        max_exec_time,\n",
    "        total_exec_time\n",
    "    FROM pg_stat_statements\n",
    "    WHERE query LIKE '%product_catalog%'\n",
    "    ORDER BY mean_exec_time DESC\n",
    "    LIMIT 10;\n",
    "    \n",
    "    -- Check table bloat\n",
    "    SELECT \n",
    "        schemaname,\n",
    "        tablename,\n",
    "        pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size,\n",
    "        n_live_tup,\n",
    "        n_dead_tup,\n",
    "        round(n_dead_tup::numeric/NULLIF(n_live_tup,0), 2) as dead_ratio\n",
    "    FROM pg_stat_user_tables\n",
    "    WHERE schemaname = 'bedrock_integration'\n",
    "    ORDER BY n_dead_tup DESC;\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"\\n-- 5. MAINTENANCE COMMANDS\")\n",
    "    print(\"\"\"\n",
    "    -- Vacuum and analyze for optimal performance\n",
    "    VACUUM (ANALYZE, VERBOSE) bedrock_integration.product_catalog;\n",
    "    \n",
    "    -- Reindex if fragmented\n",
    "    REINDEX TABLE CONCURRENTLY bedrock_integration.product_catalog;\n",
    "    \n",
    "    -- Update table statistics\n",
    "    ANALYZE bedrock_integration.product_catalog (product_description, embedding);\n",
    "    \n",
    "    -- Monitor index usage\n",
    "    SELECT \n",
    "        schemaname,\n",
    "        tablename,\n",
    "        indexname,\n",
    "        idx_scan,\n",
    "        idx_tup_read,\n",
    "        idx_tup_fetch\n",
    "    FROM pg_stat_user_indexes\n",
    "    WHERE schemaname = 'bedrock_integration'\n",
    "    ORDER BY idx_scan DESC;\n",
    "    \"\"\")\n",
    "    \n",
    "    # Performance recommendations based on actual timings\n",
    "    print(f\"\\nüéØ SPECIFIC RECOMMENDATIONS BASED ON ANALYSIS:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if avg_times['Semantic'] > 2500:\n",
    "        print(\"\\n‚ö†Ô∏è VECTOR SEARCH NEEDS OPTIMIZATION:\")\n",
    "        print(\"  ‚Ä¢ Consider increasing HNSW 'm' parameter to 32\")\n",
    "        print(\"  ‚Ä¢ Set maintenance_work_mem = '512MB' before index creation\")\n",
    "        print(\"  ‚Ä¢ Consider using IVFFlat for datasets > 1M rows\")\n",
    "    \n",
    "    if avg_times['Keyword'] > 1500:\n",
    "        print(\"\\n‚ö†Ô∏è KEYWORD SEARCH NEEDS OPTIMIZATION:\")\n",
    "        print(\"  ‚Ä¢ Ensure GIN index exists on tsvector column\")\n",
    "        print(\"  ‚Ä¢ Consider partial indexes for frequently searched categories\")\n",
    "        print(\"  ‚Ä¢ Use ts_stat() to analyze term frequency\")\n",
    "    \n",
    "    if avg_times['Fuzzy'] > 2000:\n",
    "        print(\"\\n‚ö†Ô∏è FUZZY SEARCH NEEDS OPTIMIZATION:\")\n",
    "        print(\"  ‚Ä¢ Verify pg_trgm GIN index exists\")\n",
    "        print(\"  ‚Ä¢ Consider lowering similarity_threshold\")\n",
    "        print(\"  ‚Ä¢ Use word_similarity() for better partial matching\")\n",
    "    \n",
    "    # Cost-benefit analysis\n",
    "    print(f\"\\nüí∞ Cost-Benefit Analysis:\")\n",
    "    \n",
    "    hybrid_benefit = (avg_scores['Hybrid'] - avg_scores['Keyword']) / avg_scores['Keyword'] * 100\n",
    "    hybrid_cost = (avg_times['Hybrid'] - avg_times['Keyword']) / avg_times['Keyword'] * 100\n",
    "    \n",
    "    print(f\"  ‚Ä¢ Hybrid vs Keyword:\")\n",
    "    print(f\"    - Accuracy improvement: +{hybrid_benefit:.1f}%\")\n",
    "    print(f\"    - Speed cost: +{hybrid_cost:.1f}% slower\")\n",
    "    print(f\"    - ROI: {hybrid_benefit/hybrid_cost:.2f}x benefit per ms\")\n",
    "\n",
    "# Run the analysis\n",
    "print(\"Starting comprehensive performance analysis...\")\n",
    "perf_df = performance_analysis()\n",
    "\n",
    "# Generate optimization insights\n",
    "optimization_insights(perf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Key Takeaways & Best Practices\n",
    "\n",
    "### Search Method Deep Dive\n",
    "\n",
    "| Method | Best For | Limitations | Index Strategy |\n",
    "|--------|----------|-------------|----------------|\n",
    "| **TSVector** | ‚Ä¢ Exact lexical matches<br>‚Ä¢ Known domain terminology<br>‚Ä¢ Boolean queries (AND/OR/NOT)<br>‚Ä¢ Phrase searching | ‚Ä¢ No semantic understanding<br>‚Ä¢ Misses synonyms/variants<br>‚Ä¢ Language-specific configs<br>‚Ä¢ Stopword dependencies | GIN/GiST indexes<br>Partial index patterns |\n",
    "| **pg_trgm** | ‚Ä¢ Fuzzy matching (Levenshtein)<br>‚Ä¢ Typo tolerance<br>‚Ä¢ Substring searches<br>‚Ä¢ LIKE pattern acceleration | ‚Ä¢ Limited to character n-grams<br>‚Ä¢ No semantic context<br>‚Ä¢ Memory intensive at scale<br>‚Ä¢ Fixed similarity threshold | GIN with gin_trgm_ops<br>Composite for selectivity<br>Expression indexes |\n",
    "| **Semantic** | ‚Ä¢ Natural language queries<br>‚Ä¢ Conceptual similarity<br>‚Ä¢ Intent understanding<br>‚Ä¢ Cross-language search | ‚Ä¢ Requires embedding models<br>‚Ä¢ May miss exact terms<br>‚Ä¢ Latency for embedding<br>‚Ä¢ Storage overhead (1536-dim) | HNSW (pgvector)<br>Partitioned indexes |\n",
    "| **Hybrid** | ‚Ä¢ Production search systems<br>‚Ä¢ User-facing applications<br>‚Ä¢ Mixed query patterns<br>‚Ä¢ Evolving requirements | ‚Ä¢ Tuning complexity<br>‚Ä¢ Multiple index maintenance<br>‚Ä¢ Query planning overhead<br>‚Ä¢ Cache invalidation | Combined strategy<br>Parallel index scans<br>Cost-based optimization |\n",
    "\n",
    "### Enterprise-Grade Weight Configuration Matrix\n",
    "\n",
    "| Use Case | Semantic Weight | Keyword Weight | Rationale | Index Priority |\n",
    "|----------|----------------|----------------|-----------|----------------|\n",
    "| **E-commerce Catalog** | 70% | 30% | Users describe products naturally; exact SKUs handled separately | HNSW for vectors, partial GIN for categories |\n",
    "| **Technical Documentation** | 40% | 60% | Precise terminology critical; concepts secondary for accuracy | GIN with custom dictionaries, smaller HNSW |\n",
    "| **Customer Support Tickets** | 80% | 20% | Intent matters more than exact wording; emotional context crucial | Large HNSW index, basic text search fallback |\n",
    "| **SKU/Part Number Search** | 10% | 90% | Exact matches required; minimal semantic benefit | B-tree for exact, pg_trgm for fuzzy |\n",
    "| **Legal Document Repository** | 35% | 65% | Precise legal terms essential; some conceptual linking helpful | Full-text with phrase search, auxiliary vectors |\n",
    "| **Knowledge Base Articles** | 65% | 35% | Balance between natural queries and technical terms | Dual indexing with equal maintenance priority |\n",
    "\n",
    "### ‚úÖ Congratulations! You've completed Lab 1!\n",
    "\n",
    "You've successfully:\n",
    "- Implemented multiple search methods (TSVector, pg_trgm, pgvector)\n",
    "- Compared different search approaches and their trade-offs\n",
    "- Built a configurable hybrid search system with dynamic weighting\n",
    "- Analyzed index strategies for each search method\n",
    "- Learned enterprise-grade weight configurations for various use cases\n",
    "\n",
    "### üöÄ Ready for Lab 2: MCP & Strands Integration!\n",
    "\n",
    "Next up: Build intelligent agents with Model Context Protocol and Strands framework"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}