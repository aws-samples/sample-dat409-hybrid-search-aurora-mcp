# DAT409 - Hybrid Search with Aurora PostgreSQL for MCP Retrieval

[![AWS](https://img.shields.io/badge/AWS-Aurora_PostgreSQL-FF9900?style=for-the-badge&logo=amazon-aws&logoColor=white)](https://aws.amazon.com/rds/aurora/)
[![Python](https://img.shields.io/badge/Python-3.13-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-17.5-316192?style=for-the-badge&logo=postgresql&logoColor=white)](https://www.postgresql.org/)
[![Bedrock](https://img.shields.io/badge/Amazon_Bedrock-Cohere-FF9900?style=for-the-badge&logo=amazon-aws&logoColor=white)](https://aws.amazon.com/bedrock/)
[![License](https://img.shields.io/badge/License-MIT--0-green?style=for-the-badge)](LICENSE)

> **âš ï¸ Important Notice**: For demonstration and educational purposes only. Not intended for production use.

## ğŸš€ Quick Start

**Workshop Duration**: 60 minutes | **Lab 1**: 25 min | **Lab 2**: 20 min

Build hybrid search with Aurora PostgreSQL, pgvector, and MCP for natural language database queries.

## ğŸ“ Repository Structure

```
â”œâ”€â”€ lab1-hybrid-search/
â”‚   â”œâ”€â”€ notebook/
â”‚   â”‚   â””â”€â”€ dat409-hybrid-search-notebook.ipynb  # Main lab notebook
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ amazon-products.csv                  # 21,704 products
â”‚   â””â”€â”€ requirements.txt                         # Lab 1 dependencies
â”œâ”€â”€ lab2-mcp-agent/
â”‚   â”œâ”€â”€ streamlit_app.py                         # Streamlit demo app
â”‚   â”œâ”€â”€ test_personas.sh                         # RLS testing script
â”‚   â”œâ”€â”€ mcp_config.json                          # MCP configuration
â”‚   â””â”€â”€ requirements.txt                         # Lab 2 dependencies
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ bootstrap-code-editor.sh                 # Infrastructure setup
â”‚   â”œâ”€â”€ setup-database.sh                        # Database & data loading
â”‚   â””â”€â”€ setup/                                   # Helper scripts
â”œâ”€â”€ cfn/                                         # CloudFormation templates
â”œâ”€â”€ env_example                                  # Environment template
â””â”€â”€ README.md                                    # This file
```

## ğŸ¯ Labs

### Lab 1: Hybrid Search (25 min)
Combine vector similarity (pgvector + HNSW), full-text search, and fuzzy matching (pg_trgm) with 21,704 products.

```bash
cd /workshop/lab1-hybrid-search/notebook
# Open dat409-hybrid-search-notebook.ipynb
```

### Lab 2: MCP & RLS (20 min)
Natural language queries with Model Context Protocol and Row-Level Security for multi-tenant access.

```bash
cd /workshop/lab2-mcp-agent
./test_personas.sh  # Test customer, support, product manager personas
streamlit run streamlit_app.py  # Optional demo
```

## ğŸ› ï¸ Prerequisites
- AWS Account with Aurora PostgreSQL 17.5 + Amazon Bedrock (Cohere Embed English v3)
- Python 3.13 + Jupyter Notebook

## ğŸš¦ Getting Started

**Participants**: Access Code Editor via CloudFront URL â†’ Open Lab 1 notebook in `/workshop/lab1-hybrid-search/notebook/`

**Instructors**: See [DEPLOYMENT_SEQUENCE.md](DEPLOYMENT_SEQUENCE.md) for setup.

## ğŸ”§ Technical Stack
- **Database**: Aurora PostgreSQL 17.5 with pgvector extension
- **Embeddings**: Cohere Embed English v3 (1024 dimensions)
- **Search**: HNSW vector index + GIN full-text + pg_trgm fuzzy
- **MCP**: Model Context Protocol for database access
- **AI Agent**: Strands Agent with Claude Sonnet 4 + MCP tools
- **RLS**: Row-Level Security for persona-based access
- **Python**: 3.13 with pandas, psycopg, boto3, streamlit

## ğŸ¤– MCP Agent Architecture

The workshop demonstrates natural language database queries using a **Strands Agent** with **MCP tools**:

```
User Query â†’ Strands Agent (Claude Sonnet 4) â†’ MCP Client â†’ Aurora PostgreSQL (Data API)
```

**Key Components:**
- **Strands Agent**: AI agent framework with tool-calling capabilities
- **MCP Client**: Provides standardized database access tools via `awslabs.postgres-mcp-server`
- **Claude Sonnet 4**: Interprets queries and decides which MCP tools to call
- **Aurora Data API**: Serverless database access using cluster ARN + secret ARN

**Why This Pattern?**
- Agent uses admin access via Data API for intelligent cross-schema queries
- Application-level authorization handles security (typical production pattern for AI agents)
- MCP provides standardized, reusable database tools
- Enables natural language â†’ SQL translation with context awareness

## ğŸ“š Resources
[Aurora PostgreSQL](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/) | [pgvector](https://github.com/pgvector/pgvector) | [MCP](https://modelcontextprotocol.io/)

## â­ Like This Workshop?

If you find this workshop helpful, please consider:
- â­ **Star this repository** to show your support!
- ğŸ´ **Fork it** to customize for your own use cases
- ğŸ› **Report issues** to help us improve
- ğŸ’¡ **Submit pull requests** with enhancements or fixes
- ğŸ“¢ **Share it** with your colleagues and community

Your feedback and contributions help make this workshop better for everyone!

## ğŸ¤ Contributing

Contributions welcome! Documentation, bug fixes, features, tests, or feedback. See [CONTRIBUTING.md](CONTRIBUTING.md).

## ğŸ“„ License & Security
MIT-0 License. See [LICENSE](LICENSE) | Security: [CONTRIBUTING.md](CONTRIBUTING.md#security-issue-notifications)

---

Â© 2025 Shayon Sanyal, Principal Solutions Architect, AWS
